{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Southern University of Science and Technology-Department of Computer Science and Engineering\n",
    "\n",
    "Course: Machine Learning(CS 405)-Professor: Qi Hao\n",
    "\n",
    "## Homework #2\n",
    "#### Due date: October, 7th, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import libraries that you might require.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import operator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement the KNN algorithm for the breast cancer dataset. Refer to the pdf and the following functions for the instructions. Complete all the functions as indicated below. The four functions would be autograded as mentioned in the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task 1: Classification\n",
    "\n",
    "Please implement KNN for K: 3, 5, and 7 with the following norms:\n",
    "L1\n",
    "L2\n",
    "L-inf\n",
    "\"\"\"\n",
    "\n",
    "# Read data (Breast Cancer Dataset). Remember to comment out the code not contained in a function.\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast = load_breast_cancer()\n",
    "\n",
    "X = breast['data']\n",
    "y = breast['target']\n",
    "\n",
    "np.random.seed(100)\n",
    "p = np.random.permutation(len(X))\n",
    "X, y = X[p], y[p]\n",
    "\n",
    "X_train, y_train = X[:400], y[:400]\n",
    "X_val, y_val = X[400:500], y[400:500]\n",
    "X_test, y_test = X[500:], y[500:]\n",
    "\n",
    "\n",
    "def distanceFunc(metric_type, vec1, vec2):\n",
    "    \"\"\"\n",
    "    Computes the distance between two d-dimension vectors. \n",
    "    \n",
    "    Please DO NOT use Numpy's norm function when implementing this function. \n",
    "    \n",
    "    Args:\n",
    "        metric_type (str): Metric: L1, L2, or L-inf\n",
    "        vec1 ((d,) np.ndarray): d-dim vector\n",
    "        vec2 ((d,)) np.ndarray): d-dim vector\n",
    "    \n",
    "    Returns:\n",
    "        distance (float): distance between the two vectors\n",
    "    \"\"\"\n",
    "\n",
    "    diff = vec1 - vec2\n",
    "    if metric_type == \"L1\":\n",
    "        distance = np.sum(np.abs(diff))\n",
    "\n",
    "    if metric_type == \"L2\":\n",
    "        distance = sqrt(np.sum(np.square(diff)))\n",
    "        \n",
    "    if metric_type == \"L-inf\":\n",
    "        distance = max(np.abs(diff))\n",
    "        \n",
    "    return distance\n",
    "\n",
    "\n",
    "def computeDistancesNeighbors(K, metric_type, X_train:np.ndarray, y_train, sample):\n",
    "    \"\"\"\n",
    "    Compute the distances between every datapoint in the train_data and the \n",
    "    given sample. Then, find the k-nearest neighbors.\n",
    "    \n",
    "    Return a numpy array of the label of the k-nearest neighbors.\n",
    "    \n",
    "    Args:\n",
    "        K (int): K-value\n",
    "        metric_type (str): metric type\n",
    "        X_train ((n,p) np.ndarray): Training data with n samples and p features\n",
    "        y_train : Training labels\n",
    "        sample ((p,) np.ndarray): Single sample whose distance is to computed with every entry in the dataset\n",
    "        \n",
    "    Returns:\n",
    "        neighbors (list): K-nearest neighbors' labels\n",
    "    \"\"\"\n",
    "\n",
    "    # You will also call the function \"distanceFunc\" here\n",
    "    # Complete this function\n",
    "    (m, n) = X_train.shape\n",
    "    p = sample.shape[0]\n",
    "    \n",
    "    dist = np.zeros((p, m))\n",
    "    \n",
    "    for i in range(0, p):\n",
    "        for j in range(0, m):\n",
    "            dist[i][j] = distanceFunc(metric_type, sample[i], X_train[j])\n",
    "            \n",
    "        \n",
    "    indices = np.argsort(dist, kind='stable')\n",
    "    lst = []\n",
    "    \n",
    "    for i in range(p):\n",
    "        lst.append(y_train[indices[i, :K]])\n",
    "            \n",
    "            \n",
    "    return np.array(lst)\n",
    "\n",
    "\n",
    "def Majority(neighbors):\n",
    "    \"\"\"\n",
    "    Performs majority voting and returns the predicted value for the test sample.\n",
    "    \n",
    "    Since we're performing binary classification the possible values are [0,1].\n",
    "    \n",
    "    Args:\n",
    "        neighbors (list): K-nearest neighbors' labels\n",
    "        \n",
    "    Returns:\n",
    "        predicted_value (int): predicted label for the given sample\n",
    "    \"\"\"\n",
    "    \n",
    "    # Performs majority voting\n",
    "    # Complete this function\n",
    "    res = np.argmax(np.bincount(neighbors))\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def KNN(K, metric_type, X_train, y_train, X_val:np.ndarray):\n",
    "    \"\"\"\n",
    "    Returns the predicted values for the entire validation or test set.\n",
    "    \n",
    "    Please DO NOT use Scikit's KNN model when implementing this function. \n",
    "\n",
    "    Args:\n",
    "        K (int): K-value\n",
    "        metric_type (str): metric type\n",
    "        X_train ((n,p) np.ndarray): Training data with n samples and p features\n",
    "        y_train : Training labels\n",
    "        X_val ((n, p) np.ndarray): Validation or test data\n",
    "        \n",
    "    Returns:\n",
    "        predicted_values (list): output for every entry in validation/test dataset \n",
    "    \"\"\"\n",
    "    \n",
    "    # Complete this function\n",
    "    # Loop through the val_data or the test_data (as required)\n",
    "    # and compute the output for every entry in that dataset  \n",
    "    # You will also call the function \"Majority\" here\n",
    "    K_nearest = computeDistancesNeighbors(K, metric_type, X_train, y_train, X_val)\n",
    "\n",
    "    predictions = np.zeros((X_val.shape[0],), dtype='int64')\n",
    "\n",
    "    for i in range(X_val.shape[0]):\n",
    "        predictions[i] = Majority(K_nearest[i])\n",
    "        \n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def evaluation(predicted_values, actual_values):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the given datapoints.\n",
    "    \n",
    "    Args:\n",
    "        predicted_values ((n,) np.ndarray): Predicted values for n samples\n",
    "        actual_values ((n,) np.ndarray): Actual values for n samples\n",
    "    \n",
    "    Returns:\n",
    "        accuracy (float): accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    return accuracy_score(predicted_values, actual_values)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Calls the above functions in order to implement the KNN algorithm.\n",
    "    \n",
    "    Test over the following range K = 3,5,7 and all three metrics. \n",
    "    In total you will have nine combinations to try.\n",
    "    \n",
    "    PRINTS out the accuracies for the nine combinations on the validation set,\n",
    "    and the accuracy on the test set for the selected K value and appropriate norm.\n",
    "    \n",
    "    REMEMBER: You have to report these values by populating the Table 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Complete this function\n",
    "    \n",
    "    K = [3,5,7]\n",
    "    norm = [\"L1\", \"L2\", \"L-inf\"]\n",
    "    \n",
    "    print(\"<<<<VALIDATION DATA PREDICTIONS>>>>\")\n",
    "    print(32*\"-\")\n",
    "    print(\"|{:^6s}|{:^6s}|{:^16s}|\".format(\"K\", \"Norm\", \"Accuracy(%)\"))\n",
    "\n",
    "    for k in K:\n",
    "        for n in norm:\n",
    "            res = KNN(k, n, X_train, y_train, X_val)\n",
    "            acc = evaluation(y_val, res)\n",
    "            print(\"|{:^6d}|{:^6s}|{:^16%}|\".format(k, n, acc))\n",
    "            \n",
    "        print(32*\"-\")\n",
    "\n",
    "\n",
    "    \n",
    "    ## Complete\n",
    "    print(\"<<<<TEST DATA PREDICTIONS>>>>\")\n",
    "    print(32*\"-\")\n",
    "    print(\"|{:^6s}|{:^6s}|{:^16s}|\".format(\"K\", \"Norm\", \"Accuracy(%)\"))\n",
    "\n",
    "    for k in K:\n",
    "        for n in norm:\n",
    "            res = KNN(k, n, X_train, y_train, X_test)\n",
    "            acc = evaluation(y_test, res)\n",
    "            print(\"|{:^6d}|{:^6s}|{:^16%}|\".format(k, n, acc))\n",
    "\n",
    "        print(32*\"-\")\n",
    "\n",
    "    ## Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the code below to run the main function (Remember to recomment the code before submitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<VALIDATION DATA PREDICTIONS>>>>\n",
      "--------------------------------\n",
      "|  K   | Norm |  Accuracy(%)   |\n",
      "|  3   |  L1  |   94.000000%   |\n",
      "|  3   |  L2  |   95.000000%   |\n",
      "|  3   |L-inf |   94.000000%   |\n",
      "--------------------------------\n",
      "|  5   |  L1  |   94.000000%   |\n",
      "|  5   |  L2  |   93.000000%   |\n",
      "|  5   |L-inf |   94.000000%   |\n",
      "--------------------------------\n",
      "|  7   |  L1  |   93.000000%   |\n",
      "|  7   |  L2  |   92.000000%   |\n",
      "|  7   |L-inf |   93.000000%   |\n",
      "--------------------------------\n",
      "<<<<TEST DATA PREDICTIONS>>>>\n",
      "--------------------------------\n",
      "|  K   | Norm |  Accuracy(%)   |\n",
      "|  3   |  L1  |   88.405797%   |\n",
      "|  3   |  L2  |   88.405797%   |\n",
      "|  3   |L-inf |   89.855072%   |\n",
      "--------------------------------\n",
      "|  5   |  L1  |   91.304348%   |\n",
      "|  5   |  L2  |   89.855072%   |\n",
      "|  5   |L-inf |   89.855072%   |\n",
      "--------------------------------\n",
      "|  7   |  L1  |   89.855072%   |\n",
      "|  7   |  L2  |   91.304348%   |\n",
      "|  7   |L-inf |   89.855072%   |\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Finally, call the main function\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions here:\n",
    "\n",
    "1. How could having a larger dataset influence the performance of KNN?\n",
    "\n",
    "2. Tabulate your results from `main()` in the table provided.\n",
    "\n",
    "3. Finally, mention the best K and the norm combination you have settled upon and report the accuracy on the test set using that combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. KNN 对于大数据量的样本比哦阿羡比较差，因为中间主要步骤涉及到两两比较，如不优化会有 $O(n^2)$ 级别的复杂度.\n",
    "2. \n",
    "```\n",
    "<<<<VALIDATION DATA PREDICTIONS>>>>\n",
    "--------------------------------\n",
    "|  K   | Norm |  Accuracy(%)   |\n",
    "|  3   |  L1  |   94.000000%   |\n",
    "|  3   |  L2  |   95.000000%   |\n",
    "|  3   |L-inf |   94.000000%   |\n",
    "--------------------------------\n",
    "|  5   |  L1  |   94.000000%   |\n",
    "|  5   |  L2  |   93.000000%   |\n",
    "|  5   |L-inf |   94.000000%   |\n",
    "--------------------------------\n",
    "|  7   |  L1  |   93.000000%   |\n",
    "|  7   |  L2  |   92.000000%   |\n",
    "|  7   |L-inf |   93.000000%   |\n",
    "--------------------------------\n",
    "<<<<TEST DATA PREDICTIONS>>>>\n",
    "--------------------------------\n",
    "|  K   | Norm |  Accuracy(%)   |\n",
    "|  3   |  L1  |   88.405797%   |\n",
    "|  3   |  L2  |   88.405797%   |\n",
    "|  3   |L-inf |   89.855072%   |\n",
    "--------------------------------\n",
    "|  5   |  L1  |   91.304348%   |\n",
    "|  5   |  L2  |   89.855072%   |\n",
    "|  5   |L-inf |   89.855072%   |\n",
    "...\n",
    "|  7   |  L1  |   89.855072%   |\n",
    "|  7   |  L2  |   91.304348%   |\n",
    "|  7   |L-inf |   89.855072%   |\n",
    "--------------------------------\n",
    "```\n",
    "3. 对于 X_val, 取 K = 3, Norm = L2; 对于 X_test, 取 K = 5, Norm = L1. (K = 7, Norm = L1 也有相同的结果，但是其计算复杂度大于 K = 5)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
