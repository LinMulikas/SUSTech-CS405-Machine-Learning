{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building file list...\n",
      "3826 positive files and 2000 negative files found.\n",
      "\n",
      "Converting images to BGR color space and extracting HOG features from channel(s) 0, 1, 2.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert process: 100%|██████████| 5826/5826 [00:03<00:00, 1912.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted from 5826 files in 3.1 seconds\n",
      "\n",
      "Instantiate scaler and scale features.\n",
      "\n",
      "Shuffling samples into training, cross-validation, and test sets.\n",
      "\n",
      "Loading sample data.\n",
      "Training Phase.\n",
      "\n",
      "Validation Phase.\n",
      "\n",
      "Validation Accuracy:  0.9339055793991416\n",
      "Validation Precision:  0.9163398692810457\n",
      "Validation Recall:  0.9817927170868347\n",
      "Validation F-1 Score:  0.9479377958079784\n",
      "Testing Phase.\n",
      "\n",
      "Testing Accuracy:  0.9450171821305842\n",
      "Testing Precision:  0.9267015706806283\n",
      "Testing Recall:  0.9888268156424581\n",
      "Testing F-1 Score:  0.9567567567567568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detect process: 100%|██████████| 38/38 [00:06<00:00,  5.95it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from train import processFiles, trainSVM\n",
    "from detector import Detector\n",
    "\n",
    "# Replace these with the directories containing your\n",
    "# positive and negative sample images, respectively.\n",
    "pos_dir = \"./samples/vehicles\"\n",
    "neg_dir = \"./samples/non-vehicles\"\n",
    "\n",
    "# Replace this with the path to your test video file.\n",
    "video_file = \"videos/test_video.mp4\"\n",
    "\n",
    "def example1():\n",
    "    \"\"\"\n",
    "    Train a classifier and run it on a video using default settings\n",
    "    without saving any files to disk.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract HOG features from images in the sample directories and return\n",
    "    # results and parameters in a dict.\n",
    "    feature_data = processFiles(pos_dir, neg_dir, recurse=True,\n",
    "        hog_features=True)\n",
    "\n",
    "    # Train SVM and return the classifier and parameters in a dict.\n",
    "    # This function takes the dict from processFiles() as an input arg.\n",
    "    classifier_data = trainSVM(feature_data=feature_data)\n",
    "\n",
    "    # Instantiate a Detector object and load the dict from trainSVM().\n",
    "    detector = Detector().loadClassifier(classifier_data=classifier_data)\n",
    "\n",
    "    # Open a VideoCapture object for the video file.\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    # Start the detector by supplying it with the VideoCapture object.\n",
    "    # At this point, the video will be displayed, with bounding boxes\n",
    "    # drawn around detected objects per the method detailed in README.md.\n",
    "    detector.detectVideo(video_capture=cap)\n",
    "\n",
    "def example2():\n",
    "    \"\"\"\n",
    "    Extract features from sample images and save to pickle file.\n",
    "    Load sample data to train classifier, then save classifier to pickle file.\n",
    "    Run the classifier on a video by loading the classifier file, and write\n",
    "    the resulting detection video to an avi file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract HOG features, color histogram features, and spatial features\n",
    "    # from sample images, then save the data to a pickle file. Note that if an\n",
    "    # output filepath isn't specified, a default timestamped filename will\n",
    "    # be generated.\n",
    "    feature_data_filename = \"feature_data.pkl\"\n",
    "    processFiles(pos_dir, neg_dir, recurse=True, hog_features=True,\n",
    "        hist_features=True, spatial_features=True, output_file=True,\n",
    "        output_filename=feature_data_filename)\n",
    "\n",
    "    # Load the pickle file produced by processFiles(), train the classifier,\n",
    "    # then save the classifier data to a pickle file.\n",
    "    classifier_data_filename = \"classifier_data.pkl\"\n",
    "    trainSVM(filepath=feature_data_filename, output_file=True,\n",
    "        output_filename=classifier_data_filename)\n",
    "\n",
    "    # Instantiate a detector and load the classifier pickle file.\n",
    "    detector = Detector().loadClassifier(filepath=classifier_data_filename)\n",
    "\n",
    "    # Open a VideoCapture object for the video file.\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    # Run the detector and save the resulting video to an avi file.\n",
    "    detector.detectVideo(video_capture=cap, write=True)\n",
    "\n",
    "\n",
    "def example3():\n",
    "    \"\"\"\n",
    "    Extract features, train the classifier, run the detector using a\n",
    "    variety of custom parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract features. Do not save to disk.\n",
    "    feature_data = processFiles(pos_dir, neg_dir, recurse=True,\n",
    "        color_space=\"yuv\", channels=[0, 2], hog_features=True,\n",
    "        hist_features=False, spatial_features=True, hog_lib=\"sk\",\n",
    "        size=(128, 64), hog_bins=11, pix_per_cell=(16, 8),\n",
    "        cells_per_block=(2,2), block_norm=\"L2\", transform_sqrt=False,\n",
    "        spatial_size=(64, 32))\n",
    "\n",
    "    # Train a classifier and save it to disk, then use the returned dict\n",
    "    # to instantiate and run a detector.\n",
    "    classifier_data = trainSVM(feature_data=feature_data, loss=\"squared_hinge\",\n",
    "        penalty=\"l2\", dual=False, fit_intercept=False, output_file=True,\n",
    "        output_filename=\"example_classifier.pkl\")\n",
    "\n",
    "    detector = Detector(init_size=(128,64), x_overlap=0.75, y_step=0.02,\n",
    "        x_range=(0.2, 0.85), y_range=(0.4, 0.9), scale=1.8)\n",
    "\n",
    "    detector.loadClassifier(classifier_data=classifier_data)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    detector.detectVideo(video_capture=cap, num_frames=5, threshold=100,\n",
    "        min_bbox=(50,50), draw_heatmap=False)\n",
    "\n",
    "def example4():\n",
    "    \"\"\"\n",
    "    Load an existing classifier and run it on a video with custom parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    detector = Detector(init_size=(64,64), x_overlap=0.3, y_step=0.015,\n",
    "        x_range=(0.1, 0.9), scale=1.4)\n",
    "    detector.loadClassifier(filepath=\"example_classifier.pkl\")\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    detector.detectVideo(video_capture=cap, num_frames=20, threshold=180,\n",
    "        draw_heatmap_size=0.4)\n",
    "\n",
    "def example5():\n",
    "    \"\"\"\n",
    "    Train a classifier and run on video using parameters that seemed to work\n",
    "    well for vehicle detection.\n",
    "    \"\"\"\n",
    "\n",
    "    feature_data = processFiles(pos_dir, neg_dir, recurse=True,\n",
    "        color_space=\"YCrCb\", channels=[0, 1, 2], hog_features=True,\n",
    "        hist_features=True, spatial_features=True, hog_lib=\"cv\",\n",
    "        size=(64,64), pix_per_cell=(8,8), cells_per_block=(2,2),\n",
    "        hog_bins=20, hist_bins=16, spatial_size=(20,20))\n",
    "\n",
    "    classifier_data = trainSVM(feature_data=feature_data, C=1000)\n",
    "\n",
    "    detector = Detector(init_size=(90,90), x_overlap=0.7, y_step=0.01,\n",
    "        x_range=(0.02, 0.98), y_range=(0.55, 0.89), scale=1.3)\n",
    "    detector.loadClassifier(classifier_data=classifier_data)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    detector.detectVideo(video_capture=cap, num_frames=9, threshold=120,\n",
    "        draw_heatmap_size=0.3)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example1()\n",
    "    #example2()\n",
    "    #example3()\n",
    "    #example4()\n",
    "    # example5()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
