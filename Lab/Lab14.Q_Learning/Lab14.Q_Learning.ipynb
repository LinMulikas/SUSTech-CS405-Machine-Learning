{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objective\" data-toc-modified-id=\"Objective-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objective</a></span></li><li><span><a href=\"#Introduction-for-Q-Learning\" data-toc-modified-id=\"Introduction-for-Q-Learning-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Introduction for Q-Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-Q-Learning?\" data-toc-modified-id=\"What-is-Q-Learning?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>What is Q-Learning?</a></span></li><li><span><a href=\"#Q-Function\" data-toc-modified-id=\"Q-Function-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Q-Function</a></span></li><li><span><a href=\"#Q-table\" data-toc-modified-id=\"Q-table-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Q-table</a></span></li><li><span><a href=\"#The-Q-Learning-algorithm\" data-toc-modified-id=\"The-Q-Learning-algorithm-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>The Q-Learning algorithm</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-1:-We-initialize-the-Q-Table\" data-toc-modified-id=\"Step-1:-We-initialize-the-Q-Table-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Step 1: We initialize the Q-Table</a></span></li><li><span><a href=\"#Step-2:-Choose-action-using-Epsilon-Greedy-Strategy\" data-toc-modified-id=\"Step-2:-Choose-action-using-Epsilon-Greedy-Strategy-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Step 2: Choose action using Epsilon Greedy Strategy</a></span></li><li><span><a href=\"#Step-3:-Perform-action-$A_t$,-gets-reward-$R_{t+1}-$and-next-state-$S_{t+1}$\" data-toc-modified-id=\"Step-3:-Perform-action-$A_t$,-gets-reward-$R_{t+1}-$and-next-state-$S_{t+1}$-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>Step 3: Perform action $A_t$, gets reward $R_{t+1} $and next state $S_{t+1}$</a></span></li><li><span><a href=\"#Step-4:-Update-$Q(S_t,-A_t)$\" data-toc-modified-id=\"Step-4:-Update-$Q(S_t,-A_t)$-2.4.4\"><span class=\"toc-item-num\">2.4.4&nbsp;&nbsp;</span>Step 4: Update $Q(S_t, A_t)$</a></span></li></ul></li><li><span><a href=\"#Off-policy-vs-On-policy\" data-toc-modified-id=\"Off-policy-vs-On-policy-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span><strong>Off-policy vs On-policy</strong></a></span></li></ul></li><li><span><a href=\"#Q-Learning-tutorials\" data-toc-modified-id=\"Q-Learning-tutorials-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Q-Learning tutorials</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q-Learning-with-FrozenLake-v1\" data-toc-modified-id=\"Q-Learning-with-FrozenLake-v1-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Q-Learning with FrozenLake-v1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Install-dependencies\" data-toc-modified-id=\"Install-dependencies-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Install dependencies</a></span></li><li><span><a href=\"#Import-the-packages\" data-toc-modified-id=\"Import-the-packages-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Import the packages</a></span></li></ul></li><li><span><a href=\"#Create-Frozen-Lake--environment\" data-toc-modified-id=\"Create-Frozen-Lake--environment-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Create Frozen Lake  environment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Understanding-the-FrozenLake-environment\" data-toc-modified-id=\"Understanding-the-FrozenLake-environment-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Understanding the FrozenLake environment</a></span></li><li><span><a href=\"#Create-and-Initialize-the-Q-table\" data-toc-modified-id=\"Create-and-Initialize-the-Q-table-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Create and Initialize the Q-table</a></span></li><li><span><a href=\"#Define-the-epsilon-greedy-policy\" data-toc-modified-id=\"Define-the-epsilon-greedy-policy-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Define the epsilon-greedy policy</a></span></li><li><span><a href=\"#Define-the-hyperparameters\" data-toc-modified-id=\"Define-the-hyperparameters-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Define the hyperparameters</a></span></li><li><span><a href=\"#Training-the-model\" data-toc-modified-id=\"Training-the-model-3.2.5\"><span class=\"toc-item-num\">3.2.5&nbsp;&nbsp;</span>Training the model</a></span></li><li><span><a href=\"#Tranined-Q-Learning-table\" data-toc-modified-id=\"Tranined-Q-Learning-table-3.2.6\"><span class=\"toc-item-num\">3.2.6&nbsp;&nbsp;</span>Tranined Q-Learning table</a></span></li><li><span><a href=\"#Model-evaluation\" data-toc-modified-id=\"Model-evaluation-3.2.7\"><span class=\"toc-item-num\">3.2.7&nbsp;&nbsp;</span>Model evaluation</a></span></li></ul></li><li><span><a href=\"#Visualizing-the-results\" data-toc-modified-id=\"Visualizing-the-results-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Visualizing the results</a></span></li></ul></li><li><span><a href=\"#LAB-Assignment\" data-toc-modified-id=\"LAB-Assignment-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>LAB Assignment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Exercise-(-Q-Learning-with-Taxi-v3-ðŸš•)-(100-Points)\" data-toc-modified-id=\"Exercise-(-Q-Learning-with-Taxi-v3-ðŸš•)-(100-Points)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Exercise ( Q-Learning with Taxi-v3 ðŸš•) (100 Points)</a></span></li><li><span><a href=\"#Step-0-Import-the-packages\" data-toc-modified-id=\"Step-0-Import-the-packages-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Step 0 Import the packages</a></span></li><li><span><a href=\"#Step-1-Create-Taxi-v3-ðŸš•--environment\" data-toc-modified-id=\"Step-1-Create-Taxi-v3-ðŸš•--environment-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Step 1 Create Taxi-v3 ðŸš•  environment</a></span></li><li><span><a href=\"#Step-2--Create-the-Q-table-and-initialize-it\" data-toc-modified-id=\"Step-2--Create-the-Q-table-and-initialize-it-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Step 2  Create the Q-table and initialize it</a></span></li><li><span><a href=\"#Step-3-Configure-the-hyperparameters\" data-toc-modified-id=\"Step-3-Configure-the-hyperparameters-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Step 3 Configure the hyperparameters</a></span></li><li><span><a href=\"#Step-4-Q-Learning-algorithm\" data-toc-modified-id=\"Step-4-Q-Learning-algorithm-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Step 4 Q Learning algorithm</a></span></li><li><span><a href=\"#Step-5-Model-evaluation\" data-toc-modified-id=\"Step-5-Model-evaluation-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Step 5 Model evaluation</a></span></li><li><span><a href=\"#Step-6-Visualizing-the-results\" data-toc-modified-id=\"Step-6-Visualizing-the-results-4.8\"><span class=\"toc-item-num\">4.8&nbsp;&nbsp;</span>Step 6 Visualizing the results</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JZkkkRezF2h"
   },
   "source": [
    "# LAB14 tutorial for Machine Learning <br > Q-Learning\n",
    "> The document description are designed by JIa Yanhong in 2022. Nov. 23th\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "- Understand the theory of Q-Learning\n",
    "- Be able to code from scratch a Q-Learning agent.\n",
    "- Be able to use **Gym**, the environment library.\n",
    "- Complete the LAB assignment and submit it to BB or sakai.\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction for Q-Learning\n",
    "### What is Q-Learning?\n",
    "\n",
    "Q-Learning is an **off-policy value-based method that uses a TD approach to train its action-value function:**\n",
    "\n",
    "- **Off-policy**:Using a different policy for acting and updating.\n",
    "- **Value-based method**: finds the optimal policy indirectly by training a value or action-value function that will tell us the value of each state or each state-action pair.\n",
    "- **Uses a TD approach**: updates its action-value function at each step instead of at the end of the episode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Q-Function\n",
    "\n",
    "**Q-Learning is the algorithm we use to train our Q-Function**, an **action-value function** that determines the value of being at a particular state and taking a specific action at that state.\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Bellman_Equation_63ce32c644-166962529879935.png\" alt=\"Bellman Equation\" width=600 /></div>\n",
    "\n",
    "Given a state and action, our Q Function outputs a state-action value (also called Q-value)\n",
    "\n",
    "The **Q comes from \"the Quality\" of that action at that state.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Q-table\n",
    "\n",
    "Internally, our Q-function has **a Q-table, a table where each cell corresponds to a state-action value pair value.** Think of this Q-table as **the memory or cheat sheet of our Q-function.**\n",
    "\n",
    "If we take this maze example:\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Maze-1.jpg\" alt=\"Maze example \" width=400 /></div>\n",
    "\n",
    "The Q-Table is initialized. That's why all values are = 0. This table **contains, for each state, the four state-action values.**\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Maze-2.jpg\" alt=\"Maze example\"width=600 /></div>\n",
    "\n",
    "Here we see that the **state-action value of the initial state and going up is 0:**\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Maze-3.jpg\" alt=\"Maze example\" width=600 /></div>\n",
    "\n",
    "Therefore, Q-function contains a Q-table **that has the value of each-state action pair.** And given a state and action, **our Q-Function will search inside its Q-table to output the value.**\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-function-2.jpg\" alt=\"Q-function\" width=600 /></div>\n",
    "\n",
    "\n",
    "\n",
    "Given a state and action pair, our Q-function will search inside its Q-table to output the state-action pair value (the Q value).\n",
    "\n",
    "\n",
    "\n",
    "If we recap, *Q-Learning* **is the RL algorithm that:**\n",
    "\n",
    "- Trains *Q-Function* (an **action-value function**) which internally is a *Q-table* **that contains all the state-action pair values.**\n",
    "- Given a state and action, our Q-Function **will search into its Q-table the corresponding value.**\n",
    "- When the training is done, **we have an optimal Q-function, which means we have optimal Q-Table.**\n",
    "- And if we **have an optimal Q-function**, we **have an optimal policy** since we **know for each state what is the best action to take.**\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/link-value-policy.jpg\" alt=\"Link value policy\"width=600 /></div>\n",
    "\n",
    "But, in the beginning, **our Q-Table is useless since it gives arbitrary values for each state-action pair** (most of the time, we initialize the Q-Table to 0 values). But, as we'll **explore the environment and update our Q-Table, it will give us better and better approximations.**\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-learning-1.jpg\" alt=\"Q-learning\"width=600 /></div>\n",
    "\n",
    "We see here that with the training, our Q-Table is better since, thanks to it, we can know the value of each state-action pair.\n",
    "\n",
    "So now that we understand what Q-Learning, Q-Function, and Q-Table are, **let's dive deeper into the Q-Learning algorithm**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Q-Learning algorithm\n",
    "\n",
    "**The Q-Learning algorithm** flow is as follows:\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q_Learning_Process_134331efc1.png\" alt=\"Q-Learning Process \" width=300 /></div>\n",
    "\n",
    "Here is the Q-Learning pseudocode:\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/image-20221128171006334.png\" alt=\"image-20221128171006334 \"  width=600 /></div>\n",
    "\n",
    "\n",
    "\n",
    "#### Step 1: We initialize the Q-Table\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-learning-3.jpg\" alt=\"Q-learning \"  width=600 /></div>\n",
    "\n",
    "We need to initialize the Q-Table for each state-action pair. **Most of the time, we initialize with values of 0.**\n",
    "\n",
    "#### Step 2: Choose action using Epsilon Greedy Strategy\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-learning-4.jpg\" alt=\"Q-learning\"  width=600 /></div>\n",
    "\n",
    "Epsilon Greedy Strategy is a policy that handles the exploration/exploitation trade-off.\n",
    "\n",
    "The idea is that we define epsilon É› = 1.0:\n",
    "\n",
    "- *With probability 1 â€” É›* : we do **exploitation** (aka our agent selects the action with the highest state-action pair value).\n",
    "- With probability É›: **we do exploration** (trying random action).\n",
    "\n",
    "At the beginning of the training, **the probability of doing exploration will be huge since É› is very high, so most of the time, we'll explore.** But as the training goes on, and consequently our **Q-Table gets better and better in its estimations, we progressively reduce the epsilon value** since we will need less and less exploration and more exploitation.\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-learning-5.jpg\" alt=\"Q-learning \" width=400 /></div>\n",
    "\n",
    "#### Step 3: Perform action $A_t$, gets reward $R_{t+1} $and next state $S_{t+1}$\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-learning-6.jpg\" alt=\"Q-learning \" width=600 /></div>\n",
    "\n",
    "#### Step 4: Update $Q(S_t, A_t)$\n",
    "\n",
    "Remember that in TD Learning, we update our policy or value function (depending on the RL method we choose) **after one step of the interaction.**\n",
    "\n",
    "To produce our TD target, **we used the immediate reward R_{t+1}\\*R\\**t\\*+1 plus the discounted value of the next state best state-action pair** (we call that bootstrap).\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-learning-7.jpg\" alt=\"Q-learning \" width=400 /></div>\n",
    "\n",
    "Therefore, our $Q(S_t, A_t)$ **update formula goes like this:**\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-learning-8.jpg\" alt=\"Q-learning \" width=400 /></div>\n",
    "\n",
    "To get the **best next-state-action pair value**, we use a greedy policy to select the next best action.\n",
    "\n",
    "**Note that this is not an epsilon greedy policy, this will always take the action with the highest state-action value.**\n",
    "\n",
    "**It's why we say that this is an off-policy algorithm.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Off-policy vs On-policy**\n",
    "\n",
    "<div  align=\"center\"> <img src=\"images/off-on-4.jpg\" alt=\"Off-on policy \" style=\"zoom:67%;\"  width=900 /></div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning tutorials\n",
    "Two Q-Learning tutorials, one for us to do together and one for Assignment. The gym environment of the two tutorials is as follows:\n",
    "ðŸŽ® Environments: \n",
    "- [FrozenLake-v1](https://www.gymlibrary.dev/environments/toy_text/frozen_lake/)\n",
    "- [Taxi-v3](https://www.gymlibrary.dev/environments/toy_text/taxi/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning with FrozenLake-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YA8eccSjzTkm"
   },
   "source": [
    "#### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qy__wzWWq1Ip"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "! pip install gym==0.24\n",
    "! pip install pygame\n",
    "! pip install numpy\n",
    "! pip install imageio imageio_ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PapFtBBzW3G"
   },
   "source": [
    "#### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWkA0eXLq52V",
    "outputId": "a1a9e7d0-ad83-4fcf-9b2f-f72d7a168ec0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import imageio\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "868LWxur0OGI"
   },
   "source": [
    "### Create Frozen Lake  environment \n",
    "We're going to train our Q-Learning agent **to navigate from the starting state (S) to the goal state (G) by walking only on frozen tiles (F) and avoid holes (H)**.\n",
    "\n",
    "We can have two sizes of environment:\n",
    "- `map_name=\"4x4\"`: a 4x4 grid version\n",
    "- `map_name=\"8x8\"`: a 8x8 grid version\n",
    "\n",
    "\n",
    "The environment has two modes:\n",
    "- `is_slippery=False`: The agent always move in the intended direction due to the non-slippery nature of the frozen lake.\n",
    "- `is_slippery=True`: The agent may not always move in the intended direction due to the slippery nature of the frozen lake (stochastic).\n",
    "\n",
    "You can also custom your own grid using:\n",
    "\n",
    "```python\n",
    "desc=[\"SFFF\", \"FHFH\", \"FFFH\", \"HFFG\"]\n",
    "gym.make('FrozenLake-v1', desc=desc, is_slippery=True)\n",
    "```\n",
    "\n",
    "but we'll use the default environment for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ho0clcOHrBlm"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the FrozenLake-v1 environment using 4x4 map and non-slippery version\n",
    "env = gym.make(\"FrozenLake-v1\",map_name=\"4x4\",is_slippery=False)\n",
    "img = env.render(mode='rgb_array')\n",
    "fig = plt.figure('show picture')\n",
    "\n",
    "\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.imshow(img)\n",
    "# ax.set_title(\"Taxi-v3\")#ç»™å›¾ç‰‡åŠ titile\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off') # ä¸æ˜¾ç¤ºåˆ»åº¦\n",
    "# plt.title(\"Taxi-v3\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFwhmxg80WkH"
   },
   "source": [
    "#### Understanding the FrozenLake environment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQtUaOEJrDVf",
    "outputId": "525f9f4e-ddb8-4e95-e059-2241fcee4c4a"
   },
   "outputs": [],
   "source": [
    "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
    "print(\"Observation Space\", env.observation_space)\n",
    "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see with `Observation Space Shape Discrete(16)` that the observation is a value representing the **agentâ€™s current position as current_row * nrows + current_col (where both the row and col start at 0)**. \n",
    "\n",
    "For example, the goal position in the 4x4 map can be calculated as follows: 3 * 4 + 3 = 15. The number of possible observations is dependent on the size of the map. **For example, the 4x4 map has 16 possible observations.**\n",
    "\n",
    "\n",
    "For instance, at this state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fE_JTjGrF-B",
    "outputId": "184e69e2-67e9-4ba5-b906-49b1bef3fd3c"
   },
   "outputs": [],
   "source": [
    "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
    "print(\"Action Space Shape\", env.action_space.n)\n",
    "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action space (the set of possible actions the agent can take) is discrete with 4 actions available ðŸŽ®:\n",
    "- 0: GO LEFT\n",
    "- 1: GO DOWN\n",
    "- 2: GO RIGHT\n",
    "- 3: GO UP\n",
    "\n",
    "Reward function ðŸ’°:\n",
    "- Reach goal: +1\n",
    "- Reach hole: 0\n",
    "- Reach frozen: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "badxmLJg0i6Z"
   },
   "source": [
    "#### Create and Initialize the Q-table\n",
    "\n",
    "It's time to initialize our Q-table! To know how many rows (states) and columns (actions) to use, we need to know the action and observation space. OpenAI Gym provides us a way to do that: `env.action_space.n` and `env.observation_space.n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2m0z54AfrJVj",
    "outputId": "6a885a98-0498-4c45-8e85-957886ed312c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  16  possible states\n",
      "There are  4  possible actions\n"
     ]
    }
   ],
   "source": [
    "state_space = env.observation_space.n\n",
    "print(\"There are \", state_space, \" possible states\")\n",
    "\n",
    "action_space = env.action_space.n\n",
    "print(\"There are \", action_space, \" possible actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rCddoOXM3UQH"
   },
   "outputs": [],
   "source": [
    "# Let's create our Qtable of size (state_space, action_space) and initialized each values at 0 using np.zeros\n",
    "def initialize_q_table(state_space, action_space):\n",
    "  Qtable = np.zeros((state_space, action_space))\n",
    "  return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9YfvrqRt3jdR"
   },
   "outputs": [],
   "source": [
    "Qtable_frozenlake = initialize_q_table(state_space, action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFeeieaA0mQ_"
   },
   "source": [
    "#### Define the epsilon-greedy policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Pe3nPqOQrYXi"
   },
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
    "  # Randomly generate a number between 0 and 1\n",
    "  random_int = random.uniform(0,1)\n",
    "  # if random_int > greater than epsilon --> exploitation\n",
    "  if random_int > epsilon:\n",
    "    # Take the action with the highest value given a state\n",
    "    # np.argmax can be useful here\n",
    "    action = np.argmax(Qtable[state])\n",
    "  # else --> exploration\n",
    "  else:\n",
    "    action = env.action_space.sample()\n",
    "  \n",
    "  return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AStP0Cwf0vjF"
   },
   "source": [
    "#### Define the hyperparameters\n",
    "The exploration related hyperparamters are some of the most important ones. \n",
    "\n",
    "- We need to make sure that our agent **explores enough the state space** in order to learn a good value approximation, in order to do that we need to have progressive decay of the epsilon.\n",
    "- If you decrease too fast epsilon (too high decay_rate), **you take the risk that your agent is stuck**, since your agent didn't explore enough the state space and hence can't solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Y1tWn0tycWZ1"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_training_episodes = 10000  # Total training episodes\n",
    "learning_rate = 0.7          # Learning rate\n",
    "\n",
    "# Evaluation parameters\n",
    "n_eval_episodes = 100        # Total number of test episodes\n",
    "\n",
    "# Environment parameters\n",
    "env_id = \"FrozenLake-v1\"     # Name of the environment\n",
    "max_steps = 99               # Max steps per episode\n",
    "gamma = 0.95                 # Discounting rate\n",
    "eval_seed = []               # The evaluation seed of the environment\n",
    "\n",
    "# Exploration parameters\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.05            # Minimum exploration probability \n",
    "decay_rate = 0.0005            # Exponential decay rate for exploration prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bL4oWIJ800M6"
   },
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "paOynXy3aoJW"
   },
   "outputs": [],
   "source": [
    "def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n",
    "  bar = tqdm.tqdm(total=n_training_episodes)\n",
    "  for episode in range(n_training_episodes):\n",
    "    # Reduce epsilon (because we need less and less exploration)\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "    # Reset the environment\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "\n",
    "    # repeat\n",
    "    for step in range(max_steps):\n",
    "      # Choose the action At using epsilon greedy policy\n",
    "      action = epsilon_greedy_policy(Qtable, state, epsilon)\n",
    "\n",
    "      # Take action At and observe Rt+1 and St+1\n",
    "      # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "      new_state, reward, done, info = env.step(action)\n",
    "\n",
    "      # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "      score = learning_rate * (reward + gamma * np.max(Qtable[new_state]) - Qtable[state][action]) \n",
    "      \n",
    "      if (score != 0):\n",
    "        Qtable[state][action] += score\n",
    "\n",
    "\n",
    "      # If done, finish the episode\n",
    "      if done:\n",
    "        break\n",
    "      \n",
    "      # Our state is the new state\n",
    "      state = new_state\n",
    "    bar.update()\n",
    "  return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "28e11fb654d24ef68a72d29ab062b926",
      "78f924df828046f5b093cf927260960a",
      "e402dfe3038444718c40ba487ee5a2fe",
      "7907716bab2e4ea3a86f0b80303c089a",
      "9921542e63864e0cab7b3a8780ec88a9",
      "45439de478d741698e095508be038474",
      "59a7711f82804a78b11aefc765e81362",
      "c9aa7491673046b1a6cab9f4ef1e1594",
      "edeeb0c041e74af48eceec05203cdc57",
      "362065e4131142c4872b59dab7430775",
      "b02a41ef6745420f989aba9c357a983f"
     ]
    },
    "id": "DPBxfjJdTCOH",
    "outputId": "1211b0d1-e57b-478c-f9c2-a6d85d9ed290"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:02<00:00, 4759.46it/s]\n"
     ]
    }
   ],
   "source": [
    "Qtable_frozenlake = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable_frozenlake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZE71JB7b1BiI"
   },
   "source": [
    "#### Tranined Q-Learning table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "me3KBqV4rqd-",
    "outputId": "f086891c-9b04-479e-ad4f-9aa65289a714"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73509189, 0.77378094, 0.77378094, 0.73509189],\n",
       "       [0.73509189, 0.        , 0.81450625, 0.77378094],\n",
       "       [0.77378094, 0.857375  , 0.77378094, 0.81450625],\n",
       "       [0.81450625, 0.        , 0.77378094, 0.77378094],\n",
       "       [0.77378094, 0.81450625, 0.        , 0.73509189],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.9025    , 0.        , 0.81450625],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.81450625, 0.        , 0.857375  , 0.77378094],\n",
       "       [0.81450625, 0.9025    , 0.9025    , 0.        ],\n",
       "       [0.857375  , 0.95      , 0.        , 0.857375  ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.9025    , 0.95      , 0.857375  ],\n",
       "       [0.9025    , 0.95      , 1.        , 0.9025    ],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qtable_frozenlake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttMwujJ31Lez"
   },
   "source": [
    "#### Model evaluation\n",
    "- Normally you should have mean reward of 1.0\n",
    "- It's relatively easy since the state space is really small (16). What you can try to do is [to replace with the slippery version](https://www.gymlibrary.ml/environments/toy_text/frozen_lake/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNl0_JO2cbkm"
   },
   "outputs": [],
   "source": [
    "def evaluate_agent(env, max_steps, n_eval_episodes, Q, seed):\n",
    "  \"\"\"\n",
    "  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n",
    "  :param env: The evaluation environment\n",
    "  :param n_eval_episodes: Number of episode to evaluate the agent\n",
    "  :param Q: The Q-table\n",
    "  :param seed: The evaluation seed array (for taxi-v3)\n",
    "  \"\"\"\n",
    "  episode_rewards = []\n",
    "  for episode in range(n_eval_episodes):\n",
    "    if seed:\n",
    "      state = env.reset(seed=seed[episode])\n",
    "    else:\n",
    "      state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    total_rewards_ep = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "      # Take the action (index) that have the maximum expected future reward given that state\n",
    "      action = np.argmax(Q[state][:])\n",
    "      new_state, reward, done, info = env.step(action)\n",
    "      total_rewards_ep += reward\n",
    "        \n",
    "      if done:\n",
    "        break\n",
    "      state = new_state\n",
    "    episode_rewards.append(total_rewards_ep)\n",
    "  mean_reward = np.mean(episode_rewards)\n",
    "  std_reward = np.std(episode_rewards)\n",
    "\n",
    "  return mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fAgB7s0HEFMm",
    "outputId": "0c006df2-2aad-46cb-f13f-0a893eeb00f0"
   },
   "outputs": [],
   "source": [
    "# Evaluate our Agent\n",
    "mean_reward, std_reward = evaluate_agent(env, max_steps, n_eval_episodes, Qtable_frozenlake, eval_seed)\n",
    "print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQoX2Iyo1OyC"
   },
   "source": [
    "### Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-N7tJXVHr3VJ"
   },
   "outputs": [],
   "source": [
    "def record_video(env, Qtable, out_directory, fps=1):\n",
    "  images = []  \n",
    "  done = False\n",
    "  \n",
    "  state = env.reset(seed=random.randint(0,500))\n",
    "  #state = env.reset()\n",
    "  img = env.render(mode='rgb_array')\n",
    "  images.append(img)\n",
    "  while not done:\n",
    "    # Take the action (index) that have the maximum expected future reward given that state\n",
    "    action = np.argmax(Qtable[state][:])\n",
    "    state, reward, done, info = env.step(action) # We directly put next_state = state for recording logic\n",
    "    img = env.render(mode='rgb_array')\n",
    "    images.append(img)\n",
    "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-JGGxzi3V8Y"
   },
   "source": [
    "Saving animated file as gif with 1 frame per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLw1MCIhsuX8"
   },
   "outputs": [],
   "source": [
    "video_path=\"replay.gif\"\n",
    "video_fps=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lg3BXlFEsTCN"
   },
   "outputs": [],
   "source": [
    "record_video(env, Qtable_frozenlake, video_path, video_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "dl7O7de11kbZ",
    "outputId": "28ec5ddc-c2f7-441c-cb9b-2c07f98fccba"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('replay.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB Assignment\n",
    "Please finish the **Exercise** and answer **Questions**.\n",
    "### Exercise ( Q-Learning with Taxi-v3 ðŸš•) (100 Points)\n",
    "\n",
    "In this exercise, you should complete the Q-learning algorithm using the Taxi-v3 environment in the gym\n",
    "\n",
    "In Taxi-v3 ðŸš•, there are four designated locations in the grid world indicated by R(ed), G(reen), Y(ellow), and B(lue). When the episode starts, the taxi starts off at a random square and the passenger is at a random location. The taxi drives to the passengerâ€™s location, picks up the passenger, drives to the passengerâ€™s destination (another one of the four specified locations), and then drops off the passenger. Once the passenger is dropped off, the episode ends.\n",
    "<div align=\"center\"><img src=\"images/image-20220805133926061.png\" alt=\"image-20220805133926061\" style=\"zoom:80%;\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PapFtBBzW3G"
   },
   "source": [
    "### Step 0 Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWkA0eXLq52V",
    "outputId": "a1a9e7d0-ad83-4fcf-9b2f-f72d7a168ec0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import imageio\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1 Create Taxi-v3 ðŸš•  environment \n",
    "Using the API imported from gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Taxi-v3')\n",
    "img = env.render(mode='rgb_array')\n",
    "fig = plt.figure('show picture')\n",
    "\n",
    "\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.imshow(img)\n",
    "# ax.set_title(\"Taxi-v3\")#ç»™å›¾ç‰‡åŠ titile\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off') # ä¸æ˜¾ç¤ºåˆ»åº¦\n",
    "# plt.title(\"Taxi-v3\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBOaXgtsrmtT"
   },
   "source": [
    "There are **500 discrete states since there are 25 taxi positions, 5 possible locations of the passenger** (including the case when the passenger is in the taxi), and **4 destination locations.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TPNaGSZrgqA",
    "outputId": "8aa9b617-8bdd-4817-ebc2-8f97d32e9634"
   },
   "outputs": [],
   "source": [
    "state_space = env.observation_space.n\n",
    "print(\"There are \", state_space, \" possible states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdeeZuokrhit",
    "outputId": "eae26ab9-5f2f-40b6-f6ee-a6bc12d57c5c"
   },
   "outputs": [],
   "source": [
    "action_space = env.action_space.n\n",
    "print(\"There are \", action_space, \" possible actions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1r50Advrh5Q"
   },
   "source": [
    "The action space (the set of possible actions the agent can take) is discrete with **6 actions available ðŸŽ®**:\n",
    "- 0: move south\n",
    "- 1: move north\n",
    "- 2: move east\n",
    "- 3: move west\n",
    "- 4: pickup passenger\n",
    "- 5: drop off passenger\n",
    "\n",
    "Reward function ðŸ’°:\n",
    "- -1 per step unless other reward is triggered.\n",
    "- +20 delivering passenger.\n",
    "- -10 executing â€œpickupâ€ and â€œdrop-offâ€ actions illegally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 2  Create the Q-table and initialize it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the gym api to fetch the dimension of action space and state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = env.action_space.n\n",
    "state_space = env.observation_space.n\n",
    "\n",
    "# Please complete this initialization in this line\n",
    "Q_table = initialize_q_table(state_space, action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 3 Configure the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 100000        # ä¸€å…±çŽ©å¤šå°‘å±€æ¸¸æˆ\n",
    "total_test_episodes = 100     # æµ‹è¯•ä¸­ä¸€å…±èµ°å‡ æ­¥\n",
    "max_steps = 99                # Max steps per episode æ¯ä¸€å±€æ¸¸æˆæœ€å¤šèµ°å‡ æ­¥\n",
    "\n",
    "learning_rate = 0.5           # Learning rate\n",
    "gamma = 0.95                 # Discounting rate\n",
    "\n",
    "# Exploration parameters\n",
    "epsilon = 1.0                 # Exploration rate\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.05           # Minimum exploration probability \n",
    "decay_rate = 0.008            # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "test_seed = [16,54,165,177,191,191,120,80,149,178,48,38,6,125,174,73,50,172,100,148,146,6,25,40,68,148,49,167,9,97,164,176,61,7,54,55,\n",
    " 161,131,184,51,170,12,120,113,95,126,51,98,36,135,54,82,45,95,89,59,95,124,9,113,58,85,51,134,121,169,105,21,30,11,50,65,12,43,82,145,152,97,106,55,31,85,38,\n",
    " 112,102,168,123,97,21,83,158,26,80,63,5,81,32,11,28,148] # Evaluation seed, this ensures that all classmates agents are trained on the same taxi starting position\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 4 Q Learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The formula of Q table update(Bellman equation)\n",
    "    ![Bellman equation](https://raw.githubusercontent.com/hanruihua/NoteBook/master/AI-Note/equation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = tqdm.tqdm(total=total_episodes)\n",
    "sample_rewards = []\n",
    "\n",
    "for episode in range(total_episodes):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    sample_reward = 0 \n",
    "    while True:\n",
    "        #TODO: Please complete this action selection in this line via the maximum value\n",
    "        action = epsilon_greedy_policy(Q_table, state, epsilon)\n",
    "        \n",
    "        # TODO:fetech the new state and reward by gym API\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        # Calculate the reward of this episode\n",
    "        sample_reward += reward\n",
    "    \n",
    "        \n",
    "        # TODO: Update the Q table \n",
    "        # Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "        Q_table[state, action] = Q_table[state, action] + learning_rate * (reward + gamma * np.max(Q_table[new_state]) - Q_table[state, action]) \n",
    "        \n",
    "        # Update the state\n",
    "        state = new_state\n",
    "        \n",
    "        #store the episode reward\n",
    "        if done == True:\n",
    "            sample_rewards.append(sample_reward)\n",
    "            break\n",
    "        \n",
    "    # Reduced exploration probability (due to decreasing uncertainty)\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)         \n",
    "    # print the average reward over 1000 episodes\n",
    "    if episode%1000 == 0:\n",
    "        mean_reward = np.mean(sample_rewards)\n",
    "        sample_rewards = []\n",
    "        #print(str(episode)+\": average reward:\" + str(mean_reward))\n",
    "        bar.set_description(str(episode)+\": average reward:\" + str(mean_reward))\n",
    "    bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 5 Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps=5\n",
    "bar = tqdm.tqdm(total=total_test_episodes)\n",
    "env.reset()\n",
    "rewards=[]\n",
    "images = [] \n",
    "for episode in range(total_test_episodes):\n",
    "    state = env.reset(seed=test_seed[episode])\n",
    "    step = 0\n",
    "    done =False\n",
    "    total_rewards = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        img = env.render(mode='rgb_array')\n",
    "        images.append(img)\n",
    "        #TODO:action selection\n",
    "        action = np.argmax(Q_table[state][:])\n",
    "        #TODO:fetech the new state and reward by gym API\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        total_rewards += reward\n",
    "        if done:\n",
    "            rewards.append(total_rewards)\n",
    "            break\n",
    "        \n",
    "        state = new_state\n",
    "     \n",
    "env.close()\n",
    "mean_reward = np.mean(rewards)\n",
    "std_reward = np.std(rewards)\n",
    "print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "imageio.mimsave('taxi-v3.gif', [np.array(img) for i, img in enumerate(images)], fps=fps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQoX2Iyo1OyC"
   },
   "source": [
    "###  Step 6 Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path=\"taxi-v3.gif\"\n",
    "video_fps=5\n",
    "record_video(env, Q_table, video_path, video_fps)\n",
    "from IPython.display import Image\n",
    "Image('taxi-v3.gif')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:52:34) \n[Clang 12.0.0 ]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "28e11fb654d24ef68a72d29ab062b926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78f924df828046f5b093cf927260960a",
       "IPY_MODEL_e402dfe3038444718c40ba487ee5a2fe",
       "IPY_MODEL_7907716bab2e4ea3a86f0b80303c089a"
      ],
      "layout": "IPY_MODEL_9921542e63864e0cab7b3a8780ec88a9"
     }
    },
    "362065e4131142c4872b59dab7430775": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45439de478d741698e095508be038474": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59a7711f82804a78b11aefc765e81362": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78f924df828046f5b093cf927260960a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45439de478d741698e095508be038474",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_59a7711f82804a78b11aefc765e81362",
      "value": "100%"
     }
    },
    "7907716bab2e4ea3a86f0b80303c089a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_362065e4131142c4872b59dab7430775",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b02a41ef6745420f989aba9c357a983f",
      "value": " 10000/10000 [00:03&lt;00:00, 4132.18it/s]"
     }
    },
    "9921542e63864e0cab7b3a8780ec88a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b02a41ef6745420f989aba9c357a983f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9aa7491673046b1a6cab9f4ef1e1594": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e402dfe3038444718c40ba487ee5a2fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9aa7491673046b1a6cab9f4ef1e1594",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_edeeb0c041e74af48eceec05203cdc57",
      "value": 10000
     }
    },
    "edeeb0c041e74af48eceec05203cdc57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
