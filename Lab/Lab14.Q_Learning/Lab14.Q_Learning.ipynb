{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objective\" data-toc-modified-id=\"Objective-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objective</a></span></li><li><span><a href=\"#Introduction-for-Q-Learning\" data-toc-modified-id=\"Introduction-for-Q-Learning-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Introduction for Q-Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-Q-Learning?\" data-toc-modified-id=\"What-is-Q-Learning?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>What is Q-Learning?</a></span></li><li><span><a href=\"#Q-Function\" data-toc-modified-id=\"Q-Function-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Q-Function</a></span></li><li><span><a href=\"#Q-table\" data-toc-modified-id=\"Q-table-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Q-table</a></span></li><li><span><a href=\"#The-Q-Learning-algorithm\" data-toc-modified-id=\"The-Q-Learning-algorithm-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>The Q-Learning algorithm</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-1:-We-initialize-the-Q-Table\" data-toc-modified-id=\"Step-1:-We-initialize-the-Q-Table-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Step 1: We initialize the Q-Table</a></span></li><li><span><a href=\"#Step-2:-Choose-action-using-Epsilon-Greedy-Strategy\" data-toc-modified-id=\"Step-2:-Choose-action-using-Epsilon-Greedy-Strategy-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Step 2: Choose action using Epsilon Greedy Strategy</a></span></li><li><span><a href=\"#Step-3:-Perform-action-$A_t$,-gets-reward-$R_{t+1}-$and-next-state-$S_{t+1}$\" data-toc-modified-id=\"Step-3:-Perform-action-$A_t$,-gets-reward-$R_{t+1}-$and-next-state-$S_{t+1}$-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>Step 3: Perform action $A_t$, gets reward $R_{t+1} $and next state $S_{t+1}$</a></span></li><li><span><a href=\"#Step-4:-Update-$Q(S_t,-A_t)$\" data-toc-modified-id=\"Step-4:-Update-$Q(S_t,-A_t)$-2.4.4\"><span class=\"toc-item-num\">2.4.4&nbsp;&nbsp;</span>Step 4: Update $Q(S_t, A_t)$</a></span></li></ul></li><li><span><a href=\"#Off-policy-vs-On-policy\" data-toc-modified-id=\"Off-policy-vs-On-policy-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span><strong>Off-policy vs On-policy</strong></a></span></li></ul></li><li><span><a href=\"#Q-Learning-tutorials\" data-toc-modified-id=\"Q-Learning-tutorials-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Q-Learning tutorials</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q-Learning-with-FrozenLake-v1\" data-toc-modified-id=\"Q-Learning-with-FrozenLake-v1-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Q-Learning with FrozenLake-v1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Install-dependencies\" data-toc-modified-id=\"Install-dependencies-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Install dependencies</a></span></li><li><span><a href=\"#Import-the-packages\" data-toc-modified-id=\"Import-the-packages-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Import the packages</a></span></li></ul></li><li><span><a href=\"#Create-Frozen-Lake--environment\" data-toc-modified-id=\"Create-Frozen-Lake--environment-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Create Frozen Lake  environment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Understanding-the-FrozenLake-environment\" data-toc-modified-id=\"Understanding-the-FrozenLake-environment-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Understanding the FrozenLake environment</a></span></li><li><span><a href=\"#Create-and-Initialize-the-Q-table\" data-toc-modified-id=\"Create-and-Initialize-the-Q-table-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Create and Initialize the Q-table</a></span></li><li><span><a href=\"#Define-the-epsilon-greedy-policy\" data-toc-modified-id=\"Define-the-epsilon-greedy-policy-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Define the epsilon-greedy policy</a></span></li><li><span><a href=\"#Define-the-hyperparameters\" data-toc-modified-id=\"Define-the-hyperparameters-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Define the hyperparameters</a></span></li><li><span><a href=\"#Training-the-model\" data-toc-modified-id=\"Training-the-model-3.2.5\"><span class=\"toc-item-num\">3.2.5&nbsp;&nbsp;</span>Training the model</a></span></li><li><span><a href=\"#Tranined-Q-Learning-table\" data-toc-modified-id=\"Tranined-Q-Learning-table-3.2.6\"><span class=\"toc-item-num\">3.2.6&nbsp;&nbsp;</span>Tranined Q-Learning table</a></span></li><li><span><a href=\"#Model-evaluation\" data-toc-modified-id=\"Model-evaluation-3.2.7\"><span class=\"toc-item-num\">3.2.7&nbsp;&nbsp;</span>Model evaluation</a></span></li></ul></li><li><span><a href=\"#Visualizing-the-results\" data-toc-modified-id=\"Visualizing-the-results-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Visualizing the results</a></span></li></ul></li><li><span><a href=\"#LAB-Assignment\" data-toc-modified-id=\"LAB-Assignment-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>LAB Assignment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Exercise-(-Q-Learning-with-Taxi-v3-🚕)-(100-Points)\" data-toc-modified-id=\"Exercise-(-Q-Learning-with-Taxi-v3-🚕)-(100-Points)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Exercise ( Q-Learning with Taxi-v3 🚕) (100 Points)</a></span></li><li><span><a href=\"#Step-0-Import-the-packages\" data-toc-modified-id=\"Step-0-Import-the-packages-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Step 0 Import the packages</a></span></li><li><span><a href=\"#Step-1-Create-Taxi-v3-🚕--environment\" data-toc-modified-id=\"Step-1-Create-Taxi-v3-🚕--environment-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Step 1 Create Taxi-v3 🚕  environment</a></span></li><li><span><a href=\"#Step-2--Create-the-Q-table-and-initialize-it\" data-toc-modified-id=\"Step-2--Create-the-Q-table-and-initialize-it-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Step 2  Create the Q-table and initialize it</a></span></li><li><span><a href=\"#Step-3-Configure-the-hyperparameters\" data-toc-modified-id=\"Step-3-Configure-the-hyperparameters-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Step 3 Configure the hyperparameters</a></span></li><li><span><a href=\"#Step-4-Q-Learning-algorithm\" data-toc-modified-id=\"Step-4-Q-Learning-algorithm-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Step 4 Q Learning algorithm</a></span></li><li><span><a href=\"#Step-5-Model-evaluation\" data-toc-modified-id=\"Step-5-Model-evaluation-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Step 5 Model evaluation</a></span></li><li><span><a href=\"#Step-6-Visualizing-the-results\" data-toc-modified-id=\"Step-6-Visualizing-the-results-4.8\"><span class=\"toc-item-num\">4.8&nbsp;&nbsp;</span>Step 6 Visualizing the results</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JZkkkRezF2h"
   },
   "source": [
    "# LAB14 tutorial for Machine Learning <br > Q-Learning\n",
    "> The document description are designed by JIa Yanhong in 2022. Nov. 23th\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "- Understand the theory of Q-Learning\n",
    "- Be able to code from scratch a Q-Learning agent.\n",
    "- Be able to use **Gym**, the environment library.\n",
    "- Complete the LAB assignment and submit it to BB or sakai.\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction for Q-Learning\n",
    "### What is Q-Learning?\n",
    "\n",
    "Q-Learning is an **off-policy value-based method that uses a TD approach to train its action-value function:**\n",
    "\n",
    "- **Off-policy**:Using a different policy for acting and updating.\n",
    "- **Value-based method**: finds the optimal policy indirectly by training a value or action-value function that will tell us the value of each state or each state-action pair.\n",
    "- **Uses a TD approach**: updates its action-value function at each step instead of at the end of the episode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Q-Function\n",
    "\n",
    "**Q-Learning is the algorithm we use to train our Q-Function**, an **action-value function** that determines the value of being at a particular state and taking a specific action at that state.\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Bellman_Equation_63ce32c644-166962529879935.png\" alt=\"Bellman Equation\" width=600 /></div>\n",
    "\n",
    "Given a state and action, our Q Function outputs a state-action value (also called Q-value)\n",
    "\n",
    "The **Q comes from \"the Quality\" of that action at that state.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Q-table\n",
    "\n",
    "Internally, our Q-function has **a Q-table, a table where each cell corresponds to a state-action value pair value.** Think of this Q-table as **the memory or cheat sheet of our Q-function.**\n",
    "\n",
    "If we take this maze example:\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Maze-1.jpg\" alt=\"Maze example \" width=400 /></div>\n",
    "\n",
    "The Q-Table is initialized. That's why all values are = 0. This table **contains, for each state, the four state-action values.**\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Maze-2.jpg\" alt=\"Maze example\"width=600 /></div>\n",
    "\n",
    "Here we see that the **state-action value of the initial state and going up is 0:**\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Maze-3.jpg\" alt=\"Maze example\" width=600 /></div>\n",
    "\n",
    "Therefore, Q-function contains a Q-table **that has the value of each-state action pair.** And given a state and action, **our Q-Function will search inside its Q-table to output the value.**\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-function-2.jpg\" alt=\"Q-function\" width=600 /></div>\n",
    "\n",
    "\n",
    "\n",
    "Given a state and action pair, our Q-function will search inside its Q-table to output the state-action pair value (the Q value).\n",
    "\n",
    "\n",
    "\n",
    "If we recap, *Q-Learning* **is the RL algorithm that:**\n",
    "\n",
    "- Trains *Q-Function* (an **action-value function**) which internally is a *Q-table* **that contains all the state-action pair values.**\n",
    "- Given a state and action, our Q-Function **will search into its Q-table the corresponding value.**\n",
    "- When the training is done, **we have an optimal Q-function, which means we have optimal Q-Table.**\n",
    "- And if we **have an optimal Q-function**, we **have an optimal policy** since we **know for each state what is the best action to take.**\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/link-value-policy.jpg\" alt=\"Link value policy\"width=600 /></div>\n",
    "\n",
    "But, in the beginning, **our Q-Table is useless since it gives arbitrary values for each state-action pair** (most of the time, we initialize the Q-Table to 0 values). But, as we'll **explore the environment and update our Q-Table, it will give us better and better approximations.**\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-learning-1.jpg\" alt=\"Q-learning\"width=600 /></div>\n",
    "\n",
    "We see here that with the training, our Q-Table is better since, thanks to it, we can know the value of each state-action pair.\n",
    "\n",
    "So now that we understand what Q-Learning, Q-Function, and Q-Table are, **let's dive deeper into the Q-Learning algorithm**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Q-Learning algorithm\n",
    "\n",
    "**The Q-Learning algorithm** flow is as follows:\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q_Learning_Process_134331efc1.png\" alt=\"Q-Learning Process \" width=300 /></div>\n",
    "\n",
    "Here is the Q-Learning pseudocode:\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/image-20221128171006334.png\" alt=\"image-20221128171006334 \"  width=600 /></div>\n",
    "\n",
    "\n",
    "\n",
    "#### Step 1: We initialize the Q-Table\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-learning-3.jpg\" alt=\"Q-learning \"  width=600 /></div>\n",
    "\n",
    "We need to initialize the Q-Table for each state-action pair. **Most of the time, we initialize with values of 0.**\n",
    "\n",
    "#### Step 2: Choose action using Epsilon Greedy Strategy\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-learning-4.jpg\" alt=\"Q-learning\"  width=600 /></div>\n",
    "\n",
    "Epsilon Greedy Strategy is a policy that handles the exploration/exploitation trade-off.\n",
    "\n",
    "The idea is that we define epsilon ɛ = 1.0:\n",
    "\n",
    "- *With probability 1 — ɛ* : we do **exploitation** (aka our agent selects the action with the highest state-action pair value).\n",
    "- With probability ɛ: **we do exploration** (trying random action).\n",
    "\n",
    "At the beginning of the training, **the probability of doing exploration will be huge since ɛ is very high, so most of the time, we'll explore.** But as the training goes on, and consequently our **Q-Table gets better and better in its estimations, we progressively reduce the epsilon value** since we will need less and less exploration and more exploitation.\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-learning-5.jpg\" alt=\"Q-learning \" width=400 /></div>\n",
    "\n",
    "#### Step 3: Perform action $A_t$, gets reward $R_{t+1} $and next state $S_{t+1}$\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-learning-6.jpg\" alt=\"Q-learning \" width=600 /></div>\n",
    "\n",
    "#### Step 4: Update $Q(S_t, A_t)$\n",
    "\n",
    "Remember that in TD Learning, we update our policy or value function (depending on the RL method we choose) **after one step of the interaction.**\n",
    "\n",
    "To produce our TD target, **we used the immediate reward R_{t+1}\\*R\\**t\\*+1 plus the discounted value of the next state best state-action pair** (we call that bootstrap).\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-learning-7.jpg\" alt=\"Q-learning \" width=400 /></div>\n",
    "\n",
    "Therefore, our $Q(S_t, A_t)$ **update formula goes like this:**\n",
    "\n",
    "<div  align=\"center\"><img src=\"images/Q-learning-8.jpg\" alt=\"Q-learning \" width=400 /></div>\n",
    "\n",
    "To get the **best next-state-action pair value**, we use a greedy policy to select the next best action.\n",
    "\n",
    "**Note that this is not an epsilon greedy policy, this will always take the action with the highest state-action value.**\n",
    "\n",
    "**It's why we say that this is an off-policy algorithm.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Off-policy vs On-policy**\n",
    "\n",
    "<div  align=\"center\"> <img src=\"images/off-on-4.jpg\" alt=\"Off-on policy \" style=\"zoom:67%;\"  width=900 /></div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning tutorials\n",
    "Two Q-Learning tutorials, one for us to do together and one for Assignment. The gym environment of the two tutorials is as follows:\n",
    "🎮 Environments: \n",
    "- [FrozenLake-v1](https://www.gymlibrary.dev/environments/toy_text/frozen_lake/)\n",
    "- [Taxi-v3](https://www.gymlibrary.dev/environments/toy_text/taxi/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning with FrozenLake-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YA8eccSjzTkm"
   },
   "source": [
    "#### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qy__wzWWq1Ip"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "! pip install gym==0.24\n",
    "! pip install pygame\n",
    "! pip install numpy\n",
    "! pip install imageio imageio_ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PapFtBBzW3G"
   },
   "source": [
    "#### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWkA0eXLq52V",
    "outputId": "a1a9e7d0-ad83-4fcf-9b2f-f72d7a168ec0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import imageio\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "868LWxur0OGI"
   },
   "source": [
    "### Create Frozen Lake  environment \n",
    "We're going to train our Q-Learning agent **to navigate from the starting state (S) to the goal state (G) by walking only on frozen tiles (F) and avoid holes (H)**.\n",
    "\n",
    "We can have two sizes of environment:\n",
    "- `map_name=\"4x4\"`: a 4x4 grid version\n",
    "- `map_name=\"8x8\"`: a 8x8 grid version\n",
    "\n",
    "\n",
    "The environment has two modes:\n",
    "- `is_slippery=False`: The agent always move in the intended direction due to the non-slippery nature of the frozen lake.\n",
    "- `is_slippery=True`: The agent may not always move in the intended direction due to the slippery nature of the frozen lake (stochastic).\n",
    "\n",
    "You can also custom your own grid using:\n",
    "\n",
    "```python\n",
    "desc=[\"SFFF\", \"FHFH\", \"FFFH\", \"HFFG\"]\n",
    "gym.make('FrozenLake-v1', desc=desc, is_slippery=True)\n",
    "```\n",
    "\n",
    "but we'll use the default environment for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ho0clcOHrBlm"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAACRwElEQVR4nOz9ebRtyX3XCX4iYg9nvPMbMvO9HKTULFuy5FF4wGUzewBjFzTF1DTVVSyorqZ6NasKcA2AC5pmdQGGAheTMZOZXMbYxgbbYHmUbMmSLCklpTKV+d7LN975nmFPEdF/xB7P2We4L1Ogl77fte5675wTO3ZE/HbEjvgN35+w1nKBC1zgCw/yP3UDLnCBC7TjYnJe4AJfoLiYnBe4wBcoLibnBS7wBYqLyXmBC3yBwlv244984I6VavX8VaL6vxCf3xlvgFkFswXMmkpnay3WWIQUCCGWlhWArBWRwn33+YJu6UPbd4tgtAHgQmbV50dBZr/tKx5rbeLSyamU5PHrl0jNctHtdjOUdC3qeILNUOJJgVwxkADaWHRNcv4KAUxTTZI/hBbIjGWSCs5iVX4Xa8EikUSTKcf7x+xd2sALu9glovOlYbury8+XegolwF/j4bfWktaePiUESi6+l7WW0zgrP2fGYoH7Y698sFMj0HZxHfdfuYeAC5k9YjJbhKWTUwrY7mruj5d37GBaVdPzNYKMjdAjUKsFnWjDOK0Gc7frLy3f9RVd3wnVWMvhNKXnW3q+GyRr4cbp8joAtkLNVEJmFpdJjWz0PZAJvoKdbrCyfqAhuL6v6Eq1sKwQgs1O1e7TOCPRhsv9qo6jSHEaL64DLmT2KMpsEZZOzodBoiX7E7DW0PHcKCop6PlVA0eJa/wg8PCVYCCajc+MYZoukUCOYo3zpSD0nECshd3ayjmL08xwfI7+1HEYKXwJvqwGv+ercnVNtSHKDF1fooRgEFT98qRr3yjJ5rZ4bciM63/fVxQvJWtt496z2H/I/duFzL4wZfaaT87MCDKj6PkpQrgeebYp6DgzZeM9KfFmFnmtLbFeLegCSgo6Xr5FspZBkC4sm3jr1zuLSarwhCXuVPV3fUmxHTMWYm0IlMTzqjY17q/N2mctgI4nyy2jNhlCLG6/wPIwJ6wLmf2nllk7Vk7OjrJcGybl59tnPmaNB2B/4iEEXBumZMZyMKnqsECq4SN3YRhotjrNVdNXkp2uzyjJSLRlu+OXD8Yk1UQz+5ooM8RZVf9ObZs1SqrzziweG6TlijhJJYfR6rUqs3Dz1M/bbTiJqlWxGObPHUOUWa5tpHMjVWyDjqOUUEn6tZX6cDr/gNa/6/qq7Ju1cBS1P9AXMmviUZBZG5b2TAhQElResQU8ZedWETfuzS5ZRH7Arn5RstKkCchXaXeILr53dVukEPmfdRq3XNLuu+b9i7YVMNbVr6RACVf3bJulEOXqbywoafFks5C1tBzmBcaCNoLasYvaSwYhLEII9xDl9y/a6PrtvlM1BYy1dq5f1XgU/7dYm4/VTL3VvS9k9qjJbBGWK4SoDtJncUasDY8N5vfPt888UtO2MgvujKqD+E4nYxgWZxp4YlitIsPAw5OCg9qqMwjmm9fzVWO7BU4bWFdQHEcpvnSH9X7g0QcOJkljQAaBx043mFFQNFe1KBPcG7crKkapYpSqvJeW6xtp+aZw5yfXHk8KtjrujVK8PaQQcwoK0fIdwH7t7RVl7ny03fFR0pWPMs0oqfp+IbNHT2aLsPaZM1ASKWDaoiobBAaz4MTc9aXb12eGQFVlBG5vnhmnvo61oWivNpZJTXDd2h6+tRNS0J09BEGjjo4nW1crkdevrSWZMVB50rIZtg+iJwW+kkSZZjayJ1ASlY+Vsa4vWb6cRpku++JJQbBCxd/z1Vz9sTbFcwR5+9vOexcym7/nF7rMGu1d+msNoScJkURZMjdgG+Him+x2nTBP4uaACQH9wGOaalLTPJNoy5ygl8FXcs6OlWjTUIvvdP3WQ70Qgn7gEWWaRDfb6Enmzlb1NvUDydHUNGx+AKGSBErkgm72pT5ROp5cS9CzOJwmZV9CJRmGHlnLWeZCZk08CjJr9GXpry1wh+P5EbMWTuL57dNxlLaufsbC0TTN9+SuhBCCrY5Hqu3clmf2fLQReksNxL50dRUQOK+Yfsu2C9zKudVpr2+S6rkVOsoMiU7nhAwwTjMmabOuricJPclJlJXjEWeGVDcF5CvRujWsYzP081MfiHxcBoG30IHg8yGzOi5k9trLDNaYnIUg3KFY4BUn25ZybbcpVov23yw/9S9/kB/4nr8LQBAGfO9P/CuMdOWLAdG5wqEOi23UPbuFEkLgzXxnrS3d1Nz1try2UGa0QQrTqvJe1Gd34LeNPjhlhttmFs+MhbkHRRoaD39b31SLDOrP/OdbZsVvRSuVEBcye5Uya8PSyaltpRYeBKrVBlTdSLDbW88Lo45QQBJFgDOCg1sRd3sBp3E6t/oVOK6pwzueXLlygevPWW5MP4sz/KlTm69q9yDwGJy/a4AzctffTtvdAG3sQpV6amxDFb/K+6bAaZzlD4j4vMuswHGUlueyC5m9Gpm1Y6UpxZeC1FjGCUxS6PmGYm3xpFtZnJHWfaeEO3Sn+XeBmlcMxJkhjiI++rM/z8v7n8F/e94YZfjZH/9Jti9d4tl3vRMpBGHuTmZyv8dEC1LdrM9Y8KTbUglovWfxW+H14StZrpKHU6dICJRp1GGhYW8L87NGrE3Z9zq0saTG4EtZbt9cH6rPcWaw2LIuqIzck3T+LNP368b/+XsW8Gt9/nzJDCi9eor7qNLY7vp+IbOHk1kbVppSur4ijTMeTGCcwrVhRtHGrifxAsk40eWrPswP+pNUkxrLbne+YaMk42D/iL/8p/8c4ZfB4Fvc9zbN+Mt/+s/x7q9+H3/kbW9jGHjlw5AZw3GUMU4kp0nzbTDQGinqvp7tg6GkyL1DoOsppIDUwMsnbkD3es06tLENlXfQlVjrjORF3+vI8vLDoHKYVlIwDKthHqduRa6r4I+jFKMt+1PF7Nan6yfl9qfnqznPnAI9X1FsnD5fMhMCQq9qd/0smGmT9/1CZueV2SKs3Fd4UrARenQ8gTbQ8TwsrkOxNmRR+wG756uFhta/+2f/AsfjAwbfAXKz9oOCwXfA7ekn+av/7z/F7/4vfz9vf/cXAW412wg9BIaO57YQxgr2px7TVHIvt9kJnB+lJ8VCRUKBQeBhLITboKTT1hUP7WmctbZfCqfYaDvr+Mq10VtymGjbyvV9hfHgcq/aSp3EilhLHkyq8puhU0YMF9y/wOdDZvWHtQ1tfb+Q2foya8PKyekGTuBL8le1W51AYyyte2ZrbaOz1hbeF67spz78EU6SQ7a+duZeEvw3wvgzx9z7wC9x8m3fVGlycduWjmdKrZfOzzvaCnRW3K+yfa1iFiza6J47996ZCo22NEKHZuHn19W1zOAexlVRHXU1fHF90Y6uX91zlFrQEGVV+Y4yhMqWyotFeC1l1tbuNsz23eaKlwuZrSezNqycnKlxK1JduSBF89B7HKUY6+xSsTYNj5GiI1sdn7/7l76bH/+XP8S9r+khBkO2OGu9Z3zF4/5v7vPn/8qfp/On/ix/+Uf/T3q9Dlud9Q7aN059up4lNfMH+LPaQf84cgfyunJho/aGKPre9xUdT3KU97OOrY43p2FcF1HmQq82V6zcZXtjxXGs0DZt3SoZ60wPr6XMHgY29+BR56jj17LMFmHp5DQ4hUKcCbpe1ZDZQ6wnJcZaMtP04bQWEi2YxFPufebT3B8dMh1YjAKJYDJu1yQmsQIpSLoWO7C8+NxzbG5usvXOt8yVDZTBGEFW+lPmCgpribP5wStc1qIMbDavbK/3TYrqbZIZ2wgbykzlq2mtUzasitKfhczNHG2X+dL1LWkEIecKCu22q214rWRmlCDVpuFLeh4sC9y+kNl6WDo5MwMvHElAEnrQX6CaHoZe6e84i7tjj1vP3eD7/sQf4/QdXabvGwKgNdx4Ybi0caO3dMFa/n9//E/whjc9y1/6R3+78buS8Ngg4yyej05ItORuS8BxlKvzXzmDjvZQAh5f0AxPSrY6krM4axjYAcap5DjyECIlUHZt9XkdYW7khvnt3FZHswXcOPHnHsb9Sfu9tAXsayOzQFmkcG+gbovHyzLMBiHXcSGzJpZRmqztIXQ4dSvydiebC8QFtz70fUVmFsf1veWVjJ0TwZODmDUC7rk/9Rhnik/WOuD8RQWTVJcDEHqWnU7GaaLIWp25F8NYuHHiVrxBYOh4am67EnqOwmNW2AAnsfPJdCYL2Oud6/YN9H2FtrbhFrfd1WRGPFQ0/auRWWYEB1PFaewiQZ4Ywopj50JcyOzhsPbkPEvcX6gMvpr3HxRC0PUVUaaJ210beeLA8Jb9jPfuRg2H6kX49EmHg9jwqdqtnE8mTDNdblkCZQmUZZxKsnMGG1vgwQT6vsWTJj/8N+sI8his+sNVYJJHOZwlsNV5eEEX45fkkfkFhoHbJj2MoF+NzIwVjGrmj8cGLgztYXAhs4fDuX1rb498BHDzFK704epgWWnLX/tDv4vhNObbMp+HUy/At2qfs0/f5P/2m76N7/jDv5/f/B2/vaFoiDLDJNVc6jlV+itnPudlBJikkpunsmRr+6LLtJ4rluEkgo+WfE2Wa8MUTy7e4lXXOdPGdsfHl6IReHw4TfGlC54+iRVnyfkFfj6ZteOT+9X/h4FmM9RsdryFBnZwds6TKKOXb40vZHY+rJycKqetMNYF45riEG8h0e6vKKOkQCCYjkZMxxOstYwPDwgyQxcfr2tRgcWEBi3B77QfHKxOyZIp3sDS6YA4cavu8cEhhw/22b97j829XaRUucIi91OUTqHhtsyuTW63I0rzQbH7kcKW7dZW5IHGlfYs0S4Atwj8LXw5C/9QmY+NOzOIYkga5FOJJvdYmethY1tvbPVXoLinEk7J44Koqza7Mq49s9aHh5FZPbjZk87cYmpBy/V+pdo5AiS6LSC68l1193d16VrBC5nNy6wNYpld6d9+6J59z9u2AdifKMZp+wrw2CAlVJV6+x989/fwg3//n5S/71nBb9I+b/kWzbWvtNz4+X2k7POO3/BHWus7vvMZXvrlH+TyOzbo7XX4D/+zYj+1/BuvUql/1z/9Pi49drWhUq/7ehYozAlF4O7hSczzN0a86ckBO5shxsLN03atSagMVwdNk8Ssj6ULWj7fYUwJR4exDMNAEeb3LDxt6hA4/9J64O6HnzsEBA8jM3Bvg8JWGGeCuwuClpdhr5fS9xc/U0W7C1zI7JDf+N6rre/7tbe1Xc823K1mG25x0e0AWU0F9RVf9Aa2fcWz/R5B7yVObt7j1sEW1naIfulFrlzd5Nr1XQCMMXzkQy8xPTvm8HAXdScliya88Wu/lL0UjkZTXr5zwJ0Hx4wSSSeR9HyNygNgQyXxZPNwnmqLtfPnjjqGQXu//JwCI9GmXOlmDfiDwJAZy1kyf+5pw8DXSAGn8fzDMQwMmYVpKvM3mabjOWVKEeRcPMjFeC8zvJ9HZrN9U9IyDDRRJtZ6kD1p6XqGTAtOZxQ8obKEnhsjARcyW5MtbO3J2Q8M/RVlCs1YaqqB/savegfDfsCbntzk1q8esv/CC3zu7ltItM9nbn+K93zpM9Xk1Jb3/4dP5Vc+Rse/gT4c8cXf/CVEqWB444R/9/Of4M6DY05ihYoUgyAtA2C7eQR6XdCxNgsVVOC2IjtLaBkBEm3ngnoLbITOAdoJejU280DgV85mV37LMDCkWnAUeSiRYawpBT0IPMZJ1njLtGki6ziPzGbhSTcuB1NFmrQWacCXlp2u5sHYY5I1x2KrkxF6lpPIuQdeyGw9rOVb219g54pntFQFvv53/nbe+/Vfi7Xwvf/j/wjGEAaKL3vrFd781LfyO957ibNxwnf9rX/LldHl8jqD5Vce7POOZx/jD3zLl3N08naiOOZPffePkWSaONF82W/+LfzJP/b/5I1v2iUIwJfzPotbHW/hnj72q8EZBt7CmLq2IORFEMDV/nz5u2OPdVbm3W6Gn2uvBwHsdsGTCimaD0/HU0vd6KQQebTH+WW2CJuhZuA3y49TuZaSw5OWvW5WknA9u+Mm1oXMKryqYGvBYir7Ra/n7Ut7bF/aw1rL3f1TdOYG4S3PPI7o7LF3eQv/bMoozYhnVrdRmmGV4MrVTaZGEhHz4iuHZJkr5w+GPPWWNzPMCZNmB7ItYLeOunJRSTFnH4PKL3RdT0gXrdEsbW1d5dByTe17X1rCXNCeLBwH5vumpGB5HENR9/lltgieZI7hLtZ2LpC54LtFVL9JYRvj0vXag44vZNaOV0Uq3fXkSq6YK9evobOM6WjMeBKzf3RGFA/RxvL4pQ02Bt1aacHjlzbZ2ugRJZrjsykHxxOwFs/32b16hUu7Ww/l2XEeOFa15feY5qaAxXXA9SUKhLbfPt/9gvVkNutnO4thYBgG7W/fva6GmS1nz1cr7/lq8XqU2crJmRk4iqrPm2GNx3SFUclay3f9w78FwH/4Vz/C3/+Lf5n3f+gzdP7Ab2J7o8d3/8lvb5QPfMV3/8nfycko4dMvHfPPf/xDfOpzdwB48g1v4H/53r9BqBRCiPzA377CBWo9n8mzmHKhCxT0a+O86nrVEs1gLI3zxbIqFkVCWCBZsO305PLEOgVercza2lZnN1hWha/mOWqVEBcyewisnJyTDO6Pq8/vurKa+6SAEIKN0I1et0aXceOzdzjsBpze3W+9Lk40R6cxk9G0/E5JyrrABf8u2qGtu5rdOK1sXDtdeGZrrcuApo9l2e7MlJQay+DiC9vbmOrFdfR8RW9JYp0Cr5XM6pjlkF2ErqfmxqXAhczOh5WTM5CWvV71On/5xMOXgic3H+p+ANz87B0CpXhhRbnx2XThb4NgXoEwSbMG5wy4h2XR+Wunk1Gsd9ZKXjhSPDZw/pYPA08Khmvw4ixbndvqMNYx28WZKZPlCMTCAOjPh8yG4WKFzWz7F+FCZotl1lrvqgJKQl9WHg23zlxoTPF5UaPrQa2f+/TzfP/3/D0674Pg7fCSd8hwCn/oh1PuRz63c2O3EPCunQkvPCH5kfcpjDFsGDj9e/P1B0rObZGmmYAZouFAWbwFT1XXr/o1Ti3HEVzq5YqBFf0q+laHWmMLsyqYWApB6IlGOW2B1IVUFfozgV1Y12shs1msCrZe1a+ijguZra+QWz8qJVKME0egFGv4lbvOR3NR6M5ZntBmt+uTxDHHB4dsDhT9S5JxluFLS+BleEqU4Q4CCLwMEUomQ+goj64QnIn2Q7qlPZFMHaNEM8qptlWL9Cxw67QK8fnsoRPyu6+0C9tYl4zGERSfX59WeKqsyhdZUIosgqWpuNlsWZFfjczOG+eYaMtZkuUcQouvvZDZcpnVsZJ9r/C5dDQLVc8tzsdykkLHmz/TyNzHsI7vGH45v+Xy2/iWn/4RXrRTvuv/epr/UjX4xwk4O/F55RN9/twXfwVfd+lxfo/4Pqyt8h8WMJY8sHU1fGmxwlJUURf6bL+sdf1S0vVtFko8XADy7H0LOIVEc0V1PrCr7+GCiysu1ddaZutCiELxU31nrZ3jKrqQ2bzMFmEl+94g8BoU+XXsT93f2/dg9jzfRop0784xz33iFa7uw46VvOt5jdiRyMt5hyzoT2sOpx7qUHL04hGf2gdrnJBnfRW1oZF0Zxmubzg6/IJJrR+4oN1FCopPHTjj8lt2m98rKdh+FerztmiH0YwXCcCDiWKSrl7lB75mt+d8NY21eQLY105m6yJQkmCGQe9CZu2YldkirO++5xt8VbhgNVeHe2O3yi3KUVFkPP7kJ25x/NIRb0fQtR7f8pzGew8E1/P8hZll+u81t6RlMwh4+cYNXrIvo3M+1Ho84jTVCOFcwxqwjrdl1hh8HCmUnB8Igasj0aKM8ysQZ3Dr1PG+hurhE7jWUbAKTFONJ532sOPJ8oHTeeBz3zdzMa9RKon0jLZRC46mikGLr+mrkdl5USTDjTKNNpaery5kxvllVsf6ju++pYvlNFZzGreDqRuwcEEG4p1r1/h//KX/lQ/+0I/yqx/4IF+tPbrAJ02HWx+yvPBSnmLOwFcfd4iRXJKnfFwaHgjDn/hL38XG9mZD0FGmkTjqwTpsKegmzhLlnLNnvhfC1TFKJJOZo1Bq3EO8011sdD8vikiJaWboeBAiG6zsiTbE2tDz57dNxgqiGXmmRpIm0PXn2/dqZHZeBMpNzkQbEt0+OS9kVrRxsczqWDk5fSnY7viM02whzT5Uh/R2bLP51q8k+/cf5DhO8DOLDxyjuHVg+MRRfvgH3pm5TndImSrNkTB80Ze/l7ATNmrcrNmcYt30/HhimBJlkoPp8u5t5MllZrdesziOFCfRaltV1zd5nkf3wN0e+fjScnnGh1MKGpmf6yjGu0A91Gkz1AwDzd2R35Igdr6OVyezJh4bpCVNyVkiOYkUl/vZ3JuizVxStf9CZufBat9aUWQaFgiKTL7NQNy85EKyopPjIz7yy79A8IZned8f++/40b/7N0nGEwAe/5L38r6v/jo2Qo0wGf/kf/vr5eLzvt/5zbzvrW/iR/7dT7G1ucE3fN1Xl3XW1d+ylom5UIhoaZG1INdiC1Jvt5LOUVxAHvxbMNHNepGsGtR8XMp75MqYwnRRHyVRjWkbZn+ToqpHifxPWvK0MqXSp97u10JmVQlbPpBFYHMRRF33JC0yZ0khFvqNX8gsv3OLzNqw9ra2SgyTkGi4veahHkB5HsPNLWR6hjQRW49fJZlGZEawsbvBTt/S83wwkt3rT5TXhYM+Uim2tzbZGC7m1uh48wl7Em0IvWoFu3HikxnBaNosVyTz6Weanp9yb+wRtdAzLoMArg2rLMn7E49pJnhyI8VXgq3OwycLalPfC1HlejxLJIdTjwcTH21pPCSvRmYFtju6zGydGRc2NQw01zdSNkNvobPAKlzIrJLZIpxbPRd6EiVpHGYnqVy6Ug0GQ97zZe/jpc98jPu3X+JLv+1b88BTmYfduBZKpfi63/e7G9cm2vDlX/5lKKUagcFhHjO3CEWwa5FwZhAYd5dkgeE+L+9Io9x9tBFMs9UPnwVGiQsa7vou6HjWsJ1qM6fda22HXJ05OVR55mlt8KUtZfFgUfmHkFmBSAuIJf3AJecZBLpxTp2NxVza7guZrS0zeIjJOQg8tLFkNWbuOBNrCXrr0jX87iZXB+mcjW0j9FBCtKZZm2QGOSP/QMmlYXeedCaFszgj1qYMzhWJ5m5L+SLTsjYVVUeUrSdoEBxGHj3P0PWz8k1Tx7pxlP4agu4HjnM2nho6nqXjub69LIrNZhOvRmaTVOUUkglKUp7P6lg3gPhCZotk1o6HMmxJ4bwbosxpqXZ7Gqxms+OT6MVhOVf6Q2BIqGyZXKZsSD5bD6YpUSY4rh3m70/m69qfOKqNS7WD+yBQc2xwvZyWH5zd7XBF3/qBKjM+B8pypZ/S9RWhkpzG89T+dRRETj1flbk5Zl8U98fe0jqEENwZOVNBJ483VGLeJ1PQ9DAZzTNSNfCwMqtfL2iXGTAnszZcyOx8Mls5OWcT2hSN8ZXLAYl2HDGCgkfULjWsVnXMBwQXfofu9T+vvKgj1k4ZsFXbtLtDfeEp48rXg11FbYRt7ufYlqagqEMK6HiWnmfpeJY4Wy8VjSfFwrNYomeVMO2vkq5XY9GT8/0qZFDAcQW5zxcye/Rk1tqmZQ3W1mXfXcThWQTuHkcZ2trWIN3drk9mbDNTcMdfGMK02/UZBpZuTTFw83Se3h5y5u+aKeCKdivXovAjJapUdmdxxiULi9xA6+0ep3pu69b1JD1flX0HZ+tbFOHQ9xV9XyFIG4qBo6i9/P5UQa4I8aXF2NSFHy2gH3Ep7i5k9ijKbBHW3tZmxh3S/Vryl+JfTwpaHDlKCCHKLYP7XF2rc9e8euIbKVzAb5Fkp+PZMn1aqkXNXtTsWaIdkURa83tUooo6aHPmttZlX5aiyqBc9c822l2HysfBV6I8D3uyylRc1CtoZjAOlERbx8jmSUunplxxGsf5vhkL09Sp673a4bt+zmnr24XMmngUZFbH2pNzmpr8kO7PvYhXxah5ot0/EZw2tkipJvNXvq8km/l5IdFNg/DRVM1lSS5/izzA0lGVinwQKNSSYFeLe9OESjIMm9saT0o2O8sP+sv8UU9jlxB2qyaQYeiVPKo939LzXd/szBulDm0F9yc+ic7QtkrVXud/bcOFzNrxhSyzRl9WFciM5Sx2iXAGyp0EjLWME+14R2ciy9Ncw9X15VKq/gK+kgwEc2pscEG3hQeKsS7vRS9w/qJHkVqobTyo2cW0saR+9aBEabWKTdIMgXAPQ/5kTFLnGzoI1NzKNsoDgtd1EB+21AHuXDQIqjZOUpf8dberSbRYyGw3TmWZDk8KCFTTi6V4EV7IrMKjIrM2rFYI4VTKA1UZjU3u6CuF8zOsQ1v32yKqirkGSIG3YJX0lSzzq2TGMElzgmJll2gGRYPlvONlqNq2os6pm+QscsOwWs1SbUiNZdCStifOzNq5OIQQJft32291A3yUGYywDALDJF0s6NRIiudUCkusm+dFp4AQFzKr4dGQWTvW3taOEs04V/1KIVq3SuCMrUFXNn5LtWmEMG13/YeOrTsvDqeKw+KQriwhceN3i+PHKTAMPYYLzixtYUfHUVrmAQmUPBcNxauBsc6DpsCsLyhcyAwePZnVca5W2fLfWjbkZSr4Us2+WJ3tEuY4rdzyA7IoY/ksThsmLCtzO9qZQ3pb+XrbGgl8FvStbnawtb7Ve+kCjd05YxUNhgtyduWdksOiTbPt82gyx7p+Le7bhcweHZkVWDo5rbUcnsStv+3T/v06SKa63Gok2hJnmr7vscZxhzgzJNrgE6PsvN/lynvHbo8xmrSvWqsM3svgScm4dlY6izOUEPSC9dp4lr+pusBprFrshovxysSdNZXgQmbnwBeCzBa2bdnFmbY8f2O09s0eJdzZj1YXegSRwYXMXidYziEkBZs7Wysr2elmZTSEr0SDo/a1RpTpuRjFKFt8IJ9FGieMz8b0N/r4wXK1tq8sW2EtT0eoytCozwfaqEX2pwq7ZhzgyeExwIXMHkGZtWHp5PSk4Ildb2UAbCyqmD/pGcKuZhCsF04UZboWbSLY6nhLzzHFeQfctvskdkTFl4pYOQR3RsuS0Vg4gyubkkSGZEsGUWCZ1rqw08nwpbP/Fe0ehn7pY5powzjJ6AeOJ9YFBLvGdv35EKlGq6xlz1YB5eMkIzWWeqTcaaIaqeBncXrkzngXMqs+PwoyW4Q1eGtXeyZqK8oTeqoFqXFuZKrwLaSpOKgyFjczExeV2CXKCHddUbqyHylVfGfzYNf2GopWKJGf/O3s77ZsiUU0sh7r3CslM+4vNeRaP1dr9Z1rUz1pkG+aGZSb/an8Qst25P+vH308MatSaMeFzGr9fERk1obXXIc8ySST04BLvTTnVHFv4K06jcPUeYPsdAO6vioJlAqsS5FfoOPJ0sjsBLyYF/WQjKMldV3qOV/PRZ4fsYaP3gNHqqK42fhVAvVt13reIFf72VzGqwI7NQ7Zjpex2Vnct/3b1UN3HlzI7D+1zNqx+s0pLP1afsRxul424CiTGGvp+wZjLVHWdEI2Fg4m7owQzLCkGetsb2nuGxrWtlqZmedC1aZZf718UUcbep4pow0yI4i1JMrkQj7RcSofcg1cjmkm51LzdTyDJ52xu75jLPpmcVuyNlzIrMKjIrM2rM6VomCvVw3i9FQuHLg63GG/EPR87JqjvHDp5GazFAfKJdMp/DTrblnjJGOaNRuQGktaq7/OWF4E7rZhu3bfUSKJp3KhDyiwMBrh1eKkhXlur5vhBaYRWdHzFcN8z2Ss5XDa3q8LmVV4VGTWhuWk0qIKri1y2V/qZS00i95CZrH7Y69ctIeBLrdNSsDlXlomZu37CiVFQ/vlgm6b9XVaktwkMxHrhfNyP/Do+s6XdFar1vMVG3lynrMko+MZLteS/9yfrJfh+G/+5Ke5e/JwKv6veOMev+VdT7T+dhJLRmmzn5uhIc3dvxbNtQuZPXoyW4TlphSqEJc4M4AtI73rkJFdSFQU1YyyPa86zQvheFXLhshmxmKbs5fPMp61ZQrWZn5Vnq1jVo/gSUmgZKnoqGdwXu5A01R8fPruKS/vjxeWX4YndnoLg5wTLRAznjEdZcpsyjAfsQ8XMmvDF7rMFuEc7HuKAYrDaTq3Ajw2WKwI2O3lAbAzPKMFD2iRbbge2JvoZhDwqtyNnZyBu47UNOvY6fpuWzHjPSNm6j+Nl3O93j+N+KN//4PlZ2MtSEn3XV+xtI1Ka4S1RFMwaYJ++aP82Edf4cc/dru1/B//zW/j1735cuO741iV5MtSLM/CDBcyK/AoyayOtSdnPUh30TC0uSJlxqKNnVsxrCUPzG1e40lR+jgWcAGw8+VmA4gb7cU2VnXnxTif7m322sQI4hlql9tHE45yR+ujcYKxFuEHiLDj4juWtANAKoFUjnJDWZCeD/35VF/CGqx1gcm3ThI+8cox4LaFb7wypL5lc6x3zr/TV3kSIdr7diGzR0dmdZz7tLwoANcddudXhUUJdSw0Vt6y/tAr08ktq2O74y/NiOUr2QiYBXdmWkQZUeBo6nGWNL/7Vx++yb/7+J1mXTuXCJ54amld4ITcGVZj5gNWG9Lgbc2C1uLplMwIJpnPP/vYZ/mnP/9ZAJ7c7fOXf++XNYsjuDf2y6Q4/UAt3DJdyCyv6xGSGayYnIbKsbfjyaXeI4JmMOp5MUl1qVF0FImKaWqWqMh1ueb4Siz15Chgahyr00xzFmc5F6vHKHFmgvpO7vbRhH/14Zt88pUTd58nnkYUuUS7/bX6ZYwlnnHYFoAazNjTrEVYD2UFXSvRXMFMN0gSOPYsf+MnP10W/T1f9QybMxH101TnRvgLmT1qMluEFVEplCptXwmWnSJmg1HPiygz5XbJZRt2SXG0bi9ftxcJsV6QsLEuThHcv7E2+QPqslPtz2S5P5okjdXX27mE8M+ZSs6CTprqcyEg2Gw3dqv8LzNbmN6QbALjeMK/+/jHyzK/471PstlrXpeaImuyuJDZIyezdqw0pQwDj7Mk4+YJTDJ4fJCULkvdnFmsHrwa5p4fp3FGWvDXzLy7j/KtVD0Qts6HmmjDWZzRDxSDwAkxM5bTOOM4knMO04PAsNOp9jVt9wS3RSq8UgaBV7p1ffReM+ejsZY//Ld/gSQ3kvtPPI23cwm89uES0vK291qiyHBysh7BshAJ0zPJ+GiBCCygFBuP+1gdkA6/hOT+bZL9e/yJ7/8QG12fv/YHKoXGMPDKYOgLmT16MmvDSlOKSxYDUgpHLCwEIk8eY6xTHNQDc4uFwPlmLurk/HfNRto8uU2T3U0W39XGQluBNlAsdALyRDd2ruOu7dX9lBAY0fSfPBrHxKnhdJpgEIggRPh+bfW1yJlRkxIQFiEtUrnPQkBXCgwQG5edublIWqS0yJksXUK463UKxohyIIXnO4WGHzKKYyxw72RK1hds1AitLmT26MlsEVanAFSSnW7ATpkk0S+ZyKJsMV39MuqHrQUKigJBfs9GQ6X7LlQZG6FbxbWBW2cB41TVOGgsSqQESixUhBTY7PhkBl4+qb77Kz/+KT5203lyysGQzpvf2bhGerB7fUb7ADyoJb3Y3FR0OpJv2A0ZZZYPnCScnGgmk+ZYdYaGzrBZVxgKdnY8Xv604OQAorP87ON5+JcfJ7z0GGef+ijjOOaPfO8H+IZ3XOWPfuNbGdS6eiGzR09mbVg5OYusvYESNY5QR9BbIMpcwpniu1lqf8fC/XBnmyJRjjhHHaexJPTAV/Pblbo97MEEiqa+vD/iQy8dcv/UeY54lx9HhJ3GtZ0NjcpXTd8XBEH7a0blKsmXp5ppZhiNNGnaNET3evMr53hsyDLLaKRRgaC7Cf2+RGeCo/sCK9yq7u1dwaYJ2YMqg0isnXJBcCGzOh4FmS3C6slpLZNUI4WikK0Uzs2qQKJT5zAdeESZnvPJ9OSrUzyMU51nlFqnDsFx7NHRho43r86Pa87W90aU9rEX74/4hz/3Yvmb/8RTc2eg/lZGQToXBIKNjeXt+ewkI0kMZ2fzyoXZa621jMdOmXJ2ZlAdGHTgyhVBPMUJWjonbv/qNWyWNgQdZcYpF4S4kFkNj4TMFmDp5EwNPH8o0Mbj2oaY85ksMAw9rLUcTdMZwiS4O/YIJFib0vPlQurBZdjqeK3GWilcxuVxKjmdcUSOM8Hts/kGT2dzgM/Av/4GVG5s7vYt1551q2I0tQjp3Nm+4ekuUooyHlFb+OBJQhwbTk+b9W+Gkm9+tqmmSy18dJJyNZA80/P4mZsRRzPtGg4lYSj5yu2Q6dDCu1L277jVuA0HUw9jXULWC5k9WjJbhOWmFCq6eV0GpBZ+llWlnnQPRZt9K9ECcDT3mQEvD2o9D5eot6CwEBAoS5xzmeYty9suSjLfOmaPW9Za4syU6noZdpC9Hgh3Vun2IU5tSZ7lK8FOt/lQZdZijEVryLKqbQrw7Hz5SFuYgCcEHSkw2lbX4TSUgSfo+O53FIRdi+fTGmzs+lX541zI7NGTWRvW9hC6cer+rg1TfDWfvVcKwW7XJ9ZmbouUaMHNWiDsF1+GFU4fC1EkhjmKquQyA98w8A33xt652M8AxnHG7/+en5v7fu+phDAU1Ifo29/aJ2xxcbEW7t2rcbxuV8qFZTq5Tx8m/NJLzeiIJ4aK/+ypUpPDP/7kqHo4fdh7Cg5vBeg14povZPboyayOc7vvTTNJot1i0PGg7t+8mEem+f1xXGWK8qQlUNYll1nBQ5Nqi8ojIerRCdq4N0DHsyhhmDSSy6wHEYTI3oBgqPD6bmSFBT+VXO544Ds1f9HHk1hzFJm8bdDpVPfbDSWDQDaoPk4zw0Rb4siQGJhOTalwCAJRUkxmAl4+raSYHyMJQ0GaupU+6Bm0NMzY3xfiQmaPnszgISZnQRx1fwJXB/DEOZ0vAG7U1OBF4G49KU4bjHW+mz1f4UnVyH0xzdO9bXX00uQyyyAHG4RPv4nB1YSg6wZaackwCnhqFy5tzPThNOPDd51KXQi4cqUiuXrT0Ody2HzN3I40NyLNvXspZmabNhxKgtxwH0WGn77RXJk9D7a3PU5PNeOxYbiboeOME9bDhczyPjxCMoM1PIQu5cGsZ7Ei0s0X/tEUpqmjWfSk8xjxpWQYCKaZJtUu0Dc1guMFEenTTHJ/LDiK5tUHm6Em9KqVDpzmLstHSuCyBwdKIoVgkmZk1nHKFOjmgb5ncYbFcqINx+R+oSvCX7sBPHvZ/Vu2NzX8/CsRZ4m7dmND4nuCL9moCm361TidxoZfuhNhQgG+YGtL4SF459Dn5mnG80cpp6cGpQxbW9XD0e/LUu1vDBweZmQ5m0A8DtFxczy3woz9fAAvZPboyawNKz2Eiij4SWqZjc6Ntfvr+S5RjbU2z6QkiLLcNuRbnB+2rdVaITOCzAimjf14bpdShtmTdJYrMax1io7inqEnmWbOE6ZXCwgeBK5t2jixRjn3TWYMdu5wMRviBFv9PFjXVve/dVadz4JA0vEFl4JmnsdCRZ5oy60zzYaQ9H1FGEpCCdeGilHuIpOmljQl125WNrlOx2VszjI4OanapjMPnTbHMfSKEC1xIbNHTmbtWHtbu9vV7HYXq7QttGZJBqede3Ij5TBazuFZoOu51Xt/qtifNKWx3dFshIbbIx9rwZKWTG6buYdLvR2jRDNite9kZ6DZfXreiwTgA7djnj9ydSoFV69Ww/aVWyEDTzTObv/hRsSt3EvE90WjPLhJ8w8/MWq4hkkB37CXc6A+Dr86SrmfGO7dqyhGBgPJYCD57Al4gcef/NNfy14KLGDcuJDZoyezOlZOTsHipC51suCldTQUCc3NuzailctGCMBWSgKBxVe2cuD23MNVz64shAv69Ra0FyhzOi5rZ4HUWPYnmknm+ul54HmisQXyZFVnnFnOEkOUl/d9gZ+Xj7QlseQKgiL7s6Dvu2ulcCSNQggQYDQkicFap6bf6kgskjiSYF2ft6VgmI+pJ13gbuEldCGzR0dmi7Bycnpysb/jJNVzbl/LsBkaNsOmoE9juRZDmidtg1rjjdvFA9hsmxBiqR/oNFhfn30YGX7khUn5eWfHY+BLvnIrbC1/Z5w1FAO7u4rNvPynRik3Is3hYVYqF57e9PiKxzutdZ2daQ7yaIlhIPmmZ/v84ufgw59zj37Xgy9PwROGzkCzEXoI4TSFFzJ7tGS2CK+KN9CXgv4K49d4xYMQepbtTnPwS3a3oFIuFErBQAl8Kc9FlLQOfF+wsSG51vHoK8Gnx/PbvTcPPDoz2smPP0iY5NlRp8aysVGt0G/u+2ht+eDtiKPUcJrZUs0+HEo6tcgEYy2/fKfiyjmc1qgtM8MHb0e8cuaRaY/fdR0uhbDTcUdKbeDBmDJ93dJ+XsjsC05mi/DqJqeSSw3T1trVgs6zHrfBKQlmD/xyjm38tYDnCfp9xRs2PHZ8ySstesHrXY9gZvv14nFa2s46HcH2djWkT3YVR1PDzx00DxhSQr+vGk7Y1sJzB+3nv1i736ZjgbEeX78HT/RgI3QsAKMEjiLKnJnLcCGzLzyZLezfqgEYJc3wnLdfAm9OY7YY2y3bleNong2uDYNA4c8kgCzG+ThKF1IUbnfaA3fbIDyP7fd9Ff1dV9f7b0ZkiSUyliBoCu6Hnh8jBezuVd+973qHrirOT87r5uduRdweZfzAg6zyiBlIej3JV2wFhNKRVhUT6SdfmiwlGzZaEp11sVbgKziNoQMcT8EisVby1BbcleRk0BcyK/AoyGwRVk5OSzMrcKopb7gKQsxzmEKeDGcNUUsxz7y2DMWgGksZJVsEGy9tYycEqcnSlGlqSTNL15v3D42NRQhBbHIfTJkrCLwq8j/RzmfTGJgYiwS6nqDnu7++LwnzPmXWEmnLNLNMsuXjIZVw5x5DHjTt/iQCJaGm77iQWQ2PiszasHJydjzLtRrX5qcOfHwJ77y85KIV2F7BaboO2hQIx1FKlgcVFxgEy9O4FRifKsanis5wgvI13/7WPieZ5ZdOKlX9pUvVPa93FW/uN9tw6yyb8xTZ7jrFQBtuR5pPjTNOVwg5CA1PXIs5uOdxdNAU2XYXnt5qlr+Q2aMnszasfeacZoJUu/Rv2sL9MfR8R7TUhjgnf+p4cu3tSgFtLIk2BEouXYWLoN4CbVumVFusdWeo2Wb0fY2Ugq/fVdyN4LlaQuhPHaQkS94Up5nlRm6FtxYmE8NhHkIUhqIM3u2Gbnk8Sg1nM+EVh+n8tkgpCENJHC8myvrFY9j24Wt2nHF/mpqS5b2OC5k18SjIrI61J+c4kSWtRGbg5qnz01wk6ChzeTpmWb3XQWacUmLVFsmyWrMYa1MG585u17Y6hg0L/5fHFb9wBM/VGPp/6U5MEAh2d9uH6DA1paCMsY0Ih16v0ur1c2/xe7Hz01wFzxNsbiqOjpxtrQ0/fB/6ygk60y5xTts4XcisiUdBZo16l/0ohUtWs2gwDyZwFsMzWzBLP9MPvKVR3svgK8Fm6DUanxnLaCb/ozbkGZFX40rfXTvJQ6P6vmNym9WWbWwoOj04OKj6/HRXcTlQfPg0YXY3c3yclXF9s/iyzYDYWD5wHDNtEdp0akqaC3A2Npn3+UuuhGx7kl8+SSjW6o2djP5Qc+dWkBv7K4yTLHePu5AZPFoyW4SVvrXFYOceiLVfHFNCkRHZWNuwsSlBuSc5r8AFTuVf93cEO5c6QJsiMHhRLRWc21gVXKxku2+G8gS+3/ylpwRbvgsnmu1LmjaDbp32z/1/mC/7J7Wno3691pY0tWWwbhhUb6yNUHIpVAQTUTqy+T74vkUIWwq60KNkFiw2VzZcyOxRktkirL2t3elqdrqaW2f+3Mr13L7r2JOb6ydpWYYi1+NZ4hLU7HZ9VB4YXOAoSrECnmxJDNMWfnTrzClFOsRzvwEo6WIdT44yTs8Wb2W0hgcPZtjAhQs/uhoqvrhG4/+TBzGzJ5T797O58KPf8sYee93zbyXBJYcdp7J8y9RxITOHR0lmdaycnFI4rxK9hk/mJF20IjbR9aokOamBVAs6XuWDWTZOSqzNQ41mNAO+lKicfqNOt2Gtq19bS9IIl5o3BdRTFWx58I4BvKQVoxT6A4OULlZvX2hsAtPIMEMY0Ai6jY1lv6YwsLizTZLUV2H3bxgKulIw8ASBqpywY2M5rSkhorjK5Ox5As+bHeP5Mb+Q2aMnszas4Vsr2ezIpdmGXacEDybrqduvDZPyoD9NnZ/m1X5KOJNHsuerhdwYdY7VInAX3Ip4uZ8xTQX3J8tXtkHglXQSb+67v//tcyEHI8u16zFJYjg81BwdLV6VNzZUuaU6ziy/ctp8K2SZnbteSufzeb2jeNsMeelpZhp1HBzp8uEYDiWDwWoTw4XMHj2ZtWHtbW3HkwRKsNfVpObh0nn3fV2uwNrAYeSoG/e6GZsdWRpll1FftMEF7s5+B8ZW24aDqUIbSsa3aarzdATNCz3pnq17r/hYNLTwqEK+inZlyeY2C2stJye6VK13u4IwlLxt4NzJOh3JRFs+ejpDUCxFY5t1/266RvAUHEcKY5sOBBcya+ILVWaLsLa0iu1Ez09INByte2ENobL0gzxw1sIkVQwDTT8whMpbmhFrGYokOnUIYegH1RAdTBUWUZJJpaY9pl4KF040OlVIz9KdT8kIuO1Kd8WZYzqt7uD7rvyTG37piH1jmnFvJmHOni95a22ldWFYS28DQKzlXLELmTXxKMis0d7VVTSx0/XR1qJktXrcGflkLZSGsziMFEeR4olhihJwfSNprIHW2oXBv7PY7vhL7US+dMqIs0STaFN6zBxZzTFui1W8Zd59BQ6njqnuv7zmNJn/w/OQGcX4aEDQi/DD5uF9PDZzVP1Pbnh89fUOP30j4pU8cNfzYHfX480Dnye7CoU7o/zsYVPxIICv3wnLc93P3pzy8mnGzl4VVnS073Hvlsd3vhEKx5e+75Q+AAftCZcvZJbjUZIZPMTkFEI4hjMpymQ4vrSl2cXa+czH7fXQ8IOsKw+MZeWDM83IMwRX91I1prXiX5Wvqko4tbVoUUh40vmddjyQ2hnsHw9hogV3poCRGC0R0pSDHipB1xOcJdXhP9WWs9jkHi5OyKEv2fAlHen8PseZITK2se3JMjd+Z7UVObGAdGcdawVp4v6yVBAICPP2hp4olT8wv+UrxuJCZl/IMmvHQ4WMKSnY7vpl4O7lfoYAdnsBUTbPgdoGKeb9NQt7UpStVlTcGTk+musb1eq4GXr4My4l/cCj8JLMjGU/V8uPk4zjSJXt3urAVgc+cwBnCfyJZ+CzE/juG5DEIUkU0tscOe5F4E3bPu99LOSHnh+X4Ue3R5ofer4K9N3b88rA3QK/fJoQz+hojo9dXo4fqqn7t7ZU6ReaxIKbL4bEU0gisMY9wO+4BC4WX3ISLX97Xcjs0ZPZGozveqETsi8FPV+VGXrHSTbHIN7zVSM7MbjkOYsUCD1fIQWkNQbe41jR9kawFo6iqm1KGAJl6Pmq1TdUCghnzkhFuz0pCT3JXg+GuVyUD9+0B79yCi9NwaYBFseC/soJCBEzrSW78TzmzjSRtjw/TtkLFNu59sQYy2hUjUfd5Usp50pWqN8PHyiyVOBJeNsOPBPAG7egeHZSbUi0wVfOH/ZCZo+ezBZh6eQ01jlDLxR0HrgbZy7V+LQltVzXk2RmRtC+ahW0EO7BUcJgcsdna+EkVq0vf4to5NvoeinaWqfOb4EUgqDFb3SaGULl2OCqtHkw8OE3pHCQwisJkAYu03IG92zMUdrU2nmemFObJxY+N9UEUpSCttadf9owW8fRgQdG0PHhnVvwG/bgqQ3KHCjFuG+EXpnn8kJmj5bMFuEcju/OZrbV8eeEtDHrpDl7EykaAbz1q6PMbbM2Qq9MVxcoV36Ue5s8NkzLrflprBil7YLcn3i5K1a1Xej7HuEajtyJNhxOEw4mLj3A48MUJSTvuOTx+3z4xtzB+iiFv3oDdBYwOamSs3Y3JsSx5f799q3Kkcj4kISpXh4VOR1LXjqoPNOtgSsB/LfPwNWe5nJHM05gkt9m2VHxQmau3KMkszrWDrY2tqrU5koFQR74WtPAzf5WYBF9hrXzjS0Cfl2WZEvBDGFxLltSFJ4vzUq1FWAtdZ9v7TWVHbP3sjbPqizcSSArfE8NSOXSDmz7YELnreJL2PJdKFasBVONI8ewjn3NLDi6Zdi1qPiFFYSmejBDBRs+XAlh4FGmXa/Gyn1X79eFzB49mbVh5eTMjOVwmjIIFMPQrQ5FluSuJxs5H4EyKc5G6BGsIrTBbZcW8cvUPUoyYziOMrY6jsL/1qm/gBxJcOusWsV2s4xBUOdEbarXLS7Tct/X7PU0l2r+jkXfL/UV1zcVB5OUpwT86PWAuyN45Qz+zPNwKxJMTobNStubthJfNIT/5u3N7zqeUyS8cqq4ddYcq4Gv2e1pzpIsf6DFhcweOZm1Y+1tbaotUJ0pQiXLLU0dSgjCGe8PY10gboFwxUH4tUScCWyeN6pIhTeLga/n3NDqKPoeerKUVdeD3S587SXDQe6HqYRwRvlzCjrRphTSY4GAmTxX2sD+BCYtftKpEZwlkq43fx66kNmjJ7M61p6c9QBYKebTyRVwCofZhtqGqj7oynUWpNcEo1RBvgh70tKd+V0K2O2tF/y7063Obpsd9/eHQl1qO11kxvk9Zo4jXYZWTVLBgxn/0tQ0CbuabZPEU8mV/vy56UJmj57M6ngoO6exrLTRzJZfhDjTRJlhEHhLvUeUEGyEHlHm1NCXehnasrbjNrjV7Dhq346tg9M4m3tA25LPgjvHncYZSopGdq02DAKFsa7+UFmu9FOOI0Ws139oDqfOT3PREF7IrFbnF5jMFkEsC6r9kQ/csf5cuMurR11zaCFPbLPefYryBdrSAiy93lqssSi1+EF+WAhEg/PGBTM3v1uG+vnD2OVZj1uvz7ehFzJbH18IMvttX/FY691WvjnXGci6DqHQoK0LUVy0Jmx1VXlvp508x03z8nbFRk1A42EoouXXxbIcH4vvWN0LljOCL8KFzKrPj4rM2rB0ciolefz6JVKzXHS73QyV0/F3PMFmKBvJapZBG9vYZvhSLFU8TFNdKiosTjs3SQVnuWHbQh7F0F5HNJlyvH/M3qUNvLC7VNi+NGzXsnRd6imUYK1IDGstae3pU6uIr/ItVYHMOPPG/bFXqtzTBQmECtx/5R4CLmS2QGZFu+vtNdZRqXg5Bcp/CpktwkqCr+2u5v54uaCLzMkAPV8jyNZWyyc5E1mB3RX8qHU1vrFObd7zLT2/ojxcJ0vyVqiZyqb9aRapkY2+BzLBV4sVK7OoC67vK7py8dlJiGbyodM4I9GGyzUzwVGkGt41bbiQ2WKZxdowSTVbHa904E+1y749DFzf/1PIbBFeVa6UNiRasj8Baw2dIqFN7s9ZoLBbDQLn9DwQzcZnxjBt4QedRbHG+VKUHiXWsjQn5WnmsiQ/DA4jhS/BlzVKRV+Vq2uqDVFm6PoSJQSDoOpXYcIYrWBcK1Bkgu77qtxBWmsb957FsizJy/Coy2wj0PjKcjBt9+fNDLx0XCT9VZzGorYFFaS6+i7Kqn6dSMmiTdJmqMvkTdV9XluZveaTsxiAnp+WoT6ebQo6zqowHk/KuTweWtul9BqzUFKUvqTW2oYBexbJCtvSMkxShScscaeqv+tLigfCWKfCD5Rzgm7zb3X2sfXvWSd41iZDiMXtr7Jzng+Pusw6nqHjFZNzHtrCwRSKk3UzGZkAVO279d5yvjQL7aznl1k7VqdjUJZrw8pZ+PaZj1njASh8Jq8NHd3+waSqw+Lyd3zkLgwD5z1Sh68kO93KT9MluXG/TVLdcMgGiDJDnFX179S2WaNEN4zpdTw2SMu32CSVHK5B45FZuHnq5+02nETVqlgM8+eOIcpcSoTZkSq2QcdRSqgk/drb9bAlaLn+XddXZd9cdEf7A/1rTWYPJovzXL5y9urTSLTh3nj+nrvdjJ5vH0pmbVjOWyucX6Si4hD11Dyjmxv3ZkstIleKVL84H8u8bshXaXeILr53ddvcR9P5adYT27jvmvcv2lbA2Ipz1/l7zmsGpRDl6m8sKGnntinWtmk+hQv6NaLhD1r3ZhPC5hmbXUcLP8rKfzWn1qgpYJxpgjnU222sLYmjZ+ut7v1rV2ZtO5I25dGD04j0HG/5Ovqhx2YvyMeq+VtmRO6ZVMFXlQ/tOgHtdSxXCFEpPwomt3qm4gK3zzzS1ih4wZ1RpTzZ6WQMw+JMA08Mq1VkGHh4UjQoL9oMwT1fzYUX1ZncwL2VfOkO60Xg7sGkmUVjEHjsdIMZBUVzVYsywb1x+8o7SqtIC4Hl+kZarqTu/OTa40mXtXmUZOXbQwoxp1QSLd8B7NfeXlHmzrQF3cdONyDKdMOT59eqzNZVKgH8+X/9q7y0P15dsAW/9V1P8Id//ZtafzuKvDmepq0wI+ms/7asY+0zZ8GW1hb/NwjMwlWh68syxjCo0VMI3N48M87kEOuKX1Qb20iN3l2RWMeTgm5LiFG9jo7XTqYk8vodZ2qzhCctm2G7osLRZEiiTM8xigdKovKxMtb1pXD1ijJd9sWTYmUym56v5uqPtaHOmdH1ZOt57/UuswKxNktti+Mo5Uc/9kr5+XiSghB4V55YfBEgrEVYxw5vtcae3OOz98745x98qbX8V77xEtd3m9nJIi2xeRIzKWAjXP+NvfbkDD1JiCTK5vM4LbvhbtcJ8yRuPuRCODqKaapJTfNMoi1zgl6GNt/QRJuGWnynO8967toh6AceUaZJZlJEeZK5s1W9Tf1AcjQ1c+5goXKUlG5yNvtSnyiOunL15JzF4TQp+xIqyTD0yFrOMq93mRXIohS9RLEyijP+yS+81PxSSvzHri9dQKTWSGuZTsGkCfrkHp+5e8pn7p62ln9sqzc/OTNJlFVO/J+XyVnAKTTmB8JFv89vnxZlRDYWjqbzmY63Oh6ptnNbntnz0Ua43K/Tl4KtTtU9gfNMmQ2XKhAoyVanvb5Jqufeqs5fNG310xyn2RyTetdzlBonUVaOR5wZUt2cVL5a7de5GfolE3qRPWQQeAsdCF6vMitwMPUYNQkO+P5f/By/8PwDgHLXonYv419+vKp/wXgJKQj7Cqy772ATrA5Ig3fOlfWyFG0l00zxfR+6zz//wEuAm6j//Tc3yxvrjhM937LV0QyCdnaJsu6lvaY6xIq8M16hjWgp13abYuVr/62quxC3EgIjm9/pXOFQh8U26p4daCHmsxxba0s3NXe9La8tlBltkMK0qrwX9dkpO2yjD06Z4baZxTy3zDthS9NUHLT1TbXIYDbcq37t61VmRTB5agSFiVUbS5xpHpzG3DycOCo8BEiF8ANkt9fSqxkIN0FrH7FSomavteDpBGskIvM4PDGYUeS6LRWTWhxqJ6d5SY1A59Hdq7yxlk5ObStV/qpsw1IIdnvrec60ochwDO4tttsLOI3TuTdWVb7WcU+ufNuA689ZPmBncYY/TUsmt2UYBN7CnJarkGrTeDttd4My8Lm1vGmq4ld53xQ4jatg618rMjuawksnzfKfunPCd/6Lj5Sfu+94L8I/nznFasv0pCkfIaC72zaxewRAAGSbb8IkmskEbscTfu/f+Nmy1P/+B76Cq1vN4LdKZu1YaUrxpSA1tuRA6fmGYkX0pHsb1ANPi+DVNP8uaAnSjfOzSp0nxpeidDrWxpIagxSCUBUGfqeESLSjm6jDWPBknncDWu9Z/FZ46vhKliv94dQpfwJlGnVYmAs4BqeAKPpeR9FuX1bZnWUeyFx8jjODxTYY5QrHhEk6f07r+3Xj//w9y/Gr9fnXisxGtfljreVnP3OfW4eO5lL2Boiww5wNp7qCrT3nPFFPWrQIQoDyU3QmyOL2OrUFKwR+T2L9ALG1g5lOMfGUX/rcPnuDDl/1pktl+VU+yStNKV1fkcYZDybOs+LaMCtdmrqexAsk46QKXg3zg/4kdVmSd1vo70dJhhAQetWq3Tjg57QZw6AieiooL8aJ5DSZoX3QGinqvp7tD7CSIvfoga6X0znmQbF937DXa9bRFnBsrTOSF32vI8vLD4PKYVpJ0aDuGKfuLVA3mxxHKUZb9lvcz7p+Uj5fPV/NeeYU6PmOz1Xwa0dmdVjgr/z4p8oFx9u7jLd3tX2wACHh+pssUWQ4Pl4nswlAxvREkiyMRxWgFL1NH6t9Mv9Zojs3SR5M+Xvvf4Fhx2tMzm4us0VYI8uYC5jteAJtoON5WNxDGGvjNGUtr+ae306NCE2emTb4SuTMblXTZR64KzB0PLdkGivYn3pMU8m93GYncL6vnhQrFQmDwMNYCLdBSadhLR7a0zhrbb9Th7crX9ra3XbPWfR9hfHgcq/a9p3ELnD3waQqvxk6BdJwwf0LvN5lNmsZ+kc//yIv3h+582inR/DEU4ja+VAoy3BvNj+n5eio4p8dDCS+L/iSjYCpsXxqlDKZGOJ4xkzWM2zM2MMDXzAYSh68IhifCuJxBtadU73dy6j+kOjW55gkGX/2Bz/Glz6zze947xN0V8TdrpycbuAEvixC+GSe6UljbLvXg7W2ISRrbeP1vcp8IIVoREfYXAkQKEnHM6WmUufnHW0FOivKV/bKVdmZiza65869d6ZCo20zdGgWfn5dUX/dE2ZVVEe978X1RTu6fnXPUWpBU6rhATrKECpbKpwW4fUtM9lwKgd4/u4ZH7vpzP/C81Cb2/WeuTd+b96EEddy8vq+yyL2+FAxyiyfSzPiuK7iclA+KL9ZVxgKhluCo/uuvCmyYkuJDDuIIAQp0ZnlV14+ZGcQEGVypcfQysmZGvcWqSsXpGgqKo6jFGOdXSrWZi6xTeEl8zCwuTeIOkcdN059up4lNfNKl7OacuY4cgfyulKkzuda9L3vKzqe5CjvZx318KPzIspc6NXmirdt2d5YcRwrtE1bt7fGOtPD61lmn9yH4uP7P3WPv/YTn8bkQum++yvcfrWGnesJRdRXvy8ZDpcvMj91EJOmlgf7zTetlHD5cnO6WAv37mXEseXu3Qx/CHtDlzE7mQqe/5jA5Oflzju+BLKM6a/+cnn9SZwtDYJYzviOUyjEmWi8gmcPsZ6UZdBq/WbWQqIFRglSbRq+pOfBsiDgQBmMEWSlD2yuoLCWOJu/pnBZizKw2byBpN43Kaq3SWZsw5cyM5V/rbVOQXRedjqZmznaLvOl61vSCELOlUrabVfb8HqWWdG+ornOx9kiOl2k8kBIlAedniXLLMZUvsa7XUm3I+n51eQ8ySzGuLJ57XnFcKk3M4mFk28goKsEx5GZ86P1PJBSsB1IIgO9oSWJIUsEAoGdGY9ELx/XpZMzM/DCkQQkoQf9BVr3YeiV/o6zuDv2CJRFCvcGWsR3ugizAa11KAmPDTLO4vmIkkRL7rYEHEe5Ov+VM+hol1Lu8UX5HKVkK88QXTewA4xTyXHkIURKoOzaJo86wtwxAea3c1sdzRZw48SfW0D2FygktAXs61dmixBcewa1sQVAt2954zstx8dZmWuz5wl+6xubnjuZtfzUQUwc2zmF0G5X8lufnXXDs7z/KOZK6DJb/8hnxxxOmyvkcKjodiVfuhUw1ZbET7jzsuDBK7TiKPKWuh2u7SF0OHUr8nYnmwvEBbf29X1FZubj+jIjOJi6gFZPwhNDFgaxroLzFxVM0sphK/QsO52M00StlXOyDmPhxolbzQeByzEyu8UMPUfhMTtBAU5i50frTBawt4aNexH6vkLbZo6S7a4mM+KhoulfrzKLU83f/9kXeOVoUvvWMtjJ6PQEdUak91wN6LWdASycnOjyrekSEcFb+z5df3F77o01Jyfa6QRybIWSt+z6hKFAKcGH7sQkxnISG1Aw2IXxkXdu8q+1J+dZ4v5CZfDVvM+nEIKur4gyzYxLJsYKRjVV+mODdUNa51Ek4plmutxmBjkF/ziVzBMhLocFHkyg71s8aXLFR7OOII/Bqj9cBSZ5ZMpZ4tLRPezkLMYvydkUCgwDt7V9mMn5epVZqg0/9rH5rLOdDUMYNifnm7Z9Oi2T00IjkW4YOoXQm3f9pSRfR5Hm9LS5kA0CwVt3qy3Kz7w4rTTKCrobMJkx/ayDc/vW3h75CODmKVzpw9XB+W/6yf3q/8NAsxlqNjtVUpw2ZMYFNvfybVZd0RBljhvmUs+ZP1yA7fkEPkklN09lydb2RZdpPQsuw0kEHy35mizXhimeXLzFq65zpo3tjo8vRSPw+HCa4ksXPH0SK86S80+R16vM1NYuwfVn2HjMEnSdc62nBVujkHfsBWz3KR0iAJ47SPjV+7kTrmgqeL54w2cvVA0Wws+OU25Fmv39DG0gqekdtrcVfv6GnaSWf/bcqNZvlxZwd9djNHLZtLcfT9BxxvRj6/dv5eRUtazCFlGR4FpItPsryijpDr71QFlPFkl1qkGq26lS7YzKiW4Lrq18P40t6BRtqY4v7ilF7ggincLAycPmdYALkK5/dnUX7dZWlMGzRdWJdrawIvC38L8t/ENlPjbuzCCKIWn0LdHkXkazo2ob1JTGVn9V3ymTAxkKxUbVZlfGtWdWI/96lZn7XB8k6fxlvQSZU4YIBB0p6HiCnl9dN00tk9QyzSwyDyDv17avHSUI8xtpY4ky686N1qUENNbSUYIs/67WBCwwzZzJRgj3nZo1qYl5heGiVBMFllNjCri24RQG+xPFeCaN24OJ+3ts4Fivd3tBruQIOIlSUmN5YpgSZ4K7K4KWXzmb/22vl9H3mx2YZqYMuxI4H8uO50wGha9n0Wao/EsPJi7S4tBmHOIoJXY2nDnh5um81uTjDyBUlquDyiSx3fVLv9hhaBiGZmnQ8u1RuzamPq511P1th4Ei9BTb3aD0tNkMDZths+/1rNT3hQXE61ZmoyRjFaH6IIQvfrL53Ti1/MCnq+DqnR2Pji/4mu2wVcN+FBl+5IUJGxuSfl+xt+cRSvi6nQ7P7Sd88E7M0ZEb86tXa04im6pMxJumlvv3K0VWdNZDR81V+lIv48GSCbr2trbr2Ya7VR1KOBPztKYwqRtYlbQMA02UiZV8qpDnx/AMmRaczjz4obKEnuUscX6WPV+j8qBll6inqVBJtcXaZdF+bpvWBj+nwEi0WUg1MQgMmXHtWWdbNvA1UsBpPD8Ow8CQWZimMn+TaTp5RukiyLlwNC/Ge5mzxOtZZgCeb+luZMiWp/j2WVamlk+tpd+v+vBEV9GbUfrcOE05y72BpsaV92qmqFTDJx4k3J9U4yWAp7semW+ZKMkoT/EyHmuK0GDfFwSBYHwCUkm+8quu8cZLGyt6lvdvrVJAPzD0V5Rp02aC2ybtdDUHU8VMYuFW+NKy09U8GHtMsuaDsdXJCD3LSeRczQZBWgYtd3PWgLqg68l82iCFa9syJNrOBWIX2Aid07qbnKuxmQdvv3I2+1a1DANDqgVHkYcSGcaacnIOAo9xkpWTExaPd4HXq8zKNoaGwW57wZdOMp4/cm9jpeDy5WoX8MaBx3BGSfT8YcqtM1eX7wv29ppTIzWWX74fN74TAt7c99zbdws+eppwLzGcnVWLeafjsl7fuw3KU/zGr3+WnRiYsBJr+db2F9i54hnN4ipshprBjOvTOJVrKTk8adnrZiWh07M7bmL5ct7PdKvjzZ3Dyjb7lTCHgbcwaKEtCHkRBHC1P1/+7thjnbfpbjfDz+lABoFLU+dJhZzxdul4aqkbncxjHF/PMluFg0jzw58dM8oPhjs7iq4n+LLNajHs1c6Dt0cZH74bcxq7Pu7uKoa+5N2bAS9PM+4mhsPDrPTBfXrT4x17rq7ZHfHZmWH/zPESDwPB117v8tw9+MyLAoygq+DLEugIQ7+v2e7KVxdsLVicfmDZlqr1ZpI5hrtY27lA5oI7FVH9JoVt8IR2vfag47aA3TrqykUlxZxNEyq/0HV756I1mqWtrauJWq6pfe9LS5hPTk8WjgPzfVNSsDyOoaj79Suz5oX577mGXVunuDqoOQeEvotq2ax5BmljyfKVIMrsTHlJxxf0lWuTtZY0dd5Grg+CvV7Ft+scP1xdWebKggvD2+pIlIVoKggkhBI2rRvPUNmVeVleFal015MruWJmfTZnMQwMw6B9Jd/rapjZcvZ8tfKerxaOCW+5+WOamwIW1wHXW5Q+Bdp+exgvo/Pi9SSzbkdy9arHl24G7PiSnziI53QCv363w6xPwY+8MCnPo52OKJU6Qgj+s92Qo6nhH31i1Lim8K0ddqsdg7HMlStwHLs6puOAVIf89XfBEz24PoRYwyiB5w9hGUn+Gmnn4SiqPm+GNR7TFTPfWtsapVGPlF9Whd+S8k3lKmmnpGl/CwRqPT/Xs5hy9Q0U9GtzY9X1qiUCxVgaZ8JlVSyKXrFAsmDb6cnliXUKvJ5lBiCkJNjbw9sYIoTg/kQzEoZpZJASglqc7a2zDF+I3DnBYa+nGORlAl/QDyX7E800M9w8zcotsec5k8he4DzENkPFMFcS3R1lREt876wFnXqOwkS4SRhncBxDqgVR5kw9y5aslZNzksH9GsXnu64sCS6fgRCCjXD+bTDLR7oIXU81Iu/rGCWLPfrXfQPdOK3sdztdeGZrrcuApl9sgTgzJaXGMriY0PY2pnpxHT1f0VuSWKfA61lmAEIpNr74nXQ3NZDykXtJyWYQBILd3er+P3crQoimQuirrgRzCqGfPJxwdKb56aPqrd/rOVPKV2+HdGYWrA/djdmfLn7tWSOJx46WxFcwTuBUwGkMbkpK3rwDLy6ZnSsnZyAte71qm/PyiYcvBU9urrpyMYbh4sN/o3ErgpZn65ikWYNzBtzDsuj8tdPJKIbXWskLR4rHBpTG6/PCk4LhGrw4y14QbXUY65jt4syUyXIEYmEA9OtZZnVMx5I7N3xQGqTl6653mGK5Wdt5bG5Wi9nlQPJYqOjU2nh/rPnEftI4dw4DwXuvhni+wFMuLrbAg0TzSqSZrEjC6fmWq9cSzk4U47PmgjoM4FIPOiseldUeQhL6svJCuXXmwpmKz4setNlA5DpWBe6uCrgt6pgtN80E2CY5dKAs3kLy5Kpf49RyHLlBs3Z1v6CdFW/VtnNV36QQhJ6YyQQNpC6kqrDoCOzCul7PMsvvBgiyVJClis5QoCQ8uelxnFlunlS2n06nandPCS4HzSigSWa4cdrcqQRK8NSm32hr8f+pttxPDOmK7kppGWwY4qmk2MQUz1WgLFud5dfDeaJSIsU4caRXsYZfuet8NBeFW53lCW12u/654xyTWs7EcAmVg6U9+U8do0QzyunR27RjFrh1WoVlffbQDeC7r7Q/xMY6Tx5HKn1+fVrhBbQqx2dBKbIIlqbiZrPlLfp6lNljg5QrFv7aOwI+cAz/4Fb12z/+xAg/EGzvtMvl5anmxtTV6wKlK37erS1FJ+ct3si3vM9PsrJ8vf2zCEPB9rbi+FgTRe2z9n95HgYe/H/e6o4/B1PdKrM6VrLvFT6XLsi1GiiL85qYpO71PPvCkLlf6MNAiEKJUH3n1NbNjhu7OmC1gC8tVlQq8brQZ/tlreuXku1bDyUeLgB59r4FnBKp2TfnA7v6Hi4gvOK/fb3LrGhzIMHLrTJKCTwPsgyK7BEdCb4QjHRF6FKMcpYHWdd3ps4vVjBUgq4SnGaGyFhml0etXXtKiplcaSSEYBBIeljOMovKnxvlW4KOIYkFyYznVBuPUx0r2fcGgdegyK9jf+r+3r4Hs+f5dThJFyFQkmCGjU1b2+A9BdCGRtKdZbi+4VIYFOx3/cAFWi9SUHzqwDkEvGW3+b2Sgu1XYfJoi1AZzXj+ADyYKCbp6jEc+JrdnktmZKzNk/b+2pLZ5qai24e7d6t7vaHnca3j8e8Porkt6NFRRrZAb/flWwGjzPKLx+1uUVFkGiFje3teuct479WQq6HiJ/ejMpXN1o5ma0fz0vMBzEzOQmaLsL77nm/wVeGC1bzJvbFb5RblFTkvisSqUabRxtLL2bLr8YjTVCOEcw1rwDqunVlD93GkUHJ+IASujkSLMjazQJzBrVPH+xqqh0+6W0fBKjBNNZ50Gt+OJ8sHTueBz32/mUQIIEol0Yznd6wFR1PFoMU/+PUqswJCOCeJ6bRSlLXBGMtoZGqf3b/DoWTo5UqijlP+vDDJiGdm/9lZFYdaOBm8dden70sGNZ/d4ZrbjmUyq2N9x3ff0sVyGqs5jdvB1A1r+CqyRtcRKCfoRBsS3S7oKNNIKKM0CthS0E2cJco5Z898L4SrY5RIJjNHodS4h3inu9jofl4UhFvTzNDxIEQ2WNkTbYi1oefPb3WNFcwENpAaSZpA159v3+tVZgWkcGaKODILbcPgJuN43PxdCEf4dTlUvHMjyNth+cmDeG4rO5kYZuf+G7Z8LvUeLvx8mczqWDk5fSnY7viM02whzT5UipV18NggLSkvzhLJSaS43M/m3hRtqvcCmzVbXKyb3jpPDFOiTHIwXd69jTwh0OzWaxbHkeIkWi2Irm/y3Jzugbs98vGl5fKM360UNDI/11GMd4F6GNlmqBkGmrsjvyWp73wdr1eZaesCx981hGd78HdudfjsCTz1bEyWWe7fTzl6kKEERGY+3rUIlBZC8CAxvP+w8tgwuLfj0VElM2Och9DurscTHcUbe16DPO0g0XyiRj9/90GVfbvfd7bSh8Fq31pRZBoWCIrsy81A3LzkUrIiV8LWOEerAGOnGK9zzLn/SSEW+o3XTRaylom5UIhoaRvBrMVOpd5uJZ2juIA8+Ldgopv1/Fm1XcnHpbxHrowpTBf1MRDVmLZh9jcpqnqUyP+kxeaLbqH0qbf79SozY11fii16mPuresi8US5gXmtaUwIWwdBKiTIY2gBROZZO2WOMM1kV5UMlUAp6vjNz+Z4go/IGS23zHKx1JbNlOp+2Z62Otbe1VTKfhESzMJB4GbY7usySnBkXNjUMNNc3UjZDby3DcxuKwN06Em0IvWo1u3HikxnBaNosVyTz6Weanp9yb+wRtdAzLoMArg2rzNb7E49pJnhyI8VXgq3OwycLajO5CFHl5zxLJIdTjwcT90apT+zXm8xGSda6mAQKQk/w0vMdpJfRHS7wsOpJNjaWv8XqAdLDoXvrfW3NQ+jGNOOnD5uhY3u+5NfvVobLf3Q3JVux6AGlzBbh3Oq50JMoSeMwO0nlGm8XiLSAWNIPXHKeQaAbZ57ZuL5V7VhmzigClIskQYPAuLV0QdIalZd3RF+ub9oIptnqh88Co8QFDXd9F3Q864yQajOnkW1th1yd7TpUeeZpbfClLWXxYFH514nMikzd4IjU4swRmL1zAHsB/PQBYCVp7KM8jZxR4qWpZTxuHtqHgeTxoccrZxnjxJWX0jkv7HUVux2FEk7zfDvSHM14ql/rKAb5xL19lnGWGDodWZ5bdao4OVR82YZgkLfdk5ZOPoaLZAYPMTkHgedCbmrM3HEm1hL0JFU5hWSSE/3Oa6tWBRAXCJRcGirpSWdSOIszYm3KgGqRaO62lC8yLWuTlmFVUbbe5ATBYeTR8wxdPyvfNHWsG0fprzE5+4HjnI2nho5n6Xiuby+LYrPZxOtFZh2vSjb71CYcTNzk/Lodt0X8xWOnbEkmHYJeNDc5k2Q+o9j2huTtA587+ymnZ668UoLNTcWTfY+num6KRNry3Hgm3wrwtn5lSnn+KOWlk4wrVzxkvooc3PM4OvD4b98Ml0N3XUdVuomXXwuakjqkcB4pUeY0i7s9DVaz2fFJ9PJQquJ6QTP1Qd0nM8oExysUMPsTR7VxqaZsGQRqjg2ul6dSALf6Ha7oWz9QZcbnQFmu9FO6viJUktN4Ph1DHQVpVs9XZT6V2RfF/bG3tA4hBHdGztzQyWMhlZj3oxU0vYJG8yxiDbweZDZOM44jl59zs+OzETo79M1T51j+3zwJtyL4Z3fBxAHT2KMzmJYZGp7Z8njLjs/P3Yo4yyfp3bHm37ww4TinXtjZccHW79oM6Ob9+8hpQjQjtOPjDJ3Bj53UTDSBC9YWAtJEcO8Vn8lIEI3d2VMKeNMOSCHxpVgps5WTczahDbgHyFcuByTaccQICu5XuzJBi6tjPiC48LpwW7Z55UUdsXYKnK3apt0pYgpPGVe+HqAsagNsc9/UtjQFRR1SQMez9DxLx7PE2bL0QfU6xMKzWKJnlTDtr5KuV2PRk/P9KmRQwHEFuc+vV5npnENJ5Pf1pAtR86Rr2xtyzmBfQqwlxjhep6L+nie51CtIw23eJtvgBQoCQccXbHqibP1JZubCw7IsJ/GqLWpbgaIbuDSRRkM0lWQJYCql4yAolESFt9NDKoS0ddl3F/GuFoG7x1GGtrY1SHe365MZ28zu3PEXhjDtdn2GgaVbUwzcPJ1PSQA5W3vNFHBFu7fNovAjJapUdmdxxiWbu4AtaEfR7nGq57ZuXU/S81XZd3C2vkVRKX1f0fcVgrShzDmK2svvTxXkihBfWoxNXcjYAvoRl5bw9S2zAhbnVxwqyTD0eHa7+u3NCTzThX96F37+GOyk7xaODH4lSvjEfjM4utMRbG01x/Q0s/zEQcxbattaY5rKojoK39oCL346BOtcJL/9DfCNu44HOcyLxHku00Jmi7D2tjYz7pBez8Zb/OtJwRJHDrdq11pRmBPArYba2kbiGylcwG+RZKfj2TKFXKpFzcbX7FmiHUFGWvNVVaKKFGlz5rbWZV+WosqgXPXPNtpdh8rHwVcCme9sXHo60ahX0Mw6HSiJtu4NUFcMALmWeL5vxsI0deYRT1bl62fTtr69XmVWjYvNnR7cbqTruTtuhpIne+BMlYLEwHNngJFkuReYAKSnMYaWzNbu86HQeBlMI7vUXqwzwXRcm+AWQiF42wCudiw936INpHlX1lEMwjkm5zQ1+SHdn3sRr0qs6ol2n1Jw6vMiDZ7Mt2m+kmzmZ7xEN434R1M1lyW5/C3yAEtHVWaNQaBQSwKULe5N41bh5pbNk5LNznLlzDJ/1NPYJYTdqk2iYeiV3Lc939LzXd/szBulDm0F9yc+ic7QtkrVXk9d2IbXq8wKpMaSxllp/npyI8NXgjftSgIF79t05Q4S+DNTSDOfOCn6ZOltjUgSy+Fh+9nvkPUUXdFUcLLflMVuAH/kOmyFms2OYZrBdH3OOGAtmhLLWewS4QyUOwkYaxkn2vGOzkSUp7lWsuvLpVT9BXwlGQha4yC7nio9UIx1uUp6gfMXPYrUQm3jQc2WqY0l9WvkvjVV+CTNEAj3MORPxiR1vqGDQM2t2qM8IHhdB/FhSx1QnD2qNk5Sl7B3t6tJtFjIbDdOZUlgLQUEqintYj1+PcusqPdwqgiVZRgaNkJdsrfrvO8bHckgkIzSjI0OfOfbPI4ip+H9wXtwmEI8qQVVLnqZrVZocy0QfMO15nebATy96WS2P2lWEnqOBnXaknunjtUKIdweeaAqo7HJnbOlcL6hdWjrfltEVTHXACnwFqySvpIU61xmDJM0JyhWdolmUDRYzjtehqptBdOak2SSs8gNw2rVS7UhNZZBS9qeODNr508RQhB67W0UQjQM8FFmMMIyCAyTdPHkTI0sCaGksMS6eV50ig/xupZZAVdeM8RtZ4vZVfY9EC7cb+Jk9qZtuDtyqR//7T4cpgKd1HYGr2JyboTwldvN7zoe7PYgOpWMZ471Ag2Be/MvC1Jfe1s7SjTjXPUrhWjdKoEzkAdd2fgt1aYRwrTd9R86HvK8OJwqDgvFirKENL07LI4fp8Aw9BguOGe2hYodR2mZByTIFRT/MWCs86ApMOu/C69fmQlcONkyFH3fqvkwX+47pou/Maxs2YGSDxUqdxqn5dkx0ZLTGcVelLng9ra5N0ol4xPZKrM6ztUqW/5by4a8TAVfqtkXmyBcwhynlVsefS/KWD6L02AKy8rcjnZGsdJWvt62RgKfBX2rmx2stY1xqX+vrXuQVlGXuCBnV94pppwCYTbMq4kmc6zr1+K+vZ5ktsR9d6Ye11aBaMisqywFQV+gLMN8jTuPzKwRuWIMFJZJi8wW632c7BbJrMDSyWmt5fAkbv1tn/bv10Ey1eVqlmhLnGn6vreYPLiGODMk2uATo+y8r+zKe+fM3qNJ+6q1yklhGTwpGdfOSmdxhhKCXrBeG8/yN1UXOI1Vi91wMV6ZuLOmEvyak9kyHK7o8xeCzBa2bdnFmbY8f6OdNPdRx539aHWhRxAZXMjsdYLlHEJSsLmztbKSnW5WRkP4StBdoAh5LRBles7mFGWLlSizSOOE8dmY/kYfP1huivCVZSus5VYJFWKtDdXDoY1aZH+qsGv4wAKcHB4DXMjsEZRZG5ZOTk8Kntj1VgbAxqKK+ZOeIexqBoGHJwXHkVPp130yj/MA4q2OT5TpWho6wVbHW2l4LnYC1jovFmPhUhGTh+DOaFkCIQtncGVTksiQbMkgCizT2rZtp5Phy8X2v8ZdSv4c19iuPx8iNVt+z4bl53GSkRrLsJaF+jRRjVTwszg9cme8VyOzdULALmRWlX8tZLYIa/DWtu2Jq2OvJff+yIulpkooI0SuLmY2M7Lz/cyM+74yYxWJYebvWA/6Lc7qRSukcGne3Hd5QO4CpUfRbiXyk/8y3Qhirt3MKBcENLyCbO0eTcXR/HezqOsgir7Wjz6emFUDtWMZ706Bhsy0KOWmCj9XmsqeKst0MwN4acJYokBy1xWlL2S2Lh5K7+9JRytxHElO4vYqPnecEwbTtg1x3718AqDyP4ebp+339KXl8QVBtB2vUoc7AS/mRT0k42jhr8txexTgiWb9Wx2vzJDV5G6VrR48x9HyyJZZ7NQ4ZDtexmZncd/2b9cfs/UxySST04BLvTTnLnK7pq06XcrUefDsdAO6viqJygqsm4qiwIXMHJzM2rH6zSks/Vp+xHHqAn1HiSRtyQGeGcEokawZf7s2jHX11iFwCWK1sURZ1cawtjVLc//SNvQ8U0aIZEYQr8ppjqO1GCXS2d+U87nMjM7rcJWdJTBKLP0WUjBfSizuOucrW92zjUQ6mnF8KPpmcW50bWiT2TqTNsokxlr6vsHY5piCe1seTNy5LlDzXjuhkuV412WQmXn+2guZrcbqXCkK9nrVIE5PXQT9ojNNoiUH0/U8Tc4D3XJPKdxgpsaS1mLj6ozlReBuG7ZrgcOjRBKv0e6i7xuBJuzq1jjI+2PnR/nkhp7zKCrIuxKdOje42tsjbkmMU4+G6fmKYb5nMtZyuCCRTrvMVnYtV9AUk3M+RtTRlLgUgLPZwAPlEiAVvrV198dxkjGd4e24kNlqLCeVFlVw7TTVpMZyqZfV8ovIhtvVItw8GPN3fvqzazdqFn/qW74Iv8W1zFi4N57vgi+r7dUiO1LPV2zkyXnOkoyOZ7jca24/UiMWhnSNU1kyeAvgUi8rhbrV0QxLlnLHXFDXWBbjOutxs9HiXVTXBkaZJtWGQZ6ReyP0SGYYFlbJrMDB1FvI4Hd/7JUv2mGgy62uEnC5l5bJdPu+QknRaKMLlG7W12lJTDTb7iJIoB94dH3n/zurCX29ymwRlptSqMKS4swAtozOBxeougj1Q/QozvjYzYc9NTgfTbXgQYrmaETmw3vaFImelARKlu1sy+AsMldfG7QFnUna/HgCZctjdBF6lYimJmM2FE2I+Xyf0NR/OOa7Zh2zjuSrZFZARs10BHVENUN6z6taIITjwi3gfGyrsjZnnJ/tRltGbm3m36Szdczqfl6vMluEc7DvqdIZXNvKHLIIf+Fff5wPv1T427jG+deewbt0dclVFi/TaA1xDObuZ7HjI37f3/y51tKbPZ+/84ffN/d9PfRqr6tbzxEFBG5LVQTA1hEqy5MLslN3fUnf9ziOXCqF+gIwDDwCJTiYOv/LekBznYe2rhRZhLYM20c1BUWoJLtdvxEYXaCQ2eE0nXtcHxssVt7s9vJg6xk+34Jvt8jqXb9nopv9XJVvs5Mz3deRzozVTtd3W8GTed/a16vM6lh7cjbsWNYSZQJd83nUxvKpOyfl59Np6nhG+0MQAgmIIFhoDxNKlFQOKKeC1r0elhlSJetsLdoIUs/jE68cl789szegN7PNSI3LIhwqJ4xZn8miPVI03wJ1aDNvJrDWvdEtdu7N7IKpm985XlzR2GYba0lnzlZiRuHQNl6erN4eRdC3J8Wcsb0eWL1oj9O27c+MRZv5frk+z1OaeFKUfqkFXKD5fLnZoO9Ge7ENGQhAMJ9W8fUss8Y1C39ZgswI7o2bq0Ocab7zX3xkrmz4pncg1nDADLoK5UnIA45CIO0+iZ1ZGaXOUNZwmvhMs4zv/Be/Uv72Xd/xJbzt8c1G+ZNYcRIrrm8keIKFNB+BkgtZ79oUFHGeNqENbQqHrufMD4fTinM20ZZENxcfX4qVAd5t55xB4C0MZ1tkgHcKivm3zKIkSBZaV/vN0CtNEsvq2O74S7OY+Uo2AtPBnf9+LcoMVkxOQ+XY2/EcdeTNU5dGro7v/8XP8cDl00b2Bnh7l6sf1wwzymJNljQHTvkKOeOALKwH1tI1Eqs90vRptAGdwQ9+9D7/4TlHfHltp883f0kzAtZYyoP4NNOcxVnOxbp8jXJ9P7/9ENwKPq0tyT1flUHIreWtLcccaA36bsMkD9y1zMtsEQTNoO/zYpLq8qF1tJaKaWoWprYbp7p8T/hKLPW+KWBqvLivVmZ3f+XneeUXf6rx3fYb38YbfuPvbHy3jsxe/qG/T/TgNgAbTz7L07/5d5W/nVdmi7AiKqWy4/hK4OPsXLOKhF94/gE3DycAiLCDt7fsXNkOnRaPVgXV81BB+8MVANZYRHqZNAWbwi/d+CREzun7XU9uz01OC+WWJM1XUfeALm9bPYD4vEi1aQi64ym0sQsnp7FN21lb0Pei+xTB1rMyW4TZoO/zIspMY6umpEtkpNu71rDxCbGeuc3Y105m0c3Pcuff/2DjOxmN6PzW/7zx3Toy2//QT3P2wicAiN/963jsN3xH+dv5ZdaOlaaUYeBxlmTcPIFJ1pyYP/Thm/zAL99gFKUgJd13vHc+I2sNV5807FyBBw8yzDqGNxEjEBzcDBaHICqF15V0Ox5Z/62YJGP03Ef4+K1j/uD/8XP837/+TbzvTZfL/hQrbqHazgx89B70fM1OLR3eTs5ANxtwbHNlWLeFCS/ODKMkYxh65XbLk80g56NpWtZf4CRXUNw6a5tKaXltr8Uzp8Cwpuafldnjg6QUS9HuepB4mCs5TuOMtOAcmln5i3bXA87rW7VEG87ijH6gGOQLajF+x5Gcc3IfBIadThUw3XZPcNvaVyOzP/pffSeMjvg9m8/zxLPwdf9F89hzcOeX+aE/+PX82OhJXk5dym9LRS9ajr1M+b0bnymv+6KvsQy/0tV1dO/j/Nwf+U38u/E1Xkg2+Nvf+xfodJzP7boya8NKU4o7FIOp+Sxm2nAwijkYxZxOU4QfIJSH8CvBCTV/6JYKEBapnI+kUuAJgS8gNi6L8Oyqa61FKjPn5a+cvZw0EZRGOeUhPIEIQowxnE5T9s9i7p1Mudp30QmVf65ACYER1cFfiHrynMUBx4vG0zHUzX7XPPLX71/2Jc/DU3+XaOsU/okWiJy/NjBuyyXFvNKhqK8uMylFWVbkSZqMdcqeet+KhU+s6Nssmg+Wk7cUTUa+YmxlWco5lGgDxSlG4Prvki7NK38eRmanJ2dMphH69AA5PUYOT1EqJOh2GvX7foo0E5geYqYJ49425aOWD0x/coyVKWpY+Zb6YZ8gp830gxRlJ8joCCYZ9+7u0xv02NzZXktmiyCWvVZ/8sP37De85woALx27nI4At48m/LHv+2BZrvO2dyO7vca1G1dSwt5iE4aUcOWKz1MdxVsGPr94HHOSmkZ24mW4dMnDGsFzvzyzPbIWpTX67ITJ5z5dfv0P/uuvZrfvsaOmfPj5Y977pm2u7nSYxUlUUVjMYufzSNVhZzhkXWbr5oq7FWZsdoxTrLTsUH7iw/cQQCGzOgrGvzaEn2d6FechZPJ2wK2z2T2pM38ESrQqr+4cnl9mf/2vfh//9sd+hv9q6xPsbFi+5ndvzl1Xx0f+7Yj7N1L+yW//sxjVbMO3/ej/yrY442t/z9bSOj72UyPuvZjy1w7fwd71p/gf/uJ3rSWzb3zPldaHaqVE4gyOoorW74d/5RYHo1z50x8iBxsIr6pG+YagZ1C54bvfbz9bFArck8zwuUnG8UgznskPHoYCb4b1OUksaWqZTAxY6G4afF8QhpLjB5DGYIWATgfvyhPok0Ns5FYVx3Na3SPKXMbi+rYj9CReLuji/OfnxvY2r47OiuQ8y5AZl2g2rCXoWYZIS4ghVIY2PY87cVbZsQMlaly8jlC6rCtzSYKK72bPwI7t/uHOo0VyI3GOOk5jSeiBr+YPrA8jszZEpynRccLpqUTnjhb9TcnlpwMuP+3T31L8uv2fJtWS07NqrHZ707nkybefj4knuf3etwwGhnQ83/Z1ZLYIqyendv6UBf7ZB15ilO/p5XCT4PEnmxUGlsFOLdh1KJdqro4zy3GWcTgyZUrvAt2upNtt9uj0VOfZotxgDXZcarfNTcH4VJAmAqMUdPsET/SJ0xhdTk6Ia/vmaa5trAu6/jAVCgiXGl5xMEnmBjNQ4qEnZ6qdksGX69URZZIok/S8hLZjjLUWhEBbV68UimI+SuFc4wok2tmhCze1WWO+J1+dsmic6jxz2zp1CI5jj442dLz5nVOcnV9mbYiOE45eHHPjhkeSuPG+/IzP5acDHn9z6FI8vP/fEE0Ft25VY3Xl6ZSw13wOb34y5vSBa1evZ3j8cU0yVjDDbLiWzBbgofYywg8I3/i28oz51FsMfggH+xki5yz98sdDrvRcBuECL04y7iWGg4N5hdD7Hu+wOaOZ/WyUcawtX74ZMEoMP31j2kj/LYTLNvxYR/GmoUfw1pTj2PDZj9XOoTVkhtLv8uYpdDIfKSy7vbmiQBE25ZL/HM142YwSyWksMVYTKEewvI76vI4wV/erluu2O5rN0HB35M05m92f+K0xgsa6JLrPHwq08bi2Ieb8XAsMQw9rbd6vqi5r4e7YI5BgbUrPlwspPpdhq+O1GtilcFmyx6nkNJ5VqAlun803eBq5SXAemdWjXHSieeWXDunuBjz+pdtY74x4lHHrluLwlYxf+IFTLu1pOl3LzRse3U3FV/6Ofnn9x3/yDHPfovxDzkaCoyPFsJOweb1KGQgwju9xNJ5geftcu5bJbBHWnpypNpXXhZTIXh+wICxhF4KOxQvdY6QEbASSnW5z8H0hMMaSZS6DsBC5AoP28kGqQVu6UpAgyGqLqsoVSh1f0PEEHSnodKAjnZbNYmGu45VSK9EgtZsY2oAQ1RSoe7G4uL952522OY+s1oic2a5QxqyLuvJkdgV1b7xcqWZtY4KuYtor0jpo4854Rbbo+uLhSTeR22ySiRaASyeRGfBMnmVszb5V49b2m/NjjXPO4LxleftFSZpdx8PIrN5XayAZZ3S2ffyuRxBabOLGVqeG8ZFhEGhEZkkSj9AI+rX8KWkmyGJLdJYxOZGMDmHrmiXMSRCsdblUUiBeYCFaJbM2rD05v+enPsNPfdIZ+EWuPOhtaXpbGuVX1Ty96fE11+cP7eC2pPcO8y2xhMuXPZ7uery5v/itY63l+z85T1j1rW/uM8jfyp85TPnHL1Vldp+CdCo4ubc6k7O28JF70PcNez2XXGbWmblIQtTmo3o3j4q5cSrY6sAbt1feshVCCHa7PumMKeDaMCU1gjuj81tab5y6v2vDFF/NZ8mW+T3bfFQTLbhZ81H+4su0bsvWQZGAqe5fOvANA99wb+ydi7EO1pNZG05vTTm95Y44UsIb3lCN8507irt33QSKz1Je/pkqrW0We2gtePHF9ukymQju3FH8wpf/d7x87YvR3/vPz9WfRTj3tlZtbiM7IUFPo3y3+vhaEiB4agP2epV3hLWWG6dZtaJbS6fjfvOk4GqoGHrN5D/3EoPRliS1HE8MUVas+k5BVOD2KCPMBXKQx8gFgUBKiCKLVBD0NJlirYwXmRGMU0fB4UnY6lRvilXcrAVSDUfT4pNLYOPeFMsN7ok2WFucX2k8aIm2SGHpeYbEiJWcr22YZpJEu5Z2PKj7ZS/uW/P747jKyOZJS6CsS+K0ZGycH6pF5Qq1ekSJNu6t3fEsShgmWfubZRmWyazArcfezoYXszf6JEmWkmTtVJmnE0UUuYszKxiNatxA8bixawN4cKQJfOh1+hyLTV5+4g2Me5tlA16tzOAhJmfw1LN4HcXmlUot34s8ep7iPU/Pl3//zahcLTc2JNvb7pahhHdtNFdyA3zsLCWKDEdHzSmlFOW1AL90N56ziQ6HEt8X3L2b4YWWzSsZ6cuG5dzgDrGWxJNqEr3n/E5OjFN48bj6XCTWWTU5J6kmMy4NniclG7WESvuTBE/CpX7GUaTmzmnroAhSvz+BqwN44iHcnW6cVP8vgq3riYzaYKzzt+35Ck+qhsvdNE+ruNXRS5M4LcM6MvvF9/5OhmbC1R/7DMfjMw7HByvrDb0QT1wvP987foA2zYftfm7yfObSBq88dp2f+cr/ovH7q5UZrOFbO0mzVcV4cg9m5hkfvRezP3WaNaVgY0PxzMDjSn6unJXpL92OOE0N9AS+7/IdPtP12PQlP31jitZweJjR60k6nco8UM+tOJmYUmGkM0kaheis+l0Jy0ZoOAY2Q81GL8VawX4Lq8MLR+Arw3ZH0/FUmWrBWMso0fQ8g99LOVwStPxg4hyb9yfN76Ww7PWqpbjw1Kk7jnfzAOWNPCvZONUMfE2Y04MIXLZr52rmHpz9vBmX8gDks1g5VX4NR1OYpo4a05POy8eXkmEgmGaaVLvg7NQIjhcELU8zyf2x4CiaV/lshpowT2tYLMpxpslMs92BciaoSZqRWRf4PNv3szjDYjnR55dZ3VUwCgf8h6/6/aQ6JckSzIs3UdGUrzv5xbk6rl7NUFLSDar2xNllCoVxv2fY2DT8ePwl7NtNbrzri5h2BnP1FFhXZm1Y6Vu7yCBfx0YHNkPbcLF7MNW8cpbn6ZCCTkeyGUou5xlErW0mcbk30RxMDVd7HkoJlBJcHiguB7L0IIljSxBU1zhzZpWJejSiMsdYQZZ4WCMb5YuBCpSh5+fhT9P5Pp7ELtlp33dbOGttLVBW4yvHpXNcBi3PK58cwdncqLqEsMH8PRNdjWFYu6cUQEp5T1e7ZTPMFSui+g5EyVwwSe2cI3Ss3V/Pt+U9iq10lLkx6vmWuBG03OxHlm/VmintcpufMsyqObJc8WStW5iKe4aeZJo576VeLYh7ELi2aeNssdFDyKwe1qa9gFuPVxpUfdzHG53Rj3610XaASztZrtSrvuuFvXKXtjkwXNoxTMZPcWgvcfLY25buxteTWTvOva3dfTJBtkQEZAa+/7lKKbO1pbh61ZXb9CRfthU0LECTzPIDnx6Xn7d3FFc3m/W+/+aUKKrl+ADe1Pd4+24AOyGJsfzMccJ0ajk5qbYdV696jM8Up8fwTd/yFt5y5S2EZwu0h7AwOLfAKNGMFpxcHxs4DlbnF7v6bPH4wLHYzW7jBHB9IyXKBPcnHpd6mp6fstv1UbniZpLq0tPGQmtW6jp2u5rd7uIT97I6gjxo+TBazrtaoOu5N+7+VLE/ab6ttzuajdBwe+R8ky1pGbS8mSsX6+1YNt6wnsyW4c989Qe5ru4j7RaT/Zj7nzzl7l3FZCJ56qv3UDPbupu3TyA2PPVUxuYTXXbfNODP2o+6lsif4qPpG/ju8bc1rnlYmdVxfjtni0r9KHKKG2PzwFNP0PclvVybOlSyYcs7nDpvIGOd1kwpwdCXhL7gNLOluSXT7o25W3NE6Hl5XQKkhSQxZLnSaDOUeBLiSJKmbsvVl5JtCR1lCCUNuhMlBIuCI9bNPlyYg1xOyuY1ziQh5sqXA5nDl7Y0d0gJPV/gK8pA4nWCi12NxbtzcSKeOsHzqn5BofxpGvW1Ea1beWf2qfossPjKVk73nhuhekZsIVyg9rJ+1Z+dVyOzTTFiR57RU0n+NhPOfzkRHMshp16AkMzVf+hvkWnDY8kBcWRJRhl+vzpvb8gJz6g73DdbjG23Nh5iLZktwmviUPn+m1UOizAUbG97fNGGz6UFsYI/8dK0ZGPrdiUbG4p3bwYMPMFPHsQkiW0ohH7zG3qtHTTWcnBQlfuqJ0L2uh7f87Pus+/Bswa+PIV+352xoloSnWHotdY76+e6Cs6wPpPI9hxKjt1uRpi7Ow58eGIIbaJp44utQwhyzWW7jyo45dOicLU2bIaGzbA5OU9juZBEqw5P2sa4vHG7WDRmdg2iyZE7i2nt/PdqZPbVwcf5z3s/3ax74ryBfmbz3dzafYxv59+jaPb3J7e+mmhs2bz1w2yeJSRHEY+9Z5vOhmvzm71X+J83vo//ffQtfCB9W+PadWS2COeenMOhottRvKHncZAY9mcEvR0qnul7DGpbg7PE8Nx+pTMNexI/f8tc7iqu9T1ePHSUiidTjdbFxBUNDyOAG6cZd0dOWLOurs8dpHRVRmZCrnUEv+UqvGsLdjrOgJ0aF4+6DvorjHpp7he7DNud+UlQPFfbneqBq7PZfb5zYPpSrOzbeMXkDT3baD/U+hBUCqHiEQiUwJdybSeGh0W9X37utmNevk03NHx98HGue3c5UM4X1QIH+4pbkyEfHDzLsbextO5U+Hxw8C5Cz9KNLL/hxkvshmeNMm/LfoFt/Wn+iT1/NrQ2nHty9nuSjZ7i7TsBL04ypjMP+04oearbrHaaWp47qFa1y5c9VG5e2Osonup6/OorcWmvLBCGzre2LtT746xRVx0vn2S5t0bITgDf9BjsdV1g7sHE2dYWZMdrQAixdLUDF9ydLIoqxq2IGzNvnDrafut4y/2QXwv4Si51JrDWrp6cOTlzG5xiZ9bbSa4cz1eLWZkV23p79wGhH/GVg58BoAj6MgZuvOjxUniJ57benH+7eLHNpMdz/bxcCl9072V8NW2UeZpP8DTwz+y7X32HOMfk7D/7Rra3nkF4lrPU8M+fG5FZS2adf2sRPXLjJOPTtxK2thRB7jQwUJJvf2vlq6ikYJIZfuSzEw5EysdEXDobXL7ssetL3jH0yxg4CRxFmp/43JRkybkiGnUwmSofvqMpnERFvKBPqOCpTc3xvvv9MwfV23e7A9c31x0NN5HCGftlos3KBxtcexZt4xLtArbbUHDarMIoKVJdOLz9EnjLTa0NbLe07Tia945qwyBQ5VurQLFbcGkN2mvZ7rQHW8/iYWR2bHv8f0e/vfz8B7o/xRZn/K2jtyOHG3hbVdmbHzjAm1FG6WR+If1H068jIOOP93+IF/UVfiD6qvK3hFtoazmcJmvLrA3rs+/5PqoDOouxWCaZxZMQyuaR1gCRsUTGYo0gEE44fb8S2DQ1GO1WrwRIsIRKoHJlSM+XZXlrLYl1HLmTbPnjIaUAJWoJaCpbmyed91BdEVdXjmTWKXA8uZ5/rCw0QTUoK9a6to1RrsJ8H52GswqUBsrA5kU11CdBqsFasZb7nRDzvLOQJzBaY3pKsaxv86gHSheCawtMrsqvJ7PBoMfe7hZplttsRWWIP/ECBAEj6+EbST/NsNZRhkzOEpSYYbqPEzKrkKIawDM8lBCcpD4nOuA4Cco6dna22NoaNoLbYbnM2nDube2NF0KENPS2Mt6+G/AlV0N+7ihmnJ+/Op3KSQDga3fCuQb9689O5uj5v/HpLnu99qfnZw5j4nT1g/HY9QTfl7zwXDj32zsvOcaBO4fVd1dryopRIvnV+x5v2oGN+cvXQqDknP/qa1FHZgzHkQtYLtTyAlqT7gB0PMu1mqnhUwc+voR3Xm4tvha2V/DQroO23cJx5Hhi64Hgg2Bx6r11ZfZH/+vfxR/9r38XX/M138HxyYiNnarzf5mnyv+nozHHn32B8ekhWRLx/s2bLptZDZ87+QBT0WVjZz6I/U/xxfn/XmByekSaRHzgA/+KsBueS2ZtWDk5PWEZBpov3pCEUvAzB5Wv6v5U89x+QrxkRb0ZVYxrcWLJUlsS+tZjNZVyq8ytaH5b2FZ7t+tqnbYYowEOU/ipfXj7EK6GjrmtbWvnqP1lbvaA4wiiDC712jVpxlrizOBJsVYuy1kUyXtWxTkmeRRQcc+5dkMtR2a7/+40E6Ta7SS0dflAev5icqw4J+x6mLOvNpZEGwIll745i0DsAm19S7XFWte3tmacV2ZCSsLtraXtF90AozOubzw3p63d6j+OR5ewN1xaRxSNIYmcjFsC89eRWR0rJ6eLZtB8zS68Z0PxgePKOeP2SHN7pNnb8+a0qgU+Pa5WupMT7RgMcPa8zc3qAZU58fGnxutpugYDhRAwnbaXvxvD99+BP6Tc5HRBzfPlLDTMAg9yBdelBfGC1jptZncF7eQiFGaMVZMzyszKjFT1823bhBgnVS6bzLh4yKuDxZMzylxulVkm9nWQ5S6Gq7a1ltXaYMcv6/7ftsU+r8ykUvSvzr/16ujnNb918CE80Rz3S6M3EtoFldcwPtonHrn+Wb9ddqtkVsdK9r2+r+YGUynY3VVMp7aabMCXbgYcpIYXJs0Jk6bOg0e3mB6uBpInux4vTTOmLcoeay2Hh7oMzu71JN2uQCkXH/pb39jjfqz53DQrlVLXnk6IppL9e81tlLYwyUOj+r5jclukX/rUgXvLPDWjcJDCkSg/rMmjjVz4LM7m4ioPppJJuvrU0fMMmx3DOMly97h2mZX1TuAshme2YLYp/cBbGpm/DL4SbIZe44HLjJ1TbmlDnsV6Na703bWvVmb/sXFv7NExi/s4K7NFWMm+1za7hQDfF8Rx0891y5dM8wlYF7IxtkFBkuttEDiF0oYnmGjLWcu14HiDiut8D8KcMUFJuNRTRMIS1By8Oz07x7RQKFWKSaAaiqx5H9JJ6hacghWujsII/jAPcuHtUlwrclqRWe+WVFNu25pofudL57OaWbBYZE3ZJFr6lpoq+7ixTY4FJSj3heftm8CZaZo+0/P90mZRv+b79lrKTK0IHFzWXWkN0s6nBlzU+lQLZKOPy2W2COdWCHW9nMpiBUve0ZFuTF5wIWO9nuTX73QoGElejjQ/cdA0PsaxnQsZ2+lIvunZ1VuLRbh15pQiHeaT4jy54WgzZvN/jlL4lbtuWz9L8PSwKMwUR9G8fylQBlu3+cUex/PhRy4NoyzfMnXsdDU7Xc2tM3/ubfPcft73zYf3Ua2jyM95lmQk2jZ8ggscRSlWtPvFtnlTvRYyM9ayLUf8T4N/urT9d+4qxmOJHJg5Lfy37f8oAE8/vfyZ/2v+Nh+gy7WNlG5u6z+vzOpYOTmlcF4lxYr/1j6cGvhMovBDFyWSps5mcfM04yg1RJGZ4/oJAhdpIoTgIDXl+W+ca22TpLqmeMv6vjN/7AWSYdBUUhwkujy2nyTungXqQdm1VsytUr6SSGFXRt6kWjBJV29jlaQ0zlvr6EIcA12zfjEzpvV+CWwj1Vy9bb60dD1DlIkabcl8uwqZ6TX8aNfpFzjH9qKZqXFj0vHsnAnDkxJrzVy/XPtlqQmtU6RY6+rX1pI0QtweXmZnk5TppMpxsvIU0vK2ncW6b8562XVl1obV2lop2exIjnL32T/wBNyLJd/5mR69bsbOTsaDBylZBj91OG2vwxPs7FS3+vioJXnO6Tz7Xr/vPIS+fjecI8H6xCgjykd+PNacnlaTs4iGWYVB4C1M5lPHWaLmGMvb0PMMl2qr4f2JR6DsnN+tFIt9X30l2awpmvYnldvjIDAMAsMrZ36bMrBEIbNlGaLBcfY8mKxnIrk2TErlzDR1vrVX+2npE1yg52KkWuuoc+MWwdbgHuTL/YxpKrg/Wa6MWldmL98fcXRyRnaONO+fD6wrszasEWyt59IOuPMFRCPJ3cTHygxE+6qztaVYlmQsigzTaRVZsrWl2PAET3e98m37iVE6dyZ4Y0+VE/amFnzydDXfgTbMbTEEMAwchaQg4ySWpOa82krLXlejcv/Sk9ip+fe6Lu5zWAsAOA8BGLjUCrPGpN2upnjmIi0YJYrjSGFs04Gg40kC5dqRGtZyVp9F39flW1MbOIzcWO11MzY7stwBnVdBFrRw9QYKTM0v9WCqXhOZjW2Hfzr9dUvbE3UEmQ/PiJ9jdrw/sPEeJjbggwvMdgVu6PvAmI997pCdzQHvfcNO+dsymS3C6mBrbeZXQuHcwdJEMo2guyFcioUWdDpiqc0syyxRZBvlt0LFM7nHv7WWj5+lzC46b+57dPM3zIm3XpSFRcyRSQkhCD2FRZMFhlEqSc+5wgmg55tyKxNnLoh4r5viK0HonX9SFAhbzBo9v9qumcT9Hms5tykrTD09PyHRcPQw91e2TD6cWZikimHgEhKHynsocxJUiY/qEMLQDypZHkzVayKzxHp8PHtqcQFwgTJ+wXLYHMmb4eOc2h6ssPKdmBEw5u7hFCO8BqXoujKrY+lTo0Sl+n9yE65vwK/ehz0f/uKb4ScO4Mf3ITrrAZbe1niujnv35nv0bW/uY4Af/My4fCPu7ipCX/L1e2G5I//YWcKD2DQm5rM9jye7CoWzBf7LT4/pdCRXrlRdefHTHd7ah//+7ZQr+xNDl8znyGqOW/oaKknYlXgyK/Mvxpng/hrbPgvcPPXp5WxwdQqSAvWUBMtQKFaWYbvjFDxHUcrAN/R9t2s4uN1efqfro61FyWp3cWfkr0U8dRgpjiLFE8MUJeD6RtI4MZ0nvG5RSoICvnQKpLPE0YwUXk6fD5n9x8Z5ZQar3pzkh3ZrS+Nyx8t5TDVsefB4B16ZCBILRksQFimr9WAzkGTWMkqq784SxzaXE5SjFPQ9SdcXKJya/0wbElN5I1lryTKYJIazXMCxtk53Lp0TQ5oIjIYsBasFHeUmp5IFo11FDzGL4u2uhMCXrt9Sgi9NnjBH5B47i9e64rlz2y2Rf9c0aKSaOZLoxphbwVSCqgVgz/riuuRItgw6p5BTGWo93zdhyWlWnIrFl7Y0lVk7n626DULQ4KOt74iMZeVkn2aOx8mv7bJUjWO2koH7Xglnang4mbkyu1cfI45jkvE8vWobbloPb2afNp1OSOzqhbW/sUE38BGt5sdlMmvH8jOnhePIrUiFv+Nb95yr1CcewK/bdn9//kW4Ewump32Un9IZVMHX3/Rsj4Op4d+8WMWW/dvPVYqjXs8FW79nM2Azf80dJpqPnDVX4yyD/f2MfTI+lH9XJEMqcO8Vn+lEMjmFqHxjkrODu/Rw+yyPGSuY0A+mKaGyPD7Myr4fTNaLzOj7Xut2FODe2F9ICFbHXleX20klxJxvq5z57mRBkqICSrryRbD15X5W+npG2TxvbRukmPexLWyaUbZauXRn5DiErm9UO4vN0JtLctsPPIoYpoeV2cGB4QD4PX/8/8Xx/j7/x//0p1f2D+A72Wv59uNrXfvNf+gP87b3funC388rs7UPQ3HmfD0dzaHg8Zqb4TfuwYMYfvg+SCQmDtAuzxAfuZfMbef6fVkqiQq3v5uR5kGieWOvptGbVhrcWaeCfl+6NIBANBWMTxVWC0IFv+1puD6Ax4fOYwTyLMLWlmFeUaYxdj7lXIGer8qEQEXf6y0oeFintezESgiXVKdl5SzY5jY7ujQZxVoyzdon8TiVJPmbyJcQqIxALXYZDHN/WJv3bZF7oC8FPV+V7R4n895JLpNz0we2uyRhU89XSAFpLR37caxoe4tbC0dRnRHR5MRd7dmgpeChZHZlq0M3ULxw54xOr8fXfMu3tl7zWuLS40+4f3e2GHQ8xsl6MluE9dMxGGdb6vpOS/ZYjQ3wa3Yc6fCPHwAoSBVZ5jxQfvXBaM4+5CZW88vbsUZCY3JGkWkoi+ro9WTprhdPJUcHHkGuxf/W6y5Kod7Gaaody1z+Rku0cRxGLWMjhHuAi6Q4Rd/rKB7yODM1DxbmNNsFAiUJFGyGlWLgNGbh5JxmsmS382WeLkAsDvvqeKpiKczM4smZB1sX7W47B3c9SWZmJucCloZirJQwmNxZ3Vo4iVXrLsMiGtrXrpeirV04blKIh5LZ5a0ul7e6vHRvRKfX46t+029prf/zgd2dLToeTLNsLZktwrnViC7ER3B/7DMINBuh5g1bPgbBd9Z2Rv/4Djw/gelpFWQddGK8MOPgYLHa6/88yNA2T6a7ZJv/yssBNn+zmPzfP/gEPN21PDFMkQLqZtdF21FjLcdRSqhkIwsXuLdjW+AxVEbmuq9s/dm1eb1KNhU8m6GPsZaTOGMQGLpepaS5PWpn8EuN4JUz3/G2hq68XMG7A+6tGGvDVmc+r2ibj28ds32vXx1lbmu8EXplisFAufKj3EPosWFaDvpprBil7U/ofs7tK0W1xVt2LIDzyey3veeJpf2cxdG0kFmzXnfP+ef2dks2cikEqeGhZFbH2pPT5AocK1x4UGqKDMmOP0YIuBI6pYsFdgLYSgWjxCXMmRowVmJNazRNidM14jYBAi3A1gSo4FIAVzvVylr3/ZbCtb2+g7PWqc4LH07Xz0IJMx94XPzWzEq9RLnDvM+mkk45I6iSMRXlpKja1IRLwJQZUfZJisVKHEsVlFwUsbkiqOxXrd2zv5VtXdA1a+f7VYyVS85kCUTVFiWL9sLs4qNzodRlpb1m316NzPp5mrV17LDWWtJcaTOcmUTG2oYlpZBZJ/HytszX//9v73x2nIaBMP6NnSbtNi2IsiogKg4c9sqNR+DAeyHtA/EQXOAFEKeVWC7dtrSbpvljDo5bJ3FSV+pCtPh3rdNEmUxij2fmO8VmJqydcx5xbBKO1yOpMzjT8iOXsQwuvHtxCC5cX3roMcK3W+D7Brj+ASRRgCRS0kwtJ7PYz/50BTyvlD5dTYBhj/D1tl4TNRvL6aReJaGuWy+A/R2nSApphCp3kew5a1NQTUSN4xhR6Zyq4Hg2TnCfNAdWljHHspgSMhIgKgcUpOEJaS4zaEKfYxTI8yhl64FX/9ooISNbQaC2jnJ6FpAqEn/al7ILN6tetcd1AZXUridpitDX+9g+dpuZsXbOvidAaM7MV4GIXKCk1Dy5ABIm8GF6+Fz2OSv6OBr+qPFtLUqpaDIBoTx4sZVSAybWO7bP4DFdt4K3CNkGHqtdXpzm+/xPRsd1Uc6FKjhWDLz6dCTJBNRmlCjs4hnStThRTV1bqoBr+cr84ZuPKeKUIIoW5MywjfKYbaZj7ZwyR7B9zHqXISg0RRRvngCvQoG3o8PNfDawk1nXSXOBhdYl4WbFam/hX/UciD13Ww8eExgYftO3EcaFjoeJ0NDp/j7J9gEh30K06FwIEOZaRcZ0WH8r6UXLrOXr0TNEFLNclO6LP6g/5A/FOuFS7BL472ymc5am0jq7LK/t37QVEMRphm2aI/S91vUbJ7lIVx0CLi9k4Mg2cRuQuaGLbUPorGCzyxCRXTogYBafBeSXfhWn4IyMD4hO6HPkAljFKQIuMB0mWGw54sz+oZlHMk+z6Rbm4vi+WnV8E85m57VZE9RWVPv5y0/R887/vtSnIHJh3bx3VUWNV9hs6JeOFwIiF+DcrlPeKRCoNO2XxczUuBSooq8/cnGsgMlwfDENdTazpws2+/j+pfFsrc7pcDj+HX9nsu1wOE7GOafD0VGcczocHcU5p8PRUZxzOhwdxTmnw9FR/gAgllRWMU6vjwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the FrozenLake-v1 environment using 4x4 map and non-slippery version\n",
    "env = gym.make(\"FrozenLake-v1\",map_name=\"4x4\",is_slippery=False)\n",
    "img = env.render(mode='rgb_array')\n",
    "fig = plt.figure('show picture')\n",
    "\n",
    "\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.imshow(img)\n",
    "# ax.set_title(\"Taxi-v3\")#给图片加titile\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off') # 不显示刻度\n",
    "# plt.title(\"Taxi-v3\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFwhmxg80WkH"
   },
   "source": [
    "#### Understanding the FrozenLake environment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQtUaOEJrDVf",
    "outputId": "525f9f4e-ddb8-4e95-e059-2241fcee4c4a"
   },
   "outputs": [],
   "source": [
    "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
    "print(\"Observation Space\", env.observation_space)\n",
    "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see with `Observation Space Shape Discrete(16)` that the observation is a value representing the **agent’s current position as current_row * nrows + current_col (where both the row and col start at 0)**. \n",
    "\n",
    "For example, the goal position in the 4x4 map can be calculated as follows: 3 * 4 + 3 = 15. The number of possible observations is dependent on the size of the map. **For example, the 4x4 map has 16 possible observations.**\n",
    "\n",
    "\n",
    "For instance, at this state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fE_JTjGrF-B",
    "outputId": "184e69e2-67e9-4ba5-b906-49b1bef3fd3c"
   },
   "outputs": [],
   "source": [
    "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
    "print(\"Action Space Shape\", env.action_space.n)\n",
    "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action space (the set of possible actions the agent can take) is discrete with 4 actions available 🎮:\n",
    "- 0: GO LEFT\n",
    "- 1: GO DOWN\n",
    "- 2: GO RIGHT\n",
    "- 3: GO UP\n",
    "\n",
    "Reward function 💰:\n",
    "- Reach goal: +1\n",
    "- Reach hole: 0\n",
    "- Reach frozen: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "badxmLJg0i6Z"
   },
   "source": [
    "#### Create and Initialize the Q-table\n",
    "\n",
    "It's time to initialize our Q-table! To know how many rows (states) and columns (actions) to use, we need to know the action and observation space. OpenAI Gym provides us a way to do that: `env.action_space.n` and `env.observation_space.n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2m0z54AfrJVj",
    "outputId": "6a885a98-0498-4c45-8e85-957886ed312c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  16  possible states\n",
      "There are  4  possible actions\n"
     ]
    }
   ],
   "source": [
    "state_space = env.observation_space.n\n",
    "print(\"There are \", state_space, \" possible states\")\n",
    "\n",
    "action_space = env.action_space.n\n",
    "print(\"There are \", action_space, \" possible actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rCddoOXM3UQH"
   },
   "outputs": [],
   "source": [
    "# Let's create our Qtable of size (state_space, action_space) and initialized each values at 0 using np.zeros\n",
    "def initialize_q_table(state_space, action_space):\n",
    "  Qtable = np.zeros((state_space, action_space))\n",
    "  return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9YfvrqRt3jdR"
   },
   "outputs": [],
   "source": [
    "Qtable_frozenlake = initialize_q_table(state_space, action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFeeieaA0mQ_"
   },
   "source": [
    "#### Define the epsilon-greedy policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Pe3nPqOQrYXi"
   },
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
    "  # Randomly generate a number between 0 and 1\n",
    "  random_int = random.uniform(0,1)\n",
    "  # if random_int > greater than epsilon --> exploitation\n",
    "  if random_int > epsilon:\n",
    "    # Take the action with the highest value given a state\n",
    "    # np.argmax can be useful here\n",
    "    action = np.argmax(Qtable[state])\n",
    "  # else --> exploration\n",
    "  else:\n",
    "    action = env.action_space.sample()\n",
    "  \n",
    "  return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AStP0Cwf0vjF"
   },
   "source": [
    "#### Define the hyperparameters\n",
    "The exploration related hyperparamters are some of the most important ones. \n",
    "\n",
    "- We need to make sure that our agent **explores enough the state space** in order to learn a good value approximation, in order to do that we need to have progressive decay of the epsilon.\n",
    "- If you decrease too fast epsilon (too high decay_rate), **you take the risk that your agent is stuck**, since your agent didn't explore enough the state space and hence can't solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Y1tWn0tycWZ1"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_training_episodes = 10000  # Total training episodes\n",
    "learning_rate = 0.7          # Learning rate\n",
    "\n",
    "# Evaluation parameters\n",
    "n_eval_episodes = 100        # Total number of test episodes\n",
    "\n",
    "# Environment parameters\n",
    "env_id = \"FrozenLake-v1\"     # Name of the environment\n",
    "max_steps = 99               # Max steps per episode\n",
    "gamma = 0.95                 # Discounting rate\n",
    "eval_seed = []               # The evaluation seed of the environment\n",
    "\n",
    "# Exploration parameters\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.05            # Minimum exploration probability \n",
    "decay_rate = 0.0005            # Exponential decay rate for exploration prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bL4oWIJ800M6"
   },
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "paOynXy3aoJW"
   },
   "outputs": [],
   "source": [
    "def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n",
    "  bar = tqdm.tqdm(total=n_training_episodes)\n",
    "  for episode in range(n_training_episodes):\n",
    "    # Reduce epsilon (because we need less and less exploration)\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "    # Reset the environment\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "\n",
    "    # repeat\n",
    "    for step in range(max_steps):\n",
    "      # Choose the action At using epsilon greedy policy\n",
    "      action = epsilon_greedy_policy(Qtable, state, epsilon)\n",
    "\n",
    "      # Take action At and observe Rt+1 and St+1\n",
    "      # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "      new_state, reward, done, info = env.step(action)\n",
    "\n",
    "      # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "      score = learning_rate * (reward + gamma * np.max(Qtable[new_state]) - Qtable[state][action]) \n",
    "      \n",
    "      if (score != 0):\n",
    "        Qtable[state][action] += score\n",
    "\n",
    "\n",
    "      # If done, finish the episode\n",
    "      if done:\n",
    "        break\n",
    "      \n",
    "      # Our state is the new state\n",
    "      state = new_state\n",
    "    bar.update()\n",
    "  return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "28e11fb654d24ef68a72d29ab062b926",
      "78f924df828046f5b093cf927260960a",
      "e402dfe3038444718c40ba487ee5a2fe",
      "7907716bab2e4ea3a86f0b80303c089a",
      "9921542e63864e0cab7b3a8780ec88a9",
      "45439de478d741698e095508be038474",
      "59a7711f82804a78b11aefc765e81362",
      "c9aa7491673046b1a6cab9f4ef1e1594",
      "edeeb0c041e74af48eceec05203cdc57",
      "362065e4131142c4872b59dab7430775",
      "b02a41ef6745420f989aba9c357a983f"
     ]
    },
    "id": "DPBxfjJdTCOH",
    "outputId": "1211b0d1-e57b-478c-f9c2-a6d85d9ed290"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 4759.46it/s]\n"
     ]
    }
   ],
   "source": [
    "Qtable_frozenlake = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable_frozenlake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZE71JB7b1BiI"
   },
   "source": [
    "#### Tranined Q-Learning table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "me3KBqV4rqd-",
    "outputId": "f086891c-9b04-479e-ad4f-9aa65289a714"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73509189, 0.77378094, 0.77378094, 0.73509189],\n",
       "       [0.73509189, 0.        , 0.81450625, 0.77378094],\n",
       "       [0.77378094, 0.857375  , 0.77378094, 0.81450625],\n",
       "       [0.81450625, 0.        , 0.77378094, 0.77378094],\n",
       "       [0.77378094, 0.81450625, 0.        , 0.73509189],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.9025    , 0.        , 0.81450625],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.81450625, 0.        , 0.857375  , 0.77378094],\n",
       "       [0.81450625, 0.9025    , 0.9025    , 0.        ],\n",
       "       [0.857375  , 0.95      , 0.        , 0.857375  ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.9025    , 0.95      , 0.857375  ],\n",
       "       [0.9025    , 0.95      , 1.        , 0.9025    ],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qtable_frozenlake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttMwujJ31Lez"
   },
   "source": [
    "#### Model evaluation\n",
    "- Normally you should have mean reward of 1.0\n",
    "- It's relatively easy since the state space is really small (16). What you can try to do is [to replace with the slippery version](https://www.gymlibrary.ml/environments/toy_text/frozen_lake/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNl0_JO2cbkm"
   },
   "outputs": [],
   "source": [
    "def evaluate_agent(env, max_steps, n_eval_episodes, Q, seed):\n",
    "  \"\"\"\n",
    "  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n",
    "  :param env: The evaluation environment\n",
    "  :param n_eval_episodes: Number of episode to evaluate the agent\n",
    "  :param Q: The Q-table\n",
    "  :param seed: The evaluation seed array (for taxi-v3)\n",
    "  \"\"\"\n",
    "  episode_rewards = []\n",
    "  for episode in range(n_eval_episodes):\n",
    "    if seed:\n",
    "      state = env.reset(seed=seed[episode])\n",
    "    else:\n",
    "      state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    total_rewards_ep = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "      # Take the action (index) that have the maximum expected future reward given that state\n",
    "      action = np.argmax(Q[state][:])\n",
    "      new_state, reward, done, info = env.step(action)\n",
    "      total_rewards_ep += reward\n",
    "        \n",
    "      if done:\n",
    "        break\n",
    "      state = new_state\n",
    "    episode_rewards.append(total_rewards_ep)\n",
    "  mean_reward = np.mean(episode_rewards)\n",
    "  std_reward = np.std(episode_rewards)\n",
    "\n",
    "  return mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fAgB7s0HEFMm",
    "outputId": "0c006df2-2aad-46cb-f13f-0a893eeb00f0"
   },
   "outputs": [],
   "source": [
    "# Evaluate our Agent\n",
    "mean_reward, std_reward = evaluate_agent(env, max_steps, n_eval_episodes, Qtable_frozenlake, eval_seed)\n",
    "print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQoX2Iyo1OyC"
   },
   "source": [
    "### Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-N7tJXVHr3VJ"
   },
   "outputs": [],
   "source": [
    "def record_video(env, Qtable, out_directory, fps=1):\n",
    "  images = []  \n",
    "  done = False\n",
    "  \n",
    "  state = env.reset(seed=random.randint(0,500))\n",
    "  #state = env.reset()\n",
    "  img = env.render(mode='rgb_array')\n",
    "  images.append(img)\n",
    "  while not done:\n",
    "    # Take the action (index) that have the maximum expected future reward given that state\n",
    "    action = np.argmax(Qtable[state][:])\n",
    "    state, reward, done, info = env.step(action) # We directly put next_state = state for recording logic\n",
    "    img = env.render(mode='rgb_array')\n",
    "    images.append(img)\n",
    "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-JGGxzi3V8Y"
   },
   "source": [
    "Saving animated file as gif with 1 frame per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLw1MCIhsuX8"
   },
   "outputs": [],
   "source": [
    "video_path=\"replay.gif\"\n",
    "video_fps=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lg3BXlFEsTCN"
   },
   "outputs": [],
   "source": [
    "record_video(env, Qtable_frozenlake, video_path, video_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "dl7O7de11kbZ",
    "outputId": "28ec5ddc-c2f7-441c-cb9b-2c07f98fccba"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('replay.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB Assignment\n",
    "Please finish the **Exercise** and answer **Questions**.\n",
    "### Exercise ( Q-Learning with Taxi-v3 🚕) (100 Points)\n",
    "\n",
    "In this exercise, you should complete the Q-learning algorithm using the Taxi-v3 environment in the gym\n",
    "\n",
    "In Taxi-v3 🚕, there are four designated locations in the grid world indicated by R(ed), G(reen), Y(ellow), and B(lue). When the episode starts, the taxi starts off at a random square and the passenger is at a random location. The taxi drives to the passenger’s location, picks up the passenger, drives to the passenger’s destination (another one of the four specified locations), and then drops off the passenger. Once the passenger is dropped off, the episode ends.\n",
    "<div align=\"center\"><img src=\"images/image-20220805133926061.png\" alt=\"image-20220805133926061\" style=\"zoom:80%;\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PapFtBBzW3G"
   },
   "source": [
    "### Step 0 Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWkA0eXLq52V",
    "outputId": "a1a9e7d0-ad83-4fcf-9b2f-f72d7a168ec0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import imageio\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1 Create Taxi-v3 🚕  environment \n",
    "Using the API imported from gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Taxi-v3')\n",
    "img = env.render(mode='rgb_array')\n",
    "fig = plt.figure('show picture')\n",
    "\n",
    "\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.imshow(img)\n",
    "# ax.set_title(\"Taxi-v3\")#给图片加titile\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off') # 不显示刻度\n",
    "# plt.title(\"Taxi-v3\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBOaXgtsrmtT"
   },
   "source": [
    "There are **500 discrete states since there are 25 taxi positions, 5 possible locations of the passenger** (including the case when the passenger is in the taxi), and **4 destination locations.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TPNaGSZrgqA",
    "outputId": "8aa9b617-8bdd-4817-ebc2-8f97d32e9634"
   },
   "outputs": [],
   "source": [
    "state_space = env.observation_space.n\n",
    "print(\"There are \", state_space, \" possible states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdeeZuokrhit",
    "outputId": "eae26ab9-5f2f-40b6-f6ee-a6bc12d57c5c"
   },
   "outputs": [],
   "source": [
    "action_space = env.action_space.n\n",
    "print(\"There are \", action_space, \" possible actions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1r50Advrh5Q"
   },
   "source": [
    "The action space (the set of possible actions the agent can take) is discrete with **6 actions available 🎮**:\n",
    "- 0: move south\n",
    "- 1: move north\n",
    "- 2: move east\n",
    "- 3: move west\n",
    "- 4: pickup passenger\n",
    "- 5: drop off passenger\n",
    "\n",
    "Reward function 💰:\n",
    "- -1 per step unless other reward is triggered.\n",
    "- +20 delivering passenger.\n",
    "- -10 executing “pickup” and “drop-off” actions illegally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 2  Create the Q-table and initialize it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the gym api to fetch the dimension of action space and state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = env.action_space.n\n",
    "state_space = env.observation_space.n\n",
    "\n",
    "# Please complete this initialization in this line\n",
    "Q_table = initialize_q_table(state_space, action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 3 Configure the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 100000        # 一共玩多少局游戏\n",
    "total_test_episodes = 100     # 测试中一共走几步\n",
    "max_steps = 99                # Max steps per episode 每一局游戏最多走几步\n",
    "\n",
    "learning_rate = 0.5           # Learning rate\n",
    "gamma = 0.95                 # Discounting rate\n",
    "\n",
    "# Exploration parameters\n",
    "epsilon = 1.0                 # Exploration rate\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.05           # Minimum exploration probability \n",
    "decay_rate = 0.008            # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "test_seed = [16,54,165,177,191,191,120,80,149,178,48,38,6,125,174,73,50,172,100,148,146,6,25,40,68,148,49,167,9,97,164,176,61,7,54,55,\n",
    " 161,131,184,51,170,12,120,113,95,126,51,98,36,135,54,82,45,95,89,59,95,124,9,113,58,85,51,134,121,169,105,21,30,11,50,65,12,43,82,145,152,97,106,55,31,85,38,\n",
    " 112,102,168,123,97,21,83,158,26,80,63,5,81,32,11,28,148] # Evaluation seed, this ensures that all classmates agents are trained on the same taxi starting position\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 4 Q Learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The formula of Q table update(Bellman equation)\n",
    "    ![Bellman equation](https://raw.githubusercontent.com/hanruihua/NoteBook/master/AI-Note/equation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = tqdm.tqdm(total=total_episodes)\n",
    "sample_rewards = []\n",
    "\n",
    "for episode in range(total_episodes):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    sample_reward = 0 \n",
    "    while True:\n",
    "        #TODO: Please complete this action selection in this line via the maximum value\n",
    "        action = epsilon_greedy_policy(Q_table, state, epsilon)\n",
    "        \n",
    "        # TODO:fetech the new state and reward by gym API\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        # Calculate the reward of this episode\n",
    "        sample_reward += reward\n",
    "    \n",
    "        \n",
    "        # TODO: Update the Q table \n",
    "        # Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "        Q_table[state, action] = Q_table[state, action] + learning_rate * (reward + gamma * np.max(Q_table[new_state]) - Q_table[state, action]) \n",
    "        \n",
    "        # Update the state\n",
    "        state = new_state\n",
    "        \n",
    "        #store the episode reward\n",
    "        if done == True:\n",
    "            sample_rewards.append(sample_reward)\n",
    "            break\n",
    "        \n",
    "    # Reduced exploration probability (due to decreasing uncertainty)\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)         \n",
    "    # print the average reward over 1000 episodes\n",
    "    if episode%1000 == 0:\n",
    "        mean_reward = np.mean(sample_rewards)\n",
    "        sample_rewards = []\n",
    "        #print(str(episode)+\": average reward:\" + str(mean_reward))\n",
    "        bar.set_description(str(episode)+\": average reward:\" + str(mean_reward))\n",
    "    bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 5 Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps=5\n",
    "bar = tqdm.tqdm(total=total_test_episodes)\n",
    "env.reset()\n",
    "rewards=[]\n",
    "images = [] \n",
    "for episode in range(total_test_episodes):\n",
    "    state = env.reset(seed=test_seed[episode])\n",
    "    step = 0\n",
    "    done =False\n",
    "    total_rewards = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        img = env.render(mode='rgb_array')\n",
    "        images.append(img)\n",
    "        #TODO:action selection\n",
    "        action = np.argmax(Q_table[state][:])\n",
    "        #TODO:fetech the new state and reward by gym API\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        total_rewards += reward\n",
    "        if done:\n",
    "            rewards.append(total_rewards)\n",
    "            break\n",
    "        \n",
    "        state = new_state\n",
    "     \n",
    "env.close()\n",
    "mean_reward = np.mean(rewards)\n",
    "std_reward = np.std(rewards)\n",
    "print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "imageio.mimsave('taxi-v3.gif', [np.array(img) for i, img in enumerate(images)], fps=fps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQoX2Iyo1OyC"
   },
   "source": [
    "###  Step 6 Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path=\"taxi-v3.gif\"\n",
    "video_fps=5\n",
    "record_video(env, Q_table, video_path, video_fps)\n",
    "from IPython.display import Image\n",
    "Image('taxi-v3.gif')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:52:34) \n[Clang 12.0.0 ]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "28e11fb654d24ef68a72d29ab062b926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78f924df828046f5b093cf927260960a",
       "IPY_MODEL_e402dfe3038444718c40ba487ee5a2fe",
       "IPY_MODEL_7907716bab2e4ea3a86f0b80303c089a"
      ],
      "layout": "IPY_MODEL_9921542e63864e0cab7b3a8780ec88a9"
     }
    },
    "362065e4131142c4872b59dab7430775": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45439de478d741698e095508be038474": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59a7711f82804a78b11aefc765e81362": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78f924df828046f5b093cf927260960a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45439de478d741698e095508be038474",
      "placeholder": "​",
      "style": "IPY_MODEL_59a7711f82804a78b11aefc765e81362",
      "value": "100%"
     }
    },
    "7907716bab2e4ea3a86f0b80303c089a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_362065e4131142c4872b59dab7430775",
      "placeholder": "​",
      "style": "IPY_MODEL_b02a41ef6745420f989aba9c357a983f",
      "value": " 10000/10000 [00:03&lt;00:00, 4132.18it/s]"
     }
    },
    "9921542e63864e0cab7b3a8780ec88a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b02a41ef6745420f989aba9c357a983f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9aa7491673046b1a6cab9f4ef1e1594": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e402dfe3038444718c40ba487ee5a2fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9aa7491673046b1a6cab9f4ef1e1594",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_edeeb0c041e74af48eceec05203cdc57",
      "value": 10000
     }
    },
    "edeeb0c041e74af48eceec05203cdc57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
