{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB Assignment\n",
    "Please finish the **Exercise** and answer **Questions**.\n",
    "### Exercise (100 Points)\n",
    "In this lab, our goal is to write a program to segment different objects using the **GMM and EM** algorithm. We also use <u>*k-means* clustering algorithm to initialize the parameters</u> of GMM. The following steps should be implemented to achieve such a goal:\n",
    "\n",
    "1. Load image\n",
    "2. Initialize parameters of GMM using K-means\n",
    "3. Implement the EM algorithm for GMM\n",
    "4. Display result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Image\n",
    "What you should do is to implement Z-score normalization in `load()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.cluster import KMeans\n",
    "import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "COLORS = [\n",
    "    (255, 0, 0),   # red\n",
    "    (0, 255, 0),  # green\n",
    "    (0, 0, 255),   # blue\n",
    "    (255, 255, 0), # yellow\n",
    "    (255, 0, 255), # magenta\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def loadImage(image_path):\n",
    "    image = np.array(cv2.imread(image_path))\n",
    "    h, w, c = image.shape\n",
    "    image = image.reshape((h*w, c))\n",
    "\n",
    "    _mean = np.mean(image, axis = 0)\n",
    "    _std = np.std(image, axis = 0)\n",
    "    # TODO: please normalize image_pixl using Z-score\n",
    "    normed_img = (image - _mean)/_std\n",
    "        \n",
    "    return h, w, c, normed_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(n_cluster, image_pixl):\n",
    "    kmeans = KMeans(n_clusters=n_cluster)# instantiate a K-means\n",
    "    labels = kmeans.fit_predict(image_pixl)# fit and get clustering result\n",
    "    initial_mus = kmeans.cluster_centers_# get centroids\n",
    "    initial_priors, initial_covs = [], []\n",
    "    #Followings are for initialization:\n",
    "    for i in range(n_cluster):\n",
    "        datas = image_pixl[labels == i, ...].T\n",
    "        initial_covs.append(np.cov(datas))\n",
    "        initial_priors.append(datas.shape[1] / len(labels))\n",
    "        \n",
    "        \n",
    "    return initial_mus, initial_priors, initial_covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, ncomp, initial_mus, initial_covs, initial_priors):\n",
    "        \"\"\"\n",
    "        :param ncomp:           the number of clusters\n",
    "        :param initial_mus:     initial means\n",
    "        :param initial_covs:    initial covariance matrices\n",
    "        :param initial_priors:  initial mixing coefficients\n",
    "        \"\"\"\n",
    "        self.ncomp = ncomp\n",
    "        self.mus = np.asarray(initial_mus)\n",
    "        self.covs = np.asarray(initial_covs)\n",
    "        self.priors = np.asarray(initial_priors)\n",
    "\n",
    "    def inference(self, datas:np.ndarray):\n",
    "        \"\"\"\n",
    "        E-step\n",
    "        :param datas:   original data\n",
    "        :return:        posterior probability (gamma) and log likelihood\n",
    "        \"\"\"\n",
    "        probs = []\n",
    "        self.mus = datas[np.random.choice(datas.shape[0], 5)]\n",
    "        self.covs = np.full(fill_value = 0.1, shape = (self.ncomp, 3, 3))\n",
    "        self.priors = np.repeat(1/self.ncomp, self.ncomp)\n",
    "        for i in range(self.ncomp):\n",
    "            mu, cov, prior = self.mus[i, :], self.covs[i, :, :], self.priors[i]\n",
    "            # 出现在 cls = i 的概率\n",
    "            prob = prior * multivariate_normal.pdf(\n",
    "                datas, mean=mu, cov=cov, allow_singular=True\n",
    "            )\n",
    "            probs.append(np.expand_dims(prob, -1))\n",
    "        \n",
    "        # 生成一个 N * n_cls 的矩阵\n",
    "        preds = np.concatenate(probs, axis=1)\n",
    "\n",
    "        # TODO: calc log likelihood\n",
    "        log_likelihood = np.sum(np.log(np.sum(preds, axis=1)))\n",
    "\n",
    "        # TODO: calc gamma\n",
    "        gamma = np.ndarray((datas.shape[0], self.ncomp))\n",
    "        summ = np.sum(preds, axis=1)\n",
    "        for i in range(0, datas.shape[0]):\n",
    "            for j in range(0, self.ncomp):\n",
    "                gamma[i, j] = (self.priors[j] * preds[i, j])/summ[i]\n",
    "\n",
    "\n",
    "        return gamma, log_likelihood\n",
    "\n",
    "    def update(self, datas:np.ndarray, gamma):\n",
    "        \"\"\"\n",
    "        M-step\n",
    "        :param datas:   original data\n",
    "        :param gamma:    gamma\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        new_mus, new_covs, new_priors = [], [], []\n",
    "        labels = np.argmax(gamma, axis=1)\n",
    "        soft_counts = np.sum(gamma, axis=0)\n",
    "        \n",
    "        (N, dimension) = datas.shape\n",
    "        \n",
    "        \n",
    "        for i in range(self.ncomp):\n",
    "            # TODO: calc mu\n",
    "            X_ks:np.ndarray = datas[labels == i]\n",
    "            N_i = X_ks.shape[0]\n",
    "            if(N_i == 0):\n",
    "                continue\n",
    "            \n",
    "            new_mu = np.zeros((dimension, ))\n",
    "            for n in range(N):\n",
    "                new_mu += gamma[n, i]*datas[n]\n",
    "                \n",
    "            \n",
    "            new_mu /= N_i\n",
    "                \n",
    "            new_mus.append(new_mu)\n",
    "            # TODO: calc cov\n",
    "            new_cov = np.ndarray((dimension, dimension))\n",
    "            for n in range(N):\n",
    "                new_cov += gamma[n, i]*((datas[n] - new_mus[i]) * (datas[n] - new_mus[i]).T)\n",
    "            \n",
    "            \n",
    "            new_covs.append(new_cov)\n",
    "\n",
    "            # TODO: calc mixing coefficients\n",
    "            new_prior = N_i/N\n",
    "            new_priors.append(new_prior)\n",
    "            \n",
    "\n",
    "        self.mus = np.asarray(new_mus)\n",
    "        self.covs = np.asarray(new_covs)\n",
    "        self.priors = np.asarray(new_priors)\n",
    "        \n",
    "\n",
    "    def fit(self, data, iteration):\n",
    "        prev_log_liklihood = None\n",
    "\n",
    "        bar = tqdm.tqdm(total=iteration)\n",
    "        for i in range(iteration):\n",
    "            gamma, log_likelihood = self.inference(data)\n",
    "            self.update(data, gamma)\n",
    "            if prev_log_liklihood is not None and abs(log_likelihood - prev_log_liklihood) < 1e-10:\n",
    "                break\n",
    "            prev_log_likelihood = log_likelihood\n",
    "\n",
    "            bar.update()\n",
    "            bar.set_postfix({\"log likelihood\": log_likelihood})         \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display\n",
    "We use `matplotlib` to display what we segment, you can check the code in `visualize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mulikas/Codes/CS405 ML/Lab/Lab12.GMM clustering 2/Lab12.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mulikas/Codes/CS405%20ML/Lab/Lab12.GMM%20clustering%202/Lab12.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m initial_mus, initial_priors, initial_covs \u001b[39m=\u001b[39m kmeans(n_cls, image)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mulikas/Codes/CS405%20ML/Lab/Lab12.GMM%20clustering%202/Lab12.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m gmm \u001b[39m=\u001b[39m GMM(n_cls, initial_mus, initial_covs, initial_priors)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mulikas/Codes/CS405%20ML/Lab/Lab12.GMM%20clustering%202/Lab12.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m gmm\u001b[39m.\u001b[39;49mfit(image, \u001b[39m100\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mulikas/Codes/CS405%20ML/Lab/Lab12.GMM%20clustering%202/Lab12.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m visualize(gmm, image, n_cls, h, w)\n",
      "\u001b[1;32m/Users/mulikas/Codes/CS405 ML/Lab/Lab12.GMM clustering 2/Lab12.ipynb Cell 8\u001b[0m in \u001b[0;36mGMM.fit\u001b[0;34m(self, data, iteration)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mulikas/Codes/CS405%20ML/Lab/Lab12.GMM%20clustering%202/Lab12.ipynb#X10sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iteration):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mulikas/Codes/CS405%20ML/Lab/Lab12.GMM%20clustering%202/Lab12.ipynb#X10sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     gamma, log_likelihood \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minference(data)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/mulikas/Codes/CS405%20ML/Lab/Lab12.GMM%20clustering%202/Lab12.ipynb#X10sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(data, gamma)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mulikas/Codes/CS405%20ML/Lab/Lab12.GMM%20clustering%202/Lab12.ipynb#X10sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m     \u001b[39mif\u001b[39;00m prev_log_liklihood \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mabs\u001b[39m(log_likelihood \u001b[39m-\u001b[39m prev_log_liklihood) \u001b[39m<\u001b[39m \u001b[39m1e-10\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mulikas/Codes/CS405%20ML/Lab/Lab12.GMM%20clustering%202/Lab12.ipynb#X10sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;32m/Users/mulikas/Codes/CS405 ML/Lab/Lab12.GMM clustering 2/Lab12.ipynb Cell 8\u001b[0m in \u001b[0;36mGMM.update\u001b[0;34m(self, datas, gamma)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mulikas/Codes/CS405%20ML/Lab/Lab12.GMM%20clustering%202/Lab12.ipynb#X10sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m new_mu \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((dimension, ))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mulikas/Codes/CS405%20ML/Lab/Lab12.GMM%20clustering%202/Lab12.ipynb#X10sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mulikas/Codes/CS405%20ML/Lab/Lab12.GMM%20clustering%202/Lab12.ipynb#X10sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     new_mu \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m gamma[n, i]\u001b[39m*\u001b[39;49mdatas[n]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mulikas/Codes/CS405%20ML/Lab/Lab12.GMM%20clustering%202/Lab12.ipynb#X10sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m new_mu \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m N_i\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mulikas/Codes/CS405%20ML/Lab/Lab12.GMM%20clustering%202/Lab12.ipynb#X10sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m new_mus\u001b[39m.\u001b[39mappend(new_mu)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize(gmm, image, ncomp, ih, iw):\n",
    "    beliefs, log_likelihood = gmm.inference(image)\n",
    "    map_beliefs = np.reshape(beliefs, (ih, iw, ncomp))\n",
    "    segmented_map = np.zeros((ih, iw, 3))\n",
    "    for i in range(ih):\n",
    "        for j in range(iw):\n",
    "            hard_belief = np.argmax(map_beliefs[i, j, :])\n",
    "            segmented_map[i, j, :] = np.asarray(COLORS[hard_belief]) / 255.0\n",
    "            \n",
    "            \n",
    "    plt.imshow(segmented_map)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "h, w, c, image = loadImage(\"/Users/mulikas/Codes/CS405 ML/Lab/Lab12.GMM clustering 2/data/original/sample.png\")\n",
    "n = image.shape[0]\n",
    "\n",
    "n_cls = 3\n",
    "\n",
    "initial_mus, initial_priors, initial_covs = kmeans(n_cls, image)\n",
    "\n",
    "gmm = GMM(n_cls, initial_mus, initial_covs, initial_priors)\n",
    "gmm.fit(image, 100)\n",
    "visualize(gmm, image, n_cls, h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample Result\n",
    "<img src=\"images/image-20220804223008133.png\" alt=\"image-20220804223008133\" style=\"zoom:67%;\" />\n",
    "<img src=\"images/image-20220804222915979.png\" alt=\"image-20220804222915979\" style=\"zoom: 67%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions(3 points)\n",
    "1. What are the strengths of GMM; when does it perform well?\n",
    "2. What are the weaknesses of GMM; when does it perform poorly?\n",
    "3. What makes GMM a good candidate for the clustering problem, if you have enough knowledge about the data?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 优点: GMM的优点是投影后样本点不是得到一个确定的分类标记，而是得到每个类的概率，这是一个重要信息。GMM不仅可以用在聚类上，也可以用在概率密度估计上。\n",
    "2. 缺点:当每个混合模型没有足够多的点时，估算协方差变得困难起来，同时算法会发散并且找具有无穷大似然函数值的解，除非人为地对协方差进行正则化。GMM每一步迭代的计算量比较大，大于k-means。GMM的求解办法基于EM算法，因此有可能陷入局部极值，这和初始值的选取十分相关了。\n",
    "3. 聚类的同时需要额外获得概率密度，样本可分性明显。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
