{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "path = './datasets'\n",
    "\n",
    "trainset = CIFAR10(root=path, train=True,\n",
    "                                        download=True, transform=ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "testset = CIFAR10(root=path, train=False,\n",
    "                                       download=True, transform=ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2, drop_last=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 32, 32, 3\n",
    "        self.proc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        # 16, 16, 64\n",
    "        self.proc2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        # 8, 8, 128\n",
    "        self.proc3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        # 4, 4, 256\n",
    "        \n",
    "        self.classfier = nn.Sequential(\n",
    "            nn.Linear(4*4*256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 10)\n",
    "        )       \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.proc1(x)\n",
    "        # print(x.size())\n",
    "        \n",
    "        x = self.proc2(x)\n",
    "        # print(x.size())\n",
    "\n",
    "        x = self.proc3(x)\n",
    "        # print(x.size())\n",
    "        \n",
    "        x = x.view(-1, 4*4*256)\n",
    "\n",
    "        x = self.classfier(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time as t\n",
    "# import numpy as np\n",
    "# ########### Write Your Code Here ###########\n",
    "# LEARNING_RATE = 0.01\n",
    "# device = torch.device('mps')\n",
    "# model = CNN().to(device)\n",
    "# loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "# opt = torch.optim.RMSprop(model.parameters(), lr=LEARNING_RATE)\n",
    "# ############################################\n",
    "\n",
    "# res = []\n",
    "\n",
    "# Epochs = 500\n",
    "# for i in range(Epochs):\n",
    "#     last_time = t.time()\n",
    "#     for cnt, (x, y) in enumerate(trainloader):\n",
    "#         samples = x.to(device)\n",
    "#         print(samples.size())\n",
    "#         y = y.to(device)\n",
    "#         output = model(samples)\n",
    "        \n",
    "        \n",
    "#         loss = loss_fn(output, y.to(device))\n",
    "#         opt.zero_grad()\n",
    "        \n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#         y_pred = torch.argmax(output, dim=1).to(device)        \n",
    "#         acc = (torch.argwhere(y_pred == y)).size(0)/y.size(0)\n",
    "#         res.append(acc)\n",
    "        \n",
    "    \n",
    "#     mean_acc = np.mean(res)\n",
    "#     res.clear()\n",
    "#     this_time = t.time()\n",
    "#     print(\"Epoch:{}/{}, step:{}, loss:{:.4f}, time:{:.2f}\".format(i + 1, Epochs, i + 1, loss.item(), this_time - last_time))\n",
    "#     print(\"acc:{:.4f}\".format(mean_acc))\n",
    "    \n",
    "    \n",
    "#     if((i + 1)%(Epochs/(Epochs/10)) == 0):\n",
    "#         torch.save(model.state_dict(), 'model' + str(model)[:3] + \"_\" + str(opt)[:7] + \"lr=\" + str(LEARNING_RATE) + \"_\" + str(i/(Epochs/100) + 1) + '.pth')\n",
    "#         print(str(opt)[:7])\n",
    "#         print(\"Checkpoint save!\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (proc1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (proc2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (proc3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classfier): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "finalModel = \"model_ada\"\n",
    "\n",
    "model.load_state_dict(torch.load(finalModel + \".pth\", map_location=torch.device(\"mps\")))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "\n",
    "y_pred = torch.tensor([], dtype=torch.int32)\n",
    "y_test = torch.tensor([], dtype=torch.int32)\n",
    "\n",
    "for data in testloader:\n",
    "    x, y = data\n",
    "    tmp = torch.argmax(model(x), dim=1)\n",
    "    y_pred = torch.cat((y_pred, tmp), dim=0)\n",
    "    y_test = torch.cat((y_test, y), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      1000\n",
      "           1       0.86      0.81      0.83      1000\n",
      "           2       0.66      0.57      0.62      1000\n",
      "           3       0.53      0.54      0.54      1000\n",
      "           4       0.67      0.66      0.67      1000\n",
      "           5       0.62      0.63      0.62      1000\n",
      "           6       0.77      0.79      0.78      1000\n",
      "           7       0.74      0.76      0.75      1000\n",
      "           8       0.83      0.82      0.82      1000\n",
      "           9       0.76      0.83      0.79      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.72      0.72      0.72     10000\n",
      "weighted avg       0.72      0.72      0.72     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "arr_pred = np.array(y_pred)\n",
    "arr_test = np.array(y_test)\n",
    "\n",
    "print(classification_report(arr_test, arr_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
